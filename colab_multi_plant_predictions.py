#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Colabç¯å¢ƒä¸‹çš„å¤šPlanté¢„æµ‹ç»“æœä¿å­˜è„šæœ¬
ä¸ºPlant 171ã€172ã€186ç”Ÿæˆé…ç½®å¹¶ä¿å­˜é¢„æµ‹ç»“æœåˆ°Google Drive

ä½¿ç”¨æ–¹æ³•ï¼š
1. åœ¨Colabä¸­å…ˆè¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼š
   # !pip install -q pyyaml pandas numpy scikit-learn xgboost lightgbm
   # from google.colab import drive
   # drive.mount('/content/drive')
   # !git clone https://github.com/zhesun-0209/SolarPV-Prediction.git /content/SolarPV-Prediction
   # !python /content/SolarPV-Prediction/generate_multi_plant_configs.py

2. ç„¶åè¿è¡Œæ­¤è„šæœ¬ï¼š
   # !python /content/SolarPV-Prediction/colab_multi_plant_predictions.py
"""

import os
import sys

# å¯¼å…¥å¿…è¦çš„åº“
import sys
sys.path.append('/content/SolarPV-Prediction')

import yaml
import pandas as pd
import numpy as np
import io
from pathlib import Path
from contextlib import redirect_stdout, redirect_stderr

# æ£€æŸ¥æ˜¯å¦åœ¨Colabç¯å¢ƒä¸­
try:
    from google.colab import drive
    IN_COLAB = True
except ImportError:
    IN_COLAB = False

# å¯¼å…¥è®­ç»ƒæ¨¡å—
from train.train_dl import train_dl_model
from train.train_ml import train_ml_model
from data.data_utils import load_raw_data, preprocess_features, create_sliding_windows, split_data

def load_and_preprocess_data(data_path, past_hours, future_hours, train_ratio, val_ratio, 
                            use_pv, use_forecast, use_hist_weather, use_ideal_nwp, 
                            use_time_encoding, weather_category):
    """åŠ è½½å’Œé¢„å¤„ç†æ•°æ®"""
    # åŠ è½½åŸå§‹æ•°æ®
    df = load_raw_data(data_path)
    
    # æ˜ å°„weather_categoryåˆ°data_utilsæœŸæœ›çš„å€¼
    weather_category_mapping = {
        'none': 'none',
        'hist_weather': 'all_weather',
        'nwp': 'all_weather',
        'nwp_plus': 'all_weather'
    }
    mapped_weather_category = weather_category_mapping.get(weather_category, 'none')
    
    # é¢„å¤„ç†ç‰¹å¾
    df_processed, hist_feats, fcst_feats, scaler_hist, scaler_fcst, scaler_target = preprocess_features(df, {
        'use_pv': use_pv,
        'use_forecast': use_forecast,
        'use_hist_weather': use_hist_weather,
        'use_ideal_nwp': use_ideal_nwp,
        'use_time_encoding': use_time_encoding,
        'weather_category': mapped_weather_category
    })
    
    # åˆ›å»ºæ»‘åŠ¨çª—å£
    X_hist, X_fcst, y, hours, dates = create_sliding_windows(
        df_processed, past_hours, future_hours, hist_feats, fcst_feats
    )
    
    # åˆ†å‰²æ•°æ®
    Xh_tr, Xf_tr, y_tr, hrs_tr, dates_tr, \
    Xh_va, Xf_va, y_va, hrs_va, dates_va, \
    Xh_te, Xf_te, y_te, hrs_te, dates_te = split_data(
        X_hist, X_fcst, y, hours, dates, train_ratio, val_ratio
    )
    
    # ç»„ç»‡æ•°æ®ä¸ºè®­ç»ƒå‡½æ•°æœŸæœ›çš„æ ¼å¼
    train_data = (Xh_tr, Xf_tr, y_tr, hrs_tr, dates_tr)
    val_data = (Xh_va, Xf_va, y_va, hrs_va, dates_va)
    test_data = (Xh_te, Xf_te, y_te, hrs_te, dates_te)
    scalers = (scaler_hist, scaler_fcst, scaler_target)
    
    return train_data, val_data, test_data, scalers

def get_scenario_name(config):
    """æ ¹æ®é…ç½®è·å–åœºæ™¯åç§°"""
    use_pv = config.get('use_pv', False)
    use_forecast = config.get('use_forecast', False)
    use_hist_weather = config.get('use_hist_weather', False)
    use_ideal_nwp = config.get('use_ideal_nwp', False)
    
    if use_pv and use_forecast and use_ideal_nwp:
        return 'PV+NWP+'
    elif use_pv and use_forecast:
        return 'PV+NWP'
    elif use_pv and use_hist_weather:
        return 'PV+HW'
    elif use_pv:
        return 'PV'
    elif use_forecast and use_ideal_nwp:
        return 'NWP+'
    elif use_forecast:
        return 'NWP'
    else:
        return 'Unknown'

def train_single_model(config_path, plant_id):
    """è®­ç»ƒå•ä¸ªæ¨¡å‹"""
    try:
        # åŠ è½½é…ç½®
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        model_name = config['model']
        print(f"ğŸ”„ è®­ç»ƒ {model_name} æ¨¡å‹...")
        
        # åŠ è½½å’Œé¢„å¤„ç†æ•°æ®
        data_path = config['data_path']
        if not os.path.exists(data_path):
            print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_path}")
            return None
        
        # ä½¿ç”¨ç°æœ‰çš„æ•°æ®åŠ è½½å‡½æ•°
        train_data, val_data, test_data, scalers = load_and_preprocess_data(
            data_path=data_path,
            past_hours=config['past_hours'],
            future_hours=config['future_hours'],
            train_ratio=config['train_ratio'],
            val_ratio=config['val_ratio'],
            use_pv=config['use_pv'],
            use_forecast=config['use_forecast'],
            use_hist_weather=config['use_hist_weather'],
            use_ideal_nwp=config['use_ideal_nwp'],
            use_time_encoding=config['use_time_encoding'],
            weather_category=config['weather_category']
        )
        
        # è®­ç»ƒæ¨¡å‹
        f = io.StringIO()
        with redirect_stdout(f), redirect_stderr(f):
            if model_name in ['LSTM', 'GRU', 'TCN', 'Transformer']:
                # æ·±åº¦å­¦ä¹ æ¨¡å‹
                model, metrics = train_dl_model(
                    config=config,
                    train_data=train_data,
                    val_data=val_data,
                    test_data=test_data,
                    scalers=scalers
                )
                y_pred = metrics['y_pred_inv']
                y_true = metrics['y_true_inv']
                dates_te = test_data[4]  # dates from test_data
            else:
                # æœºå™¨å­¦ä¹ æ¨¡å‹
                Xh_train, Xf_train, y_train, _, _ = train_data
                Xh_test, Xf_test, y_test, _, dates_te = test_data
                scaler_target = scalers[2]
                
                model, metrics = train_ml_model(
                    config=config,
                    Xh_train=Xh_train,
                    Xf_train=Xf_train,
                    y_train=y_train,
                    Xh_test=Xh_test,
                    Xf_test=Xf_test,
                    y_test=y_test,
                    dates_test=dates_te,
                    scaler_target=scaler_target
                )
                y_pred = metrics['y_pred_inv']
                y_true = metrics['y_true_inv']
        
        # è·å–é…ç½®ä¿¡æ¯
        scenario = get_scenario_name(config)
        lookback = config['past_hours']
        te = config.get('use_time_encoding', False)
        complexity = config.get('model_complexity', 'low')
        
        # æ¨¡å‹åç§°æ˜ å°„ï¼šLSR -> Linear
        model_name_mapped = 'Linear' if model_name == 'LSR' else model_name
        
        print(f"âœ… {model_name} æ¨¡å‹è®­ç»ƒå®Œæˆ - {scenario}")
        
        return {
            'y_true': y_true,
            'y_pred': y_pred,
            'model_name': model_name_mapped,
            'scenario': scenario,
            'lookback': lookback,
            'te': te,
            'complexity': complexity,
            'config_path': config_path,
            'dates': dates_te,
            'plant_id': plant_id
        }
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹è®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None

def save_predictions_to_drive(results, plant_id, drive_path):
    """ä¿å­˜é¢„æµ‹ç»“æœåˆ°Google Drive"""
    print(f"ğŸ’¾ ä¿å­˜Plant {plant_id}çš„é¢„æµ‹ç»“æœåˆ°Google Drive...")
    
    # åˆ›å»ºPlantä¸“ç”¨ç›®å½•
    plant_dir = os.path.join(drive_path, f'Plant_{plant_id}')
    os.makedirs(plant_dir, exist_ok=True)
    
    # 1. ä¿å­˜æ±‡æ€»CSV
    summary_data = []
    
    for i, result in enumerate(results):
        if result is None:
            continue
            
        # å–å‰168å°æ—¶çš„æ•°æ®ï¼ˆ7å¤©ï¼‰
        y_true = result['y_true'][:168].flatten()
        y_pred = result['y_pred'][:168].flatten()
        
        # ç¡®ä¿é•¿åº¦ä¸€è‡´
        min_len = min(len(y_true), len(y_pred))
        y_true = y_true[:min_len]
        y_pred = y_pred[:min_len]
        
        # åˆ›å»ºæ—¶é—´åºåˆ—æ•°æ®
        for j in range(min_len):
            summary_data.append({
                'experiment_id': i + 1,
                'model': result['model_name'],
                'scenario': result['scenario'],
                'lookback': result['lookback'],
                'te': result['te'],
                'complexity': result['complexity'],
                'timestep': j,
                'ground_truth': y_true[j],
                'prediction': y_pred[j],
                'config_file': os.path.basename(result['config_path'])
            })
    
    # ä¿å­˜æ±‡æ€»CSV
    summary_df = pd.DataFrame(summary_data)
    summary_path = os.path.join(plant_dir, f'Plant_{plant_id}_all_predictions_summary.csv')
    summary_df.to_csv(summary_path, index=False)
    print(f"âœ… æ±‡æ€»CSVå·²ä¿å­˜: {summary_path}")
    
    # 2. æŒ‰åœºæ™¯ä¿å­˜CSVæ–‡ä»¶
    scenarios = ['PV', 'PV+NWP', 'PV+NWP+', 'PV+HW', 'NWP', 'NWP+']
    
    # åˆ›å»ºby_scenarioå­ç›®å½•
    by_scenario_dir = os.path.join(plant_dir, 'by_scenario')
    os.makedirs(by_scenario_dir, exist_ok=True)
    
    for scenario in scenarios:
        scenario_data = []
        
        for i, result in enumerate(results):
            if result is None or result['scenario'] != scenario:
                continue
                
            # å–å‰168å°æ—¶çš„æ•°æ®
            y_true = result['y_true'][:168].flatten()
            y_pred = result['y_pred'][:168].flatten()
            
            min_len = min(len(y_true), len(y_pred))
            y_true = y_true[:min_len]
            y_pred = y_pred[:min_len]
            
            # åˆ›å»ºæ—¶é—´åºåˆ—æ•°æ®
            for j in range(min_len):
                scenario_data.append({
                    'experiment_id': i + 1,
                    'model': result['model_name'],
                    'lookback': result['lookback'],
                    'te': result['te'],
                    'complexity': result['complexity'],
                    'timestep': j,
                    'ground_truth': y_true[j],
                    'prediction': y_pred[j],
                    'config_file': os.path.basename(result['config_path'])
                })
        
        if scenario_data:
            scenario_df = pd.DataFrame(scenario_data)
            scenario_path = os.path.join(by_scenario_dir, f'{scenario}_predictions.csv')
            scenario_df.to_csv(scenario_path, index=False)
            print(f"âœ… {scenario} CSVå·²ä¿å­˜: {scenario_path}")
    
    # 3. æŒ‰æ¨¡å‹ä¿å­˜CSVæ–‡ä»¶
    models = ['LSTM', 'GRU', 'TCN', 'Transformer', 'RF', 'XGB', 'LGBM', 'Linear']
    
    # åˆ›å»ºby_modelå­ç›®å½•
    by_model_dir = os.path.join(plant_dir, 'by_model')
    os.makedirs(by_model_dir, exist_ok=True)
    
    for model in models:
        model_data = []
        
        for i, result in enumerate(results):
            if result is None or result['model_name'] != model:
                continue
                
            # å–å‰168å°æ—¶çš„æ•°æ®
            y_true = result['y_true'][:168].flatten()
            y_pred = result['y_pred'][:168].flatten()
            
            min_len = min(len(y_true), len(y_pred))
            y_true = y_true[:min_len]
            y_pred = y_pred[:min_len]
            
            # åˆ›å»ºæ—¶é—´åºåˆ—æ•°æ®
            for j in range(min_len):
                model_data.append({
                    'experiment_id': i + 1,
                    'scenario': result['scenario'],
                    'lookback': result['lookback'],
                    'te': result['te'],
                    'complexity': result['complexity'],
                    'timestep': j,
                    'ground_truth': y_true[j],
                    'prediction': y_pred[j],
                    'config_file': os.path.basename(result['config_path'])
                })
        
        if model_data:
            model_df = pd.DataFrame(model_data)
            model_path = os.path.join(by_model_dir, f'{model}_predictions.csv')
            model_df.to_csv(model_path, index=False)
            print(f"âœ… {model} CSVå·²ä¿å­˜: {model_path}")
    
    # 4. ä¿å­˜å®éªŒé…ç½®æ±‡æ€»
    config_summary = []
    
    for i, result in enumerate(results):
        if result is None:
            continue
        
        config_summary.append({
            'experiment_id': i + 1,
            'model': result['model_name'],
            'scenario': result['scenario'],
            'lookback': result['lookback'],
            'te': result['te'],
            'complexity': result['complexity'],
            'config_file': os.path.basename(result['config_path']),
            'plant_id': result['plant_id']
        })
    
    config_df = pd.DataFrame(config_summary)
    config_path = os.path.join(plant_dir, f'Plant_{plant_id}_experiment_configs.csv')
    config_df.to_csv(config_path, index=False)
    print(f"âœ… å®éªŒé…ç½®CSVå·²ä¿å­˜: {config_path}")
    
    print(f"ğŸ‰ Plant {plant_id} æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ°: {plant_dir}")

def process_plant(plant_id, drive_path):
    """å¤„ç†å•ä¸ªPlantçš„æ‰€æœ‰å®éªŒ"""
    print(f"\nğŸš€ å¼€å§‹å¤„ç†Plant {plant_id}...")
    
    # è·å–é…ç½®æ–‡ä»¶åˆ—è¡¨
    config_dir = f"config/projects/{plant_id}"
    if not os.path.exists(config_dir):
        print(f"âŒ é…ç½®ç›®å½•ä¸å­˜åœ¨: {config_dir}")
        return
    
    config_files = [f for f in os.listdir(config_dir) if f.endswith('.yaml')]
    print(f"ğŸ“ æ‰¾åˆ° {len(config_files)} ä¸ªé…ç½®æ–‡ä»¶")
    
    # è®­ç»ƒæ‰€æœ‰æ¨¡å‹
    results = []
    for i, config_file in enumerate(config_files):
        config_path = os.path.join(config_dir, config_file)
        print(f"\nğŸ“Š è¿›åº¦: {i+1}/{len(config_files)} - {config_file}")
        
        result = train_single_model(config_path, plant_id)
        results.append(result)
    
    # ä¿å­˜ç»“æœåˆ°Google Drive
    save_predictions_to_drive(results, plant_id, drive_path)
    
    print(f"âœ… Plant {plant_id} å¤„ç†å®Œæˆï¼")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¤šPlanté¢„æµ‹ç»“æœä¿å­˜åˆ°Google Drive...")
    
    # Google Driveè·¯å¾„
    drive_path = "/content/drive/MyDrive/Solar PV electricity/plot"
    
    # ç¡®ä¿Driveè·¯å¾„å­˜åœ¨
    os.makedirs(drive_path, exist_ok=True)
    
    # è¦å¤„ç†çš„Plantåˆ—è¡¨
    plant_ids = [171, 172, 186]
    
    for plant_id in plant_ids:
        process_plant(plant_id, drive_path)
    
    print(f"\nğŸ‰ æ‰€æœ‰Plantå¤„ç†å®Œæˆï¼")
    print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {drive_path}")

if __name__ == "__main__":
    main()
