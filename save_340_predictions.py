#!/usr/bin/env python3
"""
ä¿å­˜340ä¸ªç»„åˆçš„é¢„æµ‹ç»“æœ
å°†ground truthå’Œpredictionä¿å­˜åˆ°CSVæ–‡ä»¶ä¸­
"""

import os
import sys
import yaml
import numpy as np
import pandas as pd
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append('.')

from data.data_utils import (
    load_raw_data,
    preprocess_features,
    create_sliding_windows,
    split_data
)
from train.train_dl import train_dl_model
from train.train_ml import train_ml_model
from models.rnn_models import LSTM, GRU
from models.tcn import TCNModel
from models.transformer import Transformer
from models.ml_models import train_rf, train_xgb, train_lgbm

def load_and_prepare_data(project_id):
    """åŠ è½½å’Œå‡†å¤‡æ•°æ®"""
    print(f"ğŸ“Š åŠ è½½é¡¹ç›® {project_id} æ•°æ®...")
    
    data_path = f"data/Project{project_id}.csv"
    if not os.path.exists(data_path):
        print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_path}")
        return None
    
    df = load_raw_data(data_path)
    print(f"âœ… æ•°æ®åŠ è½½å®Œæˆ: {len(df)} è¡Œ")
    
    return df

def train_and_predict_single_model(df, config_path):
    """è®­ç»ƒå•ä¸ªæ¨¡å‹å¹¶é¢„æµ‹"""
    print(f"ğŸš€ è®­ç»ƒæ¨¡å‹: {os.path.basename(config_path)}...")
    
    try:
        with open(config_path, 'r') as f:
            config = yaml.safe_load(f)
        
        # é¢„å¤„ç†ç‰¹å¾
        df_clean, hist_feats, fcst_feats, scaler_hist, scaler_fcst, scaler_target = preprocess_features(df, config)
        
        # åˆ›å»ºæ»‘åŠ¨çª—å£
        X_hist, X_fcst, y, hours, dates = create_sliding_windows(
            df_clean, 
            config['past_hours'], 
            config['future_hours'], 
            hist_feats, 
            fcst_feats, 
            no_hist_power=not config.get('use_pv', True)
        )
        
        # åˆ†å‰²æ•°æ®
        Xh_tr, Xf_tr, y_tr, hrs_tr, dates_tr, \
        Xh_va, Xf_va, y_va, hrs_va, dates_va, \
        Xh_te, Xf_te, y_te, hrs_te, dates_te = split_data(
            X_hist, X_fcst, y, hours, dates,
            train_ratio=config["train_ratio"],
            val_ratio=config["val_ratio"]
        )
        
        model_name = config['model']
        
        # è®­ç»ƒæ¨¡å‹
        if model_name in ['LSTM', 'GRU', 'TCN', 'Transformer']:
            # æ·±åº¦å­¦ä¹ æ¨¡å‹
            train_data = (Xh_tr, Xf_tr, y_tr, hrs_tr, dates_tr)
            val_data = (Xh_va, Xf_va, y_va, hrs_va, dates_va)
            test_data = (Xh_te, Xf_te, y_te, hrs_te, dates_te)
            scalers = (scaler_hist, scaler_fcst, scaler_target)
            
            # æŠ‘åˆ¶è®­ç»ƒè¿‡ç¨‹ä¸­çš„è¾“å‡º
            import io
            from contextlib import redirect_stdout, redirect_stderr
            
            f = io.StringIO()
            with redirect_stdout(f), redirect_stderr(f):
                model, metrics = train_dl_model(config, train_data, val_data, test_data, scalers)
            
            # é¢„æµ‹
            model.eval()
            with torch.no_grad():
                device = next(model.parameters()).device
                Xh_tensor = torch.FloatTensor(Xh_te).to(device)
                Xf_tensor = torch.FloatTensor(Xf_te).to(device) if Xf_te is not None else None
                
                if Xf_tensor is not None:
                    y_pred = model(Xh_tensor, Xf_tensor)
                else:
                    y_pred = model(Xh_tensor)
                
                y_pred = y_pred.cpu().numpy()
        else:
            # æœºå™¨å­¦ä¹ æ¨¡å‹
            if Xf_tr is not None:
                X_tr = np.concatenate([Xh_tr.reshape(Xh_tr.shape[0], -1), Xf_tr.reshape(Xf_tr.shape[0], -1)], axis=1)
            else:
                X_tr = Xh_tr.reshape(Xh_tr.shape[0], -1)
            
            if Xf_te is not None:
                X_te = np.concatenate([Xh_te.reshape(Xh_te.shape[0], -1), Xf_te.reshape(Xh_te.shape[0], -1)], axis=1)
            else:
                X_te = Xh_te.reshape(Xh_te.shape[0], -1)
            
            # è®­ç»ƒæ¨¡å‹
            import io
            from contextlib import redirect_stdout, redirect_stderr
            f = io.StringIO()
            with redirect_stdout(f), redirect_stderr(f):
                complexity = config.get('model_complexity', 'low')
                if complexity == 'high' and 'ml_high' in config['model_params']:
                    ml_params = config['model_params']['ml_high']
                elif complexity == 'low' and 'ml_low' in config['model_params']:
                    ml_params = config['model_params']['ml_low']
                else:
                    ml_params = config['model_params']
                
                if model_name == 'RF':
                    model = train_rf(X_tr, y_tr, ml_params)
                elif model_name == 'XGB':
                    model = train_xgb(X_tr, y_tr, ml_params)
                elif model_name == 'LGBM':
                    model = train_lgbm(X_tr, y_tr, ml_params)
                elif model_name == 'Linear':
                    from sklearn.linear_model import LinearRegression
                    model = LinearRegression()
                    model.fit(X_tr, y_tr)
            
            # é¢„æµ‹
            y_pred = model.predict(X_te)
        
        # è·å–é…ç½®ä¿¡æ¯
        scenario = get_scenario_name(config)
        lookback = config['past_hours']
        te = config.get('use_time_encoding', False)
        complexity = config.get('model_complexity', 'low')
        
        print(f"âœ… {model_name} æ¨¡å‹è®­ç»ƒå®Œæˆ - {scenario}")
        
        return {
            'y_true': y_te,
            'y_pred': y_pred,
            'model_name': model_name,
            'scenario': scenario,
            'lookback': lookback,
            'te': te,
            'complexity': complexity,
            'config_path': config_path,
            'dates': dates_te
        }
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹è®­ç»ƒå¤±è´¥: {e}")
        return None

def get_scenario_name(config):
    """æ ¹æ®é…ç½®è·å–åœºæ™¯åç§°"""
    use_pv = config.get('use_pv', False)
    use_forecast = config.get('use_forecast', False)
    use_hist_weather = config.get('use_hist_weather', False)
    use_ideal_nwp = config.get('use_ideal_nwp', False)
    
    if use_pv and use_hist_weather:
        return 'PV+HW'
    elif use_pv and use_forecast and use_ideal_nwp:
        return 'PV+NWP+'
    elif use_pv and use_forecast:
        return 'PV+NWP'
    elif use_pv:
        return 'PV'
    elif use_forecast and use_ideal_nwp:
        return 'NWP+'
    elif use_forecast:
        return 'NWP'
    else:
        return 'Unknown'

def save_predictions_to_csv(results, output_dir):
    """ä¿å­˜é¢„æµ‹ç»“æœåˆ°CSVæ–‡ä»¶"""
    print("ğŸ’¾ ä¿å­˜é¢„æµ‹ç»“æœåˆ°CSVæ–‡ä»¶...")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    # 1. ä¿å­˜æ±‡æ€»CSVæ–‡ä»¶
    summary_data = []
    
    for i, result in enumerate(results):
        if result is None:
            continue
            
        # å–å‰168å°æ—¶çš„æ•°æ®ï¼ˆ7å¤©ï¼‰
        y_true = result['y_true'][:168].flatten()
        y_pred = result['y_pred'][:168].flatten()
        
        # ç¡®ä¿é•¿åº¦ä¸€è‡´
        min_len = min(len(y_true), len(y_pred))
        y_true = y_true[:min_len]
        y_pred = y_pred[:min_len]
        
        # åˆ›å»ºæ—¶é—´åºåˆ—æ•°æ®
        for j in range(min_len):
            summary_data.append({
                'experiment_id': i + 1,
                'model': result['model_name'],
                'scenario': result['scenario'],
                'lookback': result['lookback'],
                'te': result['te'],
                'complexity': result['complexity'],
                'timestep': j,
                'ground_truth': y_true[j],
                'prediction': y_pred[j],
                'config_file': os.path.basename(result['config_path'])
            })
    
    # ä¿å­˜æ±‡æ€»CSV
    summary_df = pd.DataFrame(summary_data)
    summary_path = os.path.join(output_dir, 'all_predictions_summary.csv')
    summary_df.to_csv(summary_path, index=False)
    print(f"âœ… æ±‡æ€»CSVå·²ä¿å­˜: {summary_path}")
    
    # 2. æŒ‰åœºæ™¯ä¿å­˜CSVæ–‡ä»¶
    scenarios = ['PV', 'PV+NWP', 'PV+NWP+', 'PV+HW', 'NWP', 'NWP+']
    
    for scenario in scenarios:
        scenario_data = []
        
        for i, result in enumerate(results):
            if result is None or result['scenario'] != scenario:
                continue
                
            # å–å‰168å°æ—¶çš„æ•°æ®
            y_true = result['y_true'][:168].flatten()
            y_pred = result['y_pred'][:168].flatten()
            
            min_len = min(len(y_true), len(y_pred))
            y_true = y_true[:min_len]
            y_pred = y_pred[:min_len]
            
            # åˆ›å»ºæ—¶é—´åºåˆ—æ•°æ®
            for j in range(min_len):
                scenario_data.append({
                    'experiment_id': i + 1,
                    'model': result['model_name'],
                    'lookback': result['lookback'],
                    'te': result['te'],
                    'complexity': result['complexity'],
                    'timestep': j,
                    'ground_truth': y_true[j],
                    'prediction': y_pred[j],
                    'config_file': os.path.basename(result['config_path'])
                })
        
        if scenario_data:
            scenario_df = pd.DataFrame(scenario_data)
            scenario_path = os.path.join(output_dir, f'{scenario}_predictions.csv')
            scenario_df.to_csv(scenario_path, index=False)
            print(f"âœ… {scenario} CSVå·²ä¿å­˜: {scenario_path}")
    
    # 3. æŒ‰æ¨¡å‹ä¿å­˜CSVæ–‡ä»¶
    models = ['LSTM', 'GRU', 'TCN', 'Transformer', 'RF', 'XGB', 'LGBM', 'Linear', 'LSR']
    
    for model in models:
        model_data = []
        
        for i, result in enumerate(results):
            if result is None or result['model_name'] != model:
                continue
                
            # å–å‰168å°æ—¶çš„æ•°æ®
            y_true = result['y_true'][:168].flatten()
            y_pred = result['y_pred'][:168].flatten()
            
            min_len = min(len(y_true), len(y_pred))
            y_true = y_true[:min_len]
            y_pred = y_pred[:min_len]
            
            # åˆ›å»ºæ—¶é—´åºåˆ—æ•°æ®
            for j in range(min_len):
                model_data.append({
                    'experiment_id': i + 1,
                    'scenario': result['scenario'],
                    'lookback': result['lookback'],
                    'te': result['te'],
                    'complexity': result['complexity'],
                    'timestep': j,
                    'ground_truth': y_true[j],
                    'prediction': y_pred[j],
                    'config_file': os.path.basename(result['config_path'])
                })
        
        if model_data:
            model_df = pd.DataFrame(model_data)
            model_path = os.path.join(output_dir, f'{model}_predictions.csv')
            model_df.to_csv(model_path, index=False)
            print(f"âœ… {model} CSVå·²ä¿å­˜: {model_path}")
    
    # 4. ä¿å­˜å®éªŒé…ç½®æ±‡æ€»
    config_summary = []
    
    for i, result in enumerate(results):
        if result is None:
            continue
            
        config_summary.append({
            'experiment_id': i + 1,
            'model': result['model_name'],
            'scenario': result['scenario'],
            'lookback': result['lookback'],
            'te': result['te'],
            'complexity': result['complexity'],
            'config_file': os.path.basename(result['config_path']),
            'data_points': len(result['y_true'][:168].flatten())
        })
    
    config_df = pd.DataFrame(config_summary)
    config_path = os.path.join(output_dir, 'experiment_configs.csv')
    config_df.to_csv(config_path, index=False)
    print(f"âœ… å®éªŒé…ç½®æ±‡æ€»å·²ä¿å­˜: {config_path}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ ä¿å­˜340ä¸ªç»„åˆçš„é¢„æµ‹ç»“æœ...")
    
    # å‚æ•°è®¾ç½®
    project_id = 1140  # ä½¿ç”¨1140é¡¹ç›®çš„æ•°æ®
    config_dir = "config/ablation"
    
    # åŠ è½½æ•°æ®
    df = load_and_prepare_data(project_id)
    if df is None:
        print("âŒ æ— æ³•åŠ è½½æ•°æ®ï¼Œé€€å‡º")
        return
    
    # è·å–æ‰€æœ‰é…ç½®æ–‡ä»¶
    config_files = []
    for file in os.listdir(config_dir):
        if file.endswith('.yaml'):
            config_files.append(os.path.join(config_dir, file))
    
    print(f"ğŸ“Š æ‰¾åˆ° {len(config_files)} ä¸ªé…ç½®æ–‡ä»¶")
    
    # å­˜å‚¨ç»“æœ
    results = []
    
    # è®­ç»ƒæ‰€æœ‰æ¨¡å‹
    for i, config_path in enumerate(config_files):
        print(f"\n--- å¤„ç†é…ç½®æ–‡ä»¶ {i+1}/{len(config_files)}: {os.path.basename(config_path)} ---")
        
        result = train_and_predict_single_model(df, config_path)
        results.append(result)
    
    # ä¿å­˜ç»“æœ
    output_dir = '340_predictions_results'
    save_predictions_to_csv(results, output_dir)
    
    print(f"\nâœ… æ‰€æœ‰é¢„æµ‹ç»“æœä¿å­˜å®Œæˆï¼")
    print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {os.path.abspath(output_dir)}")
    
    # åˆ—å‡ºç”Ÿæˆçš„æ–‡ä»¶
    files = os.listdir(output_dir)
    files.sort()
    print(f"\nğŸ“‹ ç”Ÿæˆçš„æ–‡ä»¶åˆ—è¡¨:")
    for i, file in enumerate(files, 1):
        print(f"{i:2d}. {file}")

if __name__ == "__main__":
    main()
