#!/usr/bin/env python3
"""
ç»˜åˆ¶171ã€172ã€186é¡¹ç›®åœ¨72å°æ—¶ã€no time encodingã€low complexityã€PV+NWP+é…ç½®ä¸‹
7ä¸ªæ¨¡å‹ï¼ˆé™¤äº†LSRï¼‰çš„ground truthå’Œé¢„æµ‹å€¼å¯¹æ¯”å›¾
"""

import os
import sys
import yaml
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append('.')

from data.data_utils import (
    load_raw_data,
    preprocess_features,
    create_sliding_windows,
    split_data
)
from train.train_dl import train_dl_model
from train.train_ml import train_ml_model
from models.rnn_models import LSTM, GRU
from models.tcn import TCNModel
from models.transformer import Transformer
from models.ml_models import train_rf, train_xgb, train_lgbm

def load_config(project_id, model_name):
    """åŠ è½½æŒ‡å®šé¡¹ç›®çš„é…ç½®æ–‡ä»¶"""
    config_path = f"config/projects/{project_id}/{model_name}_low_PV_plus_NWP_plus_72h_noTE.yaml"
    
    if not os.path.exists(config_path):
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        return None
    
    with open(config_path, 'r') as f:
        config = yaml.safe_load(f)
    
    return config

def load_test_data(project_id):
    """åŠ è½½æµ‹è¯•æ•°æ®"""
    data_path = f"data/Plant_{project_id}.csv"
    
    if not os.path.exists(data_path):
        print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_path}")
        return None
    
    # åŠ è½½åŸå§‹æ•°æ®
    df = load_raw_data(data_path)
    print(f"ğŸ“Š é¡¹ç›® {project_id} æ•°æ®åŠ è½½å®Œæˆ: {len(df)} è¡Œ")
    
    return df

def prepare_data(df, config):
    """å‡†å¤‡è®­ç»ƒæ•°æ®"""
    # é¢„å¤„ç†ç‰¹å¾
    df_clean, hist_feats, fcst_feats, scaler_hist, scaler_fcst, scaler_target = preprocess_features(df, config)
    
    # åˆ›å»ºæ»‘åŠ¨çª—å£
    X_hist, X_fcst, y, hours, dates = create_sliding_windows(
        df_clean, 
        config['past_hours'], 
        config['future_hours'], 
        hist_feats, 
        fcst_feats, 
        no_hist_power=not config.get('use_pv', True)
    )
    
    # åˆ†å‰²æ•°æ®
    Xh_tr, Xf_tr, y_tr, hrs_tr, dates_tr, \
    Xh_va, Xf_va, y_va, hrs_va, dates_va, \
    Xh_te, Xf_te, y_te, hrs_te, dates_te = split_data(
        X_hist, X_fcst, y, hours, dates,
        train_ratio=config["train_ratio"],
        val_ratio=config["val_ratio"]
    )
    
    return (Xh_tr, Xf_tr, y_tr, hrs_tr, dates_tr,
            Xh_va, Xf_va, y_va, hrs_va, dates_va,
            Xh_te, Xf_te, y_te, hrs_te, dates_te), (scaler_hist, scaler_fcst, scaler_target)

def train_model(config, train_data, val_data, test_data, scalers, model_name):
    """è®­ç»ƒæŒ‡å®šæ¨¡å‹"""
    print(f"ğŸš€ å¼€å§‹è®­ç»ƒ {model_name} æ¨¡å‹...")
    
    try:
        if model_name in ['LSTM', 'GRU', 'TCN', 'Transformer']:
            # æ·±åº¦å­¦ä¹ æ¨¡å‹
            model, metrics = train_dl_model(config, train_data, val_data, test_data, scalers)
        else:
            # æœºå™¨å­¦ä¹ æ¨¡å‹
            Xh_tr, Xf_tr, y_tr, _, _ = train_data
            Xh_te, Xf_te, y_te, _, _ = test_data
            scaler_hist, scaler_fcst, scaler_target = scalers
            
            # å‡†å¤‡MLæ¨¡å‹è¾“å…¥
            if Xf_tr is not None:
                X_tr = np.concatenate([Xh_tr.reshape(Xh_tr.shape[0], -1), Xf_tr.reshape(Xf_tr.shape[0], -1)], axis=1)
                X_te = np.concatenate([Xh_te.reshape(Xh_te.shape[0], -1), Xf_te.reshape(Xf_te.shape[0], -1)], axis=1)
            else:
                X_tr = Xh_tr.reshape(Xh_tr.shape[0], -1)
                X_te = Xh_te.reshape(Xh_te.shape[0], -1)
            
            # è®­ç»ƒæ¨¡å‹
            if model_name == 'RF':
                model = train_rf(X_tr, y_tr, config['model_params']['low'])
            elif model_name == 'XGB':
                model = train_xgb(X_tr, y_tr, config['model_params']['low'])
            elif model_name == 'LGBM':
                model = train_lgbm(X_tr, y_tr, config['model_params']['low'])
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹: {model_name}")
            
            # é¢„æµ‹
            y_pred = model.predict(X_te)
            metrics = {'mse': np.mean((y_te - y_pred) ** 2)}
        
        print(f"âœ… {model_name} æ¨¡å‹è®­ç»ƒå®Œæˆ")
        return model, metrics
        
    except Exception as e:
        print(f"âŒ {model_name} æ¨¡å‹è®­ç»ƒå¤±è´¥: {e}")
        return None, None

def predict_test_data(model, test_data, scalers, model_name, config):
    """é¢„æµ‹æµ‹è¯•æ•°æ®"""
    Xh_te, Xf_te, y_te, hrs_te, dates_te = test_data
    scaler_hist, scaler_fcst, scaler_target = scalers
    
    if model_name in ['LSTM', 'GRU', 'TCN', 'Transformer']:
        # æ·±åº¦å­¦ä¹ æ¨¡å‹é¢„æµ‹
        model.eval()
        with torch.no_grad():
            # è½¬æ¢ä¸ºtensor
            Xh_tensor = torch.FloatTensor(Xh_te)
            Xf_tensor = torch.FloatTensor(Xf_te) if Xf_te is not None else None
            
            # é¢„æµ‹
            if Xf_tensor is not None:
                y_pred = model(Xh_tensor, Xf_tensor)
            else:
                y_pred = model(Xh_tensor)
            
            y_pred = y_pred.cpu().numpy()
    else:
        # æœºå™¨å­¦ä¹ æ¨¡å‹é¢„æµ‹
        if Xf_te is not None:
            X_te = np.concatenate([Xh_te.reshape(Xh_te.shape[0], -1), Xf_te.reshape(Xf_te.shape[0], -1)], axis=1)
        else:
            X_te = Xh_te.reshape(Xh_te.shape[0], -1)
        
        y_pred = model.predict(X_te)
    
    # åæ ‡å‡†åŒ–
    if scaler_target is not None:
        y_te_orig = scaler_target.inverse_transform(y_te)
        y_pred_orig = scaler_target.inverse_transform(y_pred)
    else:
        y_te_orig = y_te
        y_pred_orig = y_pred
    
    return y_te_orig, y_pred_orig, dates_te

def plot_model_comparison(project_id, models_to_plot):
    """ç»˜åˆ¶æ¨¡å‹å¯¹æ¯”å›¾"""
    print(f"ğŸ¨ å¼€å§‹ç»˜åˆ¶é¡¹ç›® {project_id} çš„æ¨¡å‹å¯¹æ¯”å›¾...")
    
    # åŠ è½½æ•°æ®
    df = load_test_data(project_id)
    if df is None:
        return
    
    # åˆ›å»ºå›¾å½¢
    fig, axes = plt.subplots(2, 4, figsize=(20, 10))
    axes = axes.flatten()
    
    # æ¨¡å‹åç§°æ˜ å°„
    model_names = {
        'LSTM': 'LSTM',
        'GRU': 'GRU', 
        'TCN': 'TCN',
        'Transformer': 'Transformer',
        'RF': 'Random Forest',
        'XGB': 'XGBoost',
        'LGBM': 'LightGBM'
    }
    
    for i, model_name in enumerate(models_to_plot):
        print(f"ğŸ“Š å¤„ç†æ¨¡å‹: {model_name}")
        
        # åŠ è½½é…ç½®
        config = load_config(project_id, model_name)
        if config is None:
            continue
        
        # å‡†å¤‡æ•°æ®
        data_splits, scalers = prepare_data(df, config)
        train_data, val_data, test_data = data_splits[0:3], data_splits[3:6], data_splits[6:9]
        
        # è®­ç»ƒæ¨¡å‹
        model, metrics = train_model(config, train_data, val_data, test_data, scalers, model_name)
        if model is None:
            continue
        
        # é¢„æµ‹æµ‹è¯•æ•°æ®
        y_te_orig, y_pred_orig, dates_te = predict_test_data(model, test_data, scalers, model_name, config)
        
        # å–å‰3å¤©çš„æ•°æ®ï¼ˆ72å°æ—¶ï¼‰
        n_samples = min(72, len(y_te_orig))
        y_true_plot = y_te_orig[:n_samples].flatten()
        y_pred_plot = y_pred_orig[:n_samples].flatten()
        
        # ç»˜åˆ¶
        ax = axes[i]
        timesteps = range(len(y_true_plot))
        
        ax.plot(timesteps, y_true_plot, 'gray', linewidth=2, label='Ground Truth', alpha=0.8)
        ax.plot(timesteps, y_pred_plot, 'red', linewidth=2, label=f'{model_names[model_name]}', alpha=0.8)
        
        ax.set_title(f'{model_names[model_name]}', fontsize=12, fontweight='bold')
        ax.set_xlabel('Timestep', fontsize=10)
        ax.set_ylabel('Capacity Factor', fontsize=10)
        ax.legend(fontsize=9)
        ax.grid(True, alpha=0.3)
        ax.set_ylim(0, 1.0)
        
        # è®¡ç®—å¹¶æ˜¾ç¤ºRMSE
        rmse = np.sqrt(np.mean((y_true_plot - y_pred_plot) ** 2))
        ax.text(0.02, 0.98, f'RMSE: {rmse:.4f}', transform=ax.transAxes, 
                verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))
    
    # éšè—å¤šä½™çš„å­å›¾
    for i in range(len(models_to_plot), len(axes)):
        axes[i].set_visible(False)
    
    plt.tight_layout()
    plt.suptitle(f'Project {project_id}: Day-ahead Forecasting Results (72h, noTE, low, PV+NWP+)', 
                 fontsize=16, fontweight='bold', y=0.98)
    
    # ä¿å­˜å›¾ç‰‡
    output_path = f'project_{project_id}_model_comparison.png'
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"ğŸ’¾ å›¾ç‰‡å·²ä¿å­˜: {output_path}")
    
    plt.show()

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹ç»˜åˆ¶æ¨¡å‹å¯¹æ¯”å›¾...")
    
    # è¦ç»˜åˆ¶çš„é¡¹ç›®
    projects = [171, 172, 186]
    
    # è¦ç»˜åˆ¶çš„æ¨¡å‹ï¼ˆé™¤äº†LSRï¼‰
    models_to_plot = ['LSTM', 'GRU', 'TCN', 'Transformer', 'RF', 'XGB', 'LGBM']
    
    for project_id in projects:
        print(f"\n{'='*50}")
        print(f"ğŸ“Š å¤„ç†é¡¹ç›® {project_id}")
        print(f"{'='*50}")
        
        try:
            plot_model_comparison(project_id, models_to_plot)
        except Exception as e:
            print(f"âŒ é¡¹ç›® {project_id} å¤„ç†å¤±è´¥: {e}")
            continue
    
    print("\nâœ… æ‰€æœ‰é¡¹ç›®å¤„ç†å®Œæˆï¼")

if __name__ == "__main__":
    main()
