#!/usr/bin/env python3
"""
Colab GPUç‰ˆæœ¬å…¨å‚æ•°ç»„åˆå®éªŒè„šæœ¬
æ”¯æŒæ–­ç‚¹ç»­ä¼ å’ŒGPUåŠ é€Ÿçš„RF/GBR
"""

import os
import subprocess
import sys
import time
import glob
import pandas as pd
from datetime import datetime
import matplotlib.pyplot as plt
import seaborn as sns

def setup_gpu_environment():
    """è®¾ç½®GPUç¯å¢ƒ"""
    print("ğŸ”§ è®¾ç½®GPUç¯å¢ƒ...")
    
    # å®‰è£…cuML (GPUç‰ˆæœ¬çš„RF/GBR)
    print("ğŸ“¦ å®‰è£…cuML...")
    try:
        import cuml
        print(f"âœ… cuMLå·²å®‰è£…ï¼Œç‰ˆæœ¬: {cuml.__version__}")
    except ImportError:
        print("ğŸ“¥ å®‰è£…cuML...")
        result = subprocess.run([
            sys.executable, '-m', 'pip', 'install', 
            'cuml-cu11', '--extra-index-url=https://pypi.nvidia.com'
        ], capture_output=True, text=True)
        
        if result.returncode == 0:
            print("âœ… cuMLå®‰è£…æˆåŠŸ")
        else:
            print("âŒ cuMLå®‰è£…å¤±è´¥ï¼Œå°†ä½¿ç”¨CPUç‰ˆæœ¬")
            print("é”™è¯¯:", result.stderr)
    
    # è®¾ç½®A100ä¼˜åŒ–
    try:
        import torch
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.allow_tf32 = True
        torch.backends.cudnn.benchmark = True
        torch.cuda.set_per_process_memory_fraction(0.9)
        print("âœ… A100ä¼˜åŒ–è®¾ç½®å®Œæˆ")
    except ImportError:
        print("âš ï¸ PyTorchæœªå®‰è£…ï¼Œè·³è¿‡A100ä¼˜åŒ–")

def check_existing_results():
    """æ£€æŸ¥ç°æœ‰ç»“æœ"""
    print("ğŸ” æ£€æŸ¥ç°æœ‰ç»“æœ...")
    
    # æŸ¥æ‰¾æ‰€æœ‰summary.csvæ–‡ä»¶
    summary_files = glob.glob('result/**/summary.csv', recursive=True)
    
    if not summary_files:
        print("ğŸ“ æœªæ‰¾åˆ°ç°æœ‰ç»“æœï¼Œå°†ä»å¤´å¼€å§‹")
        return set()
    
    # è¯»å–ç°æœ‰ç»“æœ
    existing_experiments = set()
    for file in summary_files:
        try:
            df = pd.read_csv(file)
            if not df.empty:
                # åˆ›å»ºå®éªŒæ ‡è¯†
                exp_id = f"{df.iloc[0]['model']}_{df.iloc[0]['use_hist_weather']}_{df.iloc[0]['use_forecast']}_{df.iloc[0].get('model_complexity', 'medium')}"
                existing_experiments.add(exp_id)
        except Exception as e:
            print(f"âš ï¸ è¯»å–ç»“æœæ–‡ä»¶å¤±è´¥ {file}: {e}")
    
    print(f"ğŸ“Š æ‰¾åˆ° {len(existing_experiments)} ä¸ªå·²å®Œæˆå®éªŒ")
    return existing_experiments

def get_experiment_id(model, hist_weather, forecast, complexity, past_days):
    """ç”Ÿæˆå®éªŒæ ‡è¯†"""
    return f"{model}_{hist_weather}_{forecast}_{complexity}_{past_days}"

def run_experiment(model, hist_weather, forecast, complexity, past_days, description):
    """è¿è¡Œå•ä¸ªå®éªŒ"""
    print(f"\nğŸš€ {description}")
    print("-" * 60)
    
    cmd = [
        sys.executable, 'main.py',
        '--config', 'config/default.yaml',
        '--model', model,
        '--use_hist_weather', hist_weather,
        '--use_forecast', forecast,
        '--model_complexity', complexity,
        '--past_days', str(past_days)
    ]
    
    start_time = time.time()
    result = subprocess.run(cmd, capture_output=True, text=True)
    end_time = time.time()
    
    if result.returncode == 0:
        print(f"âœ… {description} å®Œæˆ (è€—æ—¶: {end_time - start_time:.2f}ç§’)")
        return True
    else:
        print(f"âŒ {description} å¤±è´¥")
        print("é”™è¯¯:", result.stderr)
        return False

def run_gpu_experiments():
    """è¿è¡ŒGPUç‰ˆæœ¬å®éªŒ"""
    print("\nğŸ”¬ GPUç‰ˆæœ¬å…¨å‚æ•°ç»„åˆå®éªŒ")
    print("=" * 80)
    
    # æ¨¡å‹åˆ—è¡¨ (å·²ç§»é™¤GBR)
    models = ['Transformer', 'LSTM', 'GRU', 'TCN', 'RF', 'XGB', 'LGBM']
    
    # ç‰¹å¾ç»„åˆ
    feature_configs = [
        ('hist_only', 'true', 'false'),
        ('fcst_only', 'false', 'true'),
        ('both', 'true', 'true'),
        ('none', 'false', 'false')
    ]
    
    # å¤æ‚åº¦ç»„åˆ
    complexities = ['low', 'medium', 'high']
    
    # æ—¶é—´çª—å£ç»„åˆ
    past_days_options = [1, 3, 7]
    
    # æ£€æŸ¥ç°æœ‰ç»“æœ
    existing_experiments = check_existing_results()
    
    # ç»Ÿè®¡ä¿¡æ¯
    total_experiments = len(models) * len(feature_configs) * len(complexities) * len(past_days_options)
    completed = 0
    failed = 0
    skipped = 0
    
    print(f"ğŸ“Š æ€»å®éªŒæ•°: {total_experiments}")
    print(f"   å·²å®Œæˆ: {len(existing_experiments)}")
    print(f"   å¾…å®Œæˆ: {total_experiments - len(existing_experiments)}")
    
    start_time = time.time()
    
    for model in models:
        print(f"\nğŸ¯ å¼€å§‹ {model} æ¨¡å‹å®éªŒ")
        print("-" * 60)
        
        for feat_desc, hist_weather, forecast in feature_configs:
            print(f"\nğŸ“‹ ç‰¹å¾ç»„åˆ: {feat_desc}")
            
            for complexity in complexities:
                for past_days in past_days_options:
                    exp_id = get_experiment_id(model, hist_weather, forecast, complexity, past_days)
                    description = f"{model} - {feat_desc} - {complexity} - {past_days}å¤©"
                    
                    if exp_id in existing_experiments:
                        print(f"â­ï¸ {description} - è·³è¿‡ (å·²å®Œæˆ)")
                        skipped += 1
                        continue
                    
                    if run_experiment(model, hist_weather, forecast, complexity, past_days, description):
                        completed += 1
                    else:
                        failed += 1
                    
                    # æ˜¾ç¤ºè¿›åº¦
                    total_done = completed + failed + skipped
                    progress = total_done / total_experiments * 100
                    elapsed = time.time() - start_time
                    eta = elapsed / total_done * (total_experiments - total_done) if total_done > 0 else 0
                    
                    print(f"ğŸ“ˆ è¿›åº¦: {total_done}/{total_experiments} ({progress:.1f}%)")
                    print(f"â±ï¸  å·²ç”¨æ—¶é—´: {elapsed/60:.1f}åˆ†é’Ÿ, é¢„è®¡å‰©ä½™: {eta/60:.1f}åˆ†é’Ÿ")
    
    end_time = time.time()
    total_time = end_time - start_time
    
    print(f"\nğŸ‰ GPUç‰ˆæœ¬å®éªŒå®Œæˆï¼")
    print(f"ğŸ“Š æˆåŠŸ: {completed}")
    print(f"âŒ å¤±è´¥: {failed}")
    print(f"â­ï¸ è·³è¿‡: {skipped}")
    print(f"â±ï¸  æ€»è€—æ—¶: {total_time/60:.1f}åˆ†é’Ÿ")
    
    return completed, failed, skipped

def analyze_results():
    """åˆ†æç»“æœ"""
    print("\nğŸ“Š åˆ†æç»“æœ...")
    
    try:
        # æ£€æŸ¥Driveç›®å½•
        drive_dir = '/content/drive/MyDrive/Solar PV electricity/results'
        if os.path.exists(drive_dir):
            result_dir = drive_dir
        else:
            result_dir = 'result'
        
        # æŸ¥æ‰¾æ‰€æœ‰summary.csvæ–‡ä»¶
        summary_files = glob.glob(f'{result_dir}/**/summary.csv', recursive=True)
        
        if not summary_files:
            print("âŒ æœªæ‰¾åˆ°ç»“æœæ–‡ä»¶")
            return
        
        print(f"âœ… æ‰¾åˆ° {len(summary_files)} ä¸ªç»“æœæ–‡ä»¶")
        
        # åˆå¹¶æ‰€æœ‰ç»“æœ
        all_results = []
        for file in summary_files:
            try:
                df = pd.read_csv(file)
                all_results.append(df)
            except Exception as e:
                print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥ {file}: {e}")
        
        if not all_results:
            print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„ç»“æœæ–‡ä»¶")
            return
        
        # åˆå¹¶ç»“æœ
        combined_df = pd.concat(all_results, ignore_index=True)
        
        # ä¿å­˜åˆå¹¶ç»“æœ
        combined_df.to_csv(f'{result_dir}/all_experiments_results.csv', index=False)
        print(f"âœ… åˆå¹¶ç»“æœä¿å­˜åˆ° {result_dir}/all_experiments_results.csv")
        
        # åˆ›å»ºå¯è§†åŒ–
        create_visualizations(combined_df)
        
        # æ˜¾ç¤ºç»Ÿè®¡ç»“æœ
        show_statistics(combined_df)
        
    except Exception as e:
        print(f"âŒ åˆ†æç»“æœæ—¶å‡ºé”™: {e}")

def create_visualizations(df):
    """åˆ›å»ºå¯è§†åŒ–å›¾è¡¨"""
    print("\nğŸ“Š åˆ›å»ºå¯è§†åŒ–å›¾è¡¨...")
    
    plt.style.use('default')
    fig, axes = plt.subplots(2, 3, figsize=(20, 12))
    
    # 1. æ¨¡å‹æ€§èƒ½å¯¹æ¯”
    ax1 = axes[0, 0]
    model_perf = df.groupby('model')['rmse'].mean().sort_values()
    model_perf.plot(kind='bar', ax=ax1, color='skyblue')
    ax1.set_title('Model Performance (RMSE)', fontsize=12)
    ax1.set_ylabel('RMSE')
    ax1.tick_params(axis='x', rotation=45)
    
    # 2. ç‰¹å¾ç»„åˆå½±å“
    ax2 = axes[0, 1]
    feature_perf = df.groupby(['use_hist_weather', 'use_forecast'])['rmse'].mean()
    feature_perf.plot(kind='bar', ax=ax2, color='lightcoral')
    ax2.set_title('Feature Combination Impact', fontsize=12)
    ax2.set_ylabel('RMSE')
    ax2.tick_params(axis='x', rotation=45)
    
    # 3. å¤æ‚åº¦å½±å“
    ax3 = axes[0, 2]
    complexity_perf = df.groupby('model_complexity')['rmse'].mean()
    complexity_perf.plot(kind='bar', ax=ax3, color='lightgreen')
    ax3.set_title('Complexity Impact', fontsize=12)
    ax3.set_ylabel('RMSE')
    ax3.tick_params(axis='x', rotation=45)
    
    # 4. è®­ç»ƒæ—¶é—´å¯¹æ¯”
    ax4 = axes[1, 0]
    train_time = df.groupby('model')['train_time_sec'].mean().sort_values()
    train_time.plot(kind='bar', ax=ax4, color='orange')
    ax4.set_title('Training Time Comparison', fontsize=12)
    ax4.set_ylabel('Time (seconds)')
    ax4.tick_params(axis='x', rotation=45)
    
    # 5. å‚æ•°æ•°é‡å¯¹æ¯”
    ax5 = axes[1, 1]
    param_count = df.groupby('model')['param_count'].mean().sort_values()
    param_count.plot(kind='bar', ax=ax5, color='purple')
    ax5.set_title('Parameter Count Comparison', fontsize=12)
    ax5.set_ylabel('Parameters')
    ax5.tick_params(axis='x', rotation=45)
    
    # 6. æ€§èƒ½vsæ—¶é—´æ•£ç‚¹å›¾
    ax6 = axes[1, 2]
    scatter = ax6.scatter(df['train_time_sec'], df['rmse'], c=df['param_count'], cmap='viridis', alpha=0.7)
    ax6.set_xlabel('Training Time (s)')
    ax6.set_ylabel('RMSE')
    ax6.set_title('Performance vs Training Time')
    plt.colorbar(scatter, ax=ax6, label='Parameter Count')
    
    plt.tight_layout()
    # æ£€æŸ¥Driveç›®å½•
    drive_dir = '/content/drive/MyDrive/Solar PV electricity/results'
    if os.path.exists(drive_dir):
        result_dir = drive_dir
    else:
        result_dir = 'result'
    
    plt.savefig(f'{result_dir}/gpu_experiments_analysis.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    print(f"âœ… å¯è§†åŒ–å›¾è¡¨ä¿å­˜åˆ° {result_dir}/gpu_experiments_analysis.png")

def show_statistics(df):
    """æ˜¾ç¤ºç»Ÿè®¡ç»“æœ"""
    print("\n=== è¯¦ç»†ç»Ÿè®¡ç»“æœ ===")
    
    # æŒ‰æ¨¡å‹ç»Ÿè®¡
    print("\nğŸ“Š æŒ‰æ¨¡å‹ç»Ÿè®¡:")
    model_stats = df.groupby('model').agg({
        'test_loss': ['mean', 'std', 'min'],
        'rmse': ['mean', 'std', 'min'],
        'mae': ['mean', 'std', 'min'],
        'train_time_sec': ['mean', 'std'],
        'param_count': ['mean', 'std']
    }).round(4)
    print(model_stats)
    
    # æ‰¾å‡ºæœ€ä½³é…ç½®
    best_overall = df.loc[df['rmse'].idxmin()]
    print(f"\nğŸ† æœ€ä½³æ•´ä½“é…ç½®:")
    print(f"   æ¨¡å‹: {best_overall['model']}")
    print(f"   å†å²å¤©æ°”: {best_overall['use_hist_weather']}")
    print(f"   é¢„æµ‹å¤©æ°”: {best_overall['use_forecast']}")
    print(f"   å¤æ‚åº¦: {best_overall.get('model_complexity', 'N/A')}")
    print(f"   RMSE: {best_overall['rmse']:.4f}")
    print(f"   MAE: {best_overall['mae']:.4f}")
    print(f"   è®­ç»ƒæ—¶é—´: {best_overall['train_time_sec']:.2f}ç§’")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ SolarPV-Prediction GPUç‰ˆæœ¬å…¨å‚æ•°ç»„åˆå®éªŒ")
    print(f"â° å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 80)
    
    # è®¾ç½®GPUç¯å¢ƒ
    setup_gpu_environment()
    
    # æ£€æŸ¥Driveç›®å½•å¹¶ä¿®æ”¹é…ç½®
    drive_dir = '/content/drive/MyDrive/Solar PV electricity/results'
    if os.path.exists(drive_dir):
        print(f"âœ… Driveç›®å½•å­˜åœ¨: {drive_dir}")
        # ä¿®æ”¹é…ç½®æ–‡ä»¶ï¼Œä¿å­˜åˆ°Driveç›®å½•
        import yaml
        with open('config/default.yaml', 'r') as f:
            config = yaml.safe_load(f)
        config['save_dir'] = drive_dir
        with open('config/default.yaml', 'w') as f:
            yaml.dump(config, f, default_flow_style=False)
        print(f"âœ… é…ç½®å·²æ›´æ–°ï¼Œç»“æœå°†ä¿å­˜åˆ°: {drive_dir}")
    else:
        print(f"âš ï¸ Driveç›®å½•ä¸å­˜åœ¨: {drive_dir}")
        print("ğŸ’¡ è¯·ç¡®ä¿å·²æŒ‚è½½Google Drive")
        # åˆ›å»ºæœ¬åœ°ç»“æœç›®å½•
        if not os.path.exists('result'):
            os.makedirs('result')
            print("âœ… åˆ›å»ºæœ¬åœ°resultç›®å½•")
    
    # æ£€æŸ¥æ•°æ®æ–‡ä»¶
    if not os.path.exists('data/Project1033.csv'):
        print("âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: data/Project1033.csv")
        return
    
    print("âœ… æ•°æ®æ–‡ä»¶æ£€æŸ¥é€šè¿‡")
    
    # è¿è¡ŒGPUå®éªŒ
    completed, failed, skipped = run_gpu_experiments()
    
    # åˆ†æç»“æœ
    analyze_results()
    
    print(f"\nğŸ‰ æ‰€æœ‰å®éªŒå®Œæˆï¼")
    print(f"ğŸ“Š æˆåŠŸ: {completed}")
    print(f"âŒ å¤±è´¥: {failed}")
    print(f"â­ï¸ è·³è¿‡: {skipped}")
    # æ£€æŸ¥Driveç›®å½•
    drive_dir = '/content/drive/MyDrive/Solar PV electricity/results'
    if os.path.exists(drive_dir):
        result_dir = drive_dir
        print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {result_dir} (Google Drive)")
    else:
        result_dir = 'result'
        print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {result_dir} (æœ¬åœ°)")
    
    print(f"ğŸ“Š åˆå¹¶ç»“æœ: {result_dir}/all_experiments_results.csv")
    print(f"ğŸ“Š å¯è§†åŒ–: {result_dir}/gpu_experiments_analysis.png")

if __name__ == "__main__":
    main()
