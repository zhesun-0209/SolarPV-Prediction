#!/usr/bin/env python3
"""
Colabæ‰¹é‡å®éªŒè„šæœ¬ - æ”¯æŒ100ä¸ªé¡¹ç›®çš„å…¨é‡å®éªŒ
æ¯ä¸ªé¡¹ç›®è¿è¡Œ340ä¸ªå®éªŒï¼Œç»“æœä¿å­˜åˆ°Google Drive
"""

import os
import sys
import subprocess
import time
import yaml
import glob
import pandas as pd
from datetime import datetime
from utils.drive_utils import mount_drive, save_project_results_to_drive, list_drive_results

def get_available_projects(data_dir: str = "data") -> list:
    """è·å–å¯ç”¨çš„é¡¹ç›®åˆ—è¡¨"""
    csv_files = glob.glob(os.path.join(data_dir, "Project*.csv"))
    projects = []
    
    for csv_file in csv_files:
        filename = os.path.basename(csv_file)
        # æå–é¡¹ç›®IDï¼Œä¾‹å¦‚ Project1140.csv -> 1140
        if filename.startswith("Project") and filename.endswith(".csv"):
            project_id = filename[7:-4]  # å»æ‰"Project"å’Œ".csv"
            projects.append(project_id)
    
    return sorted(projects)

def get_config_files(config_dir: str = "config/projects") -> list:
    """è·å–æ‰€æœ‰é…ç½®æ–‡ä»¶"""
    # æ‰«ææ‰€æœ‰é¡¹ç›®ç›®å½•ä¸‹çš„é…ç½®æ–‡ä»¶
    all_config_files = []
    
    # è·å–æ‰€æœ‰é¡¹ç›®ç›®å½•
    project_dirs = glob.glob(os.path.join(config_dir, "*"))
    project_dirs = [d for d in project_dirs if os.path.isdir(d)]
    
    for project_dir in project_dirs:
        yaml_files = glob.glob(os.path.join(project_dir, "*.yaml"))
        config_files = [f for f in yaml_files if not f.endswith("config_index.yaml")]
        all_config_files.extend(config_files)
    
    return sorted(all_config_files)

def run_project_experiments(project_id: str, all_config_files: list, data_dir: str = "data", 
                          save_to_drive: bool = True) -> dict:
    """
    è¿è¡Œå•ä¸ªé¡¹ç›®çš„æ‰€æœ‰å®éªŒ
    
    Args:
        project_id: é¡¹ç›®ID
        all_config_files: æ‰€æœ‰é…ç½®æ–‡ä»¶åˆ—è¡¨
        data_dir: æ•°æ®ç›®å½•
        results_dir: ç»“æœç›®å½•
        save_to_drive: æ˜¯å¦ä¿å­˜åˆ°Drive
        
    Returns:
        å®éªŒç»“æœç»Ÿè®¡
    """
    print(f"\n{'='*80}")
    print(f"ğŸš€ å¼€å§‹é¡¹ç›® {project_id} çš„å®éªŒ")
    print(f"{'='*80}")
    
    # æ£€æŸ¥æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    data_file = os.path.join(data_dir, f"Project{project_id}.csv")
    if not os.path.exists(data_file):
        print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_file}")
        return {'success': False, 'error': 'Data file not found'}
    
    # ç­›é€‰å‡ºå½“å‰é¡¹ç›®çš„é…ç½®æ–‡ä»¶
    project_config_files = []
    for config_file in all_config_files:
        if f"/{project_id}/" in config_file or f"\\{project_id}\\" in config_file:
            project_config_files.append(config_file)
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°é¡¹ç›®ä¸“ç”¨é…ç½®ï¼Œä½¿ç”¨é€šç”¨é…ç½®ï¼ˆå¦‚1140çš„é…ç½®ï¼‰
    if not project_config_files:
        print(f"âš ï¸ é¡¹ç›® {project_id} æ²¡æœ‰ä¸“ç”¨é…ç½®æ–‡ä»¶ï¼Œä½¿ç”¨é€šç”¨é…ç½®")
        # ä½¿ç”¨1140çš„é…ç½®ä½œä¸ºæ¨¡æ¿
        template_configs = [f for f in all_config_files if "/1140/" in f or "\\1140\\" in f]
        project_config_files = template_configs
    
    # ç¡¬ç¼–ç Driveä¿å­˜ç›®å½•ï¼Œåˆ é™¤æœ¬åœ°ä¿å­˜
    drive_save_dir = "/content/drive/MyDrive/Solar PV electricity/ablation results"
    os.makedirs(drive_save_dir, exist_ok=True)
    
    # ä¸ºé¡¹ç›®åˆ›å»ºåˆå§‹CSVæ–‡ä»¶
    csv_file_path = os.path.join(drive_save_dir, f"{project_id}_results.csv")
    if not os.path.exists(csv_file_path):
        print(f"ğŸ“„ åˆ›å»ºé¡¹ç›®CSVæ–‡ä»¶: {csv_file_path}")
        # åˆ›å»ºç©ºçš„CSVæ–‡ä»¶ï¼ŒåŒ…å«åˆ—å¤´
        import pandas as pd
        empty_df = pd.DataFrame(columns=[
            'model', 'use_pv', 'use_hist_weather', 'use_forecast', 'weather_category',
            'use_time_encoding', 'past_days', 'model_complexity', 'epochs', 'batch_size',
            'learning_rate', 'train_time_sec', 'inference_time_sec', 'param_count',
            'samples_count', 'best_epoch', 'final_lr', 'mse', 'rmse', 'mae', 'nrmse',
            'r_square', 'smape', 'gpu_memory_used'
        ])
        empty_df.to_csv(csv_file_path, index=False)
        print(f"âœ… é¡¹ç›®CSVæ–‡ä»¶å·²åˆ›å»º")
    else:
        print(f"ğŸ“„ é¡¹ç›®CSVæ–‡ä»¶å·²å­˜åœ¨: {csv_file_path}")
    
    # ç»Ÿè®¡ä¿¡æ¯
    stats = {
        'project_id': project_id,
        'total_experiments': len(project_config_files),
        'successful': 0,
        'failed': 0,
        'start_time': time.time(),
        'errors': []
    }
    
    print(f"ğŸ“Š é¡¹ç›® {project_id}: å°†è¿è¡Œ {len(project_config_files)} ä¸ªå®éªŒ")
    print(f"ğŸ“ ç»“æœä¿å­˜åˆ°: {drive_save_dir}")
    
    # è¿è¡Œæ¯ä¸ªå®éªŒ
    for i, config_file in enumerate(project_config_files, 1):
        print(f"\nğŸ”„ è¿›åº¦: {i}/{len(project_config_files)} - {os.path.basename(config_file)}")
        
        try:
            # ä¿®æ”¹é…ç½®æ–‡ä»¶ä¸­çš„æ•°æ®è·¯å¾„
            with open(config_file, 'r') as f:
                config = yaml.safe_load(f)
            
            print(f"ğŸ” è°ƒè¯•: åŸå§‹é…ç½®æ–‡ä»¶åŠ è½½å®Œæˆ")
            print(f"ğŸ” è°ƒè¯•: åŸå§‹config['train_params'] = {config.get('train_params', 'NOT_FOUND')}")
            
            # æ›´æ–°æ•°æ®è·¯å¾„å’Œplant_idï¼ˆsave_dirå·²åœ¨eval_utilsä¸­ç¡¬ç¼–ç ï¼‰
            config['data_path'] = data_file
            config['plant_id'] = project_id  # è®¾ç½®plant_id
            
            print(f"ğŸ” è°ƒè¯•: ä¿®æ”¹åconfig['train_params'] = {config.get('train_params', 'NOT_FOUND')}")
            print(f"ğŸ” è°ƒè¯•: ä¿®æ”¹åconfig['model'] = {config.get('model', 'NOT_FOUND')}")
            print(f"ğŸ” è°ƒè¯•: ä¿®æ”¹åconfig['model_params'] = {config.get('model_params', 'NOT_FOUND')}")
            
            # ä¿å­˜ä¸´æ—¶é…ç½®æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
            temp_dir = "/tmp/solarpv_configs"
            os.makedirs(temp_dir, exist_ok=True)
            temp_config_file = os.path.join(temp_dir, f"temp_{project_id}_{os.path.basename(config_file)}")
            with open(temp_config_file, 'w') as f:
                yaml.dump(config, f, default_flow_style=False, allow_unicode=True)
            
            # è¿è¡Œå®éªŒ
            start_time = time.time()
            result = subprocess.run([
                sys.executable, "main.py", "--config", temp_config_file
            ], capture_output=True, text=True, timeout=1800)  # 30åˆ†é’Ÿè¶…æ—¶
            
            # æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
            if "ğŸ” è°ƒè¯•" in result.stdout:
                print("ğŸ” å®éªŒè°ƒè¯•ä¿¡æ¯:")
                for line in result.stdout.split('\n'):
                    if "ğŸ” è°ƒè¯•" in line:
                        print(f"   {line}")
            
            # æ˜¾ç¤ºå®Œæ•´çš„æ ‡å‡†è¾“å‡ºï¼ˆç”¨äºè°ƒè¯•ï¼‰
            if "CSVç»“æœå·²æ›´æ–°" not in result.stdout and "ğŸ” è°ƒè¯•" not in result.stdout:
                print("ğŸ” å®Œæ•´æ ‡å‡†è¾“å‡º:")
                print(result.stdout[-1000:])  # æ˜¾ç¤ºæœ€å1000ä¸ªå­—ç¬¦
            
            # æ˜¾ç¤ºé”™è¯¯è¾“å‡ºï¼ˆå¦‚æœæœ‰ï¼‰
            if result.stderr:
                print("ğŸ” é”™è¯¯è¾“å‡º:")
                print(result.stderr[-500:])  # æ˜¾ç¤ºæœ€å500ä¸ªå­—ç¬¦
            
            duration = time.time() - start_time
            
            # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯ä¿¡æ¯ï¼ˆå³ä½¿è¿”å›ç ä¸º0ï¼‰
            has_error = "[ERROR]" in result.stdout or result.returncode != 0
            
            if not has_error and result.returncode == 0:
                stats['successful'] += 1
                print(f"âœ… å®éªŒæˆåŠŸ! ç”¨æ—¶: {duration:.1f}ç§’")
                
                # æå–ç»“æœæŒ‡æ ‡
                if "mse=" in result.stdout:
                    lines = result.stdout.split('\n')
                    for line in lines:
                        if "mse=" in line and "rmse=" in line and "mae=" in line:
                            print(f"ğŸ“Š ç»“æœ: {line.strip()}")
                            break
                
                # æ£€æŸ¥æ˜¯å¦æœ‰CSVä¿å­˜ä¿¡æ¯
                if "CSVç»“æœå·²æ›´æ–°" in result.stdout:
                    print("âœ… CSVç»“æœå·²ä¿å­˜")
                else:
                    print("âš ï¸ æœªçœ‹åˆ°CSVä¿å­˜ä¿¡æ¯")
                
                # ç¡¬ç¼–ç ä¿å­˜ç»“æœåˆ°CSVæ–‡ä»¶
                csv_file_path = os.path.join(drive_save_dir, f"{project_id}_results.csv")
                print(f"ğŸ”§ ç¡¬ç¼–ç ä¿å­˜ç»“æœåˆ°: {csv_file_path}")
                
                # ä»å®éªŒè¾“å‡ºä¸­æå–ç»“æœ
                result_line = None
                for line in result.stdout.split('\n'):
                    if "mse=" in line and "rmse=" in line and "mae=" in line and "r_square=" in line:
                        result_line = line
                        break
                
                if result_line:
                    # è§£æç»“æœ
                    import re
                    mse_match = re.search(r'mse=([0-9.]+)', result_line)
                    rmse_match = re.search(r'rmse=([0-9.]+)', result_line)
                    mae_match = re.search(r'mae=([0-9.]+)', result_line)
                    r_square_match = re.search(r'r_square=([0-9.]+)', result_line)
                    
                    if mse_match and rmse_match and mae_match and r_square_match:
                        # ä»é…ç½®æ–‡ä»¶åä¸­æå–æ›´å¤šä¿¡æ¯
                        config_filename = os.path.basename(config_file)
                        parts = config_filename.replace('.yaml', '').split('_')
                        
                        # è§£æé…ç½®æ–‡ä»¶å: GRU_high_NWP_24h_TE.yaml
                        model_name = parts[0] if len(parts) > 0 else config.get('model', 'Unknown')
                        complexity = parts[1] if len(parts) > 1 else config.get('model_complexity', 'low')
                        input_category = parts[2] if len(parts) > 2 else 'unknown'
                        lookback_hours = parts[3].replace('h', '') if len(parts) > 3 else '24'
                        time_encoding = parts[4] == 'TE' if len(parts) > 4 else config.get('use_time_encoding', False)
                        
                        # æ ¹æ®input_categoryç¡®å®šå…¶ä»–å‚æ•°
                        use_pv = input_category in ['PV', 'PV_plus_NWP', 'PV_plus_NWP_plus', 'PV_plus_HW']
                        use_hist_weather = input_category in ['PV_plus_HW']
                        use_forecast = input_category in ['PV_plus_NWP', 'PV_plus_NWP_plus', 'PV_plus_HW', 'NWP', 'NWP_plus']
                        
                        # åˆ›å»ºç»“æœè¡Œ
                        result_row = {
                            'model': model_name,
                            'use_pv': use_pv,
                            'use_hist_weather': use_hist_weather,
                            'use_forecast': use_forecast,
                            'weather_category': config.get('weather_category', 'all_weather'),
                            'use_time_encoding': time_encoding,
                            'past_days': config.get('past_days', 1),
                            'model_complexity': complexity,
                            'epochs': config.get('epochs', 50 if complexity == 'high' else 15),
                            'batch_size': config.get('train_params', {}).get('batch_size', 32),
                            'learning_rate': config.get('train_params', {}).get('learning_rate', 0.001),
                            'train_time_sec': round(duration, 4),
                            'inference_time_sec': 0.0,
                            'param_count': 0,
                            'samples_count': 0,
                            'best_epoch': 0,
                            'final_lr': 0.0,
                            'mse': float(mse_match.group(1)),
                            'rmse': float(rmse_match.group(1)),
                            'mae': float(mae_match.group(1)),
                            'nrmse': 0.0,
                            'r_square': float(r_square_match.group(1)),
                            'smape': 0.0,
                            'gpu_memory_used': 0
                        }
                        
                        # è¯»å–ç°æœ‰CSVæ–‡ä»¶
                        import pandas as pd
                        if os.path.exists(csv_file_path):
                            df = pd.read_csv(csv_file_path)
                        else:
                            df = pd.DataFrame()
                        
                        # æ·»åŠ æ–°è¡Œ
                        new_row_df = pd.DataFrame([result_row])
                        df = pd.concat([df, new_row_df], ignore_index=True)
                        
                        # ä¿å­˜CSVæ–‡ä»¶
                        df.to_csv(csv_file_path, index=False)
                        print(f"âœ… ç»“æœå·²ç¡¬ç¼–ç ä¿å­˜åˆ°CSVæ–‡ä»¶")
                        print(f"ğŸ“Š CSVæ–‡ä»¶å½“å‰è¡Œæ•°: {len(df)}")
                        print(f"ğŸ“Š æœ€æ–°å®éªŒ: {result_row['model']} - {result_row['mse']:.4f}")
                        print(f"ğŸ” è§£æçš„é…ç½®ä¿¡æ¯:")
                        print(f"   æ¨¡å‹: {result_row['model']}, å¤æ‚åº¦: {result_row['model_complexity']}")
                        print(f"   è¾“å…¥ç±»åˆ«: {input_category}, æ—¶é—´ç¼–ç : {result_row['use_time_encoding']}")
                        print(f"   PV: {result_row['use_pv']}, å†å²å¤©æ°”: {result_row['use_hist_weather']}, é¢„æµ‹å¤©æ°”: {result_row['use_forecast']}")
                    else:
                        print(f"âŒ æ— æ³•è§£æå®éªŒç»“æœ: {result_line}")
                else:
                    print(f"âŒ æœªæ‰¾åˆ°å®éªŒç»“æœè¡Œ")
            else:
                stats['failed'] += 1
                error_msg = f"è¿”å›ç : {result.returncode}, é”™è¯¯: {result.stderr[-200:]}"
                if "[ERROR]" in result.stdout:
                    # æå–é”™è¯¯ä¿¡æ¯
                    error_lines = [line for line in result.stdout.split('\n') if "[ERROR]" in line]
                    if error_lines:
                        error_msg = f"å®éªŒé”™è¯¯: {error_lines[-1]}"
                stats['errors'].append(error_msg)
                print(f"âŒ å®éªŒå¤±è´¥! {error_msg}")
                print(f"   æ ‡å‡†è¾“å‡º: {result.stdout[-500:]}")
                print(f"   é”™è¯¯è¾“å‡º: {result.stderr[-500:]}")
            
            # æ¸…ç†ä¸´æ—¶é…ç½®æ–‡ä»¶
            if os.path.exists(temp_config_file):
                os.remove(temp_config_file)
                
        except subprocess.TimeoutExpired:
            stats['failed'] += 1
            error_msg = "å®éªŒè¶…æ—¶ (30åˆ†é’Ÿ)"
            stats['errors'].append(error_msg)
            print(f"â° å®éªŒè¶…æ—¶: {error_msg}")
        except Exception as e:
            stats['failed'] += 1
            error_msg = f"å®éªŒå¼‚å¸¸: {str(e)}"
            stats['errors'].append(error_msg)
            print(f"ğŸ’¥ å®éªŒå¼‚å¸¸: {error_msg}")
    
    # è®¡ç®—æ€»ç”¨æ—¶
    stats['total_time'] = time.time() - stats['start_time']
    stats['success'] = stats['successful'] > 0
    
    # æ˜¾ç¤ºé¡¹ç›®ç»Ÿè®¡
    print(f"\nğŸ“Š é¡¹ç›® {project_id} å®Œæˆ!")
    print(f"   æ€»å®éªŒ: {stats['total_experiments']}")
    print(f"   æˆåŠŸ: {stats['successful']} ({stats['successful']/stats['total_experiments']*100:.1f}%)")
    print(f"   å¤±è´¥: {stats['failed']} ({stats['failed']/stats['total_experiments']*100:.1f}%)")
    print(f"   æ€»ç”¨æ—¶: {stats['total_time']/60:.1f} åˆ†é’Ÿ")
    
    # æ£€æŸ¥Driveä¸­çš„ç»“æœæ–‡ä»¶
    if save_to_drive and stats['success']:
        drive_csv_file = os.path.join(drive_save_dir, f"{project_id}_results.csv")
        if os.path.exists(drive_csv_file):
            print(f"âœ… é¡¹ç›® {project_id} ç»“æœå·²ä¿å­˜åˆ°Drive: {drive_csv_file}")
        else:
            print(f"âš ï¸ é¡¹ç›® {project_id} ç»“æœæ–‡ä»¶æœªæ‰¾åˆ°: {drive_csv_file}")
    
    return stats

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸŒŸ SolarPVé¡¹ç›® - æ‰¹é‡å®éªŒè„šæœ¬")
    print("=" * 80)
    
    # æ£€æŸ¥Google Driveæ˜¯å¦å·²æŒ‚è½½
    print("ğŸ”— æ£€æŸ¥Google Drive...")
    drive_mounted = os.path.exists("/content/drive/MyDrive")
    if drive_mounted:
        print("âœ… Google Driveå·²æŒ‚è½½")
    else:
        print("âš ï¸ Google DriveæœªæŒ‚è½½ï¼Œå°†è·³è¿‡Driveä¿å­˜")
    
    # è·å–å¯ç”¨é¡¹ç›®
    print("ğŸ“ æ‰«ææ•°æ®æ–‡ä»¶...")
    projects = get_available_projects()
    print(f"ğŸ“Š æ‰¾åˆ° {len(projects)} ä¸ªé¡¹ç›®: {projects[:10]}{'...' if len(projects) > 10 else ''}")
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦ç”Ÿæˆé…ç½®æ–‡ä»¶
    print("ğŸ“ æ£€æŸ¥é…ç½®æ–‡ä»¶...")
    config_files = get_config_files()
    print(f"ğŸ“Š æ‰¾åˆ° {len(config_files)} ä¸ªé…ç½®æ–‡ä»¶")
    
    if not projects:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•é¡¹ç›®æ•°æ®æ–‡ä»¶")
        return
    
    # æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦è¶³å¤Ÿ
    if len(config_files) < len(projects) * 100:  # æ¯ä¸ªé¡¹ç›®è‡³å°‘éœ€è¦100ä¸ªé…ç½®
        print("âš ï¸ é…ç½®æ–‡ä»¶æ•°é‡ä¸è¶³ï¼Œéœ€è¦ç”Ÿæˆé…ç½®æ–‡ä»¶")
        print("ğŸ”§ æ­£åœ¨ç”Ÿæˆé…ç½®æ–‡ä»¶...")
        
        try:
            # è¿è¡Œé…ç½®æ–‡ä»¶ç”Ÿæˆè„šæœ¬
            result = subprocess.run([
                sys.executable, "scripts/generate_dynamic_project_configs.py"
            ], capture_output=True, text=True, timeout=300)  # 5åˆ†é’Ÿè¶…æ—¶
            
            if result.returncode == 0:
                print("âœ… é…ç½®æ–‡ä»¶ç”ŸæˆæˆåŠŸ")
                # é‡æ–°æ‰«æé…ç½®æ–‡ä»¶
                config_files = get_config_files()
                print(f"ğŸ“Š é‡æ–°æ‰«æåˆ° {len(config_files)} ä¸ªé…ç½®æ–‡ä»¶")
            else:
                print(f"âŒ é…ç½®æ–‡ä»¶ç”Ÿæˆå¤±è´¥: {result.stderr}")
                return
                
        except subprocess.TimeoutExpired:
            print("â° é…ç½®æ–‡ä»¶ç”Ÿæˆè¶…æ—¶")
            return
        except Exception as e:
            print(f"ğŸ’¥ é…ç½®æ–‡ä»¶ç”Ÿæˆå¼‚å¸¸: {str(e)}")
            return
    
    if not config_files:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•é…ç½®æ–‡ä»¶")
        return
    
    # æ‰¹é‡å®éªŒè®¾ç½®
    # ç¡¬ç¼–ç Driveè·¯å¾„ï¼Œåˆ é™¤æœ¬åœ°ç»“æœç›®å½•
    drive_save_dir = "/content/drive/MyDrive/Solar PV electricity/ablation results"
    os.makedirs(drive_save_dir, exist_ok=True)
    
    # è¿è¡Œæ‰€æœ‰é¡¹ç›®
    all_stats = []
    total_projects = len(projects)
    successful_projects = 0
    
    print(f"\nğŸš€ å¼€å§‹æ‰¹é‡å®éªŒ!")
    print(f"ğŸ“Š æ€»é¡¹ç›®æ•°: {total_projects}")
    # è®¡ç®—æ€»å®éªŒæ•°ï¼ˆæ¯ä¸ªé¡¹ç›®ä½¿ç”¨340ä¸ªé…ç½®ï¼‰
    experiments_per_project = 340
    total_experiments = total_projects * experiments_per_project
    print(f"ğŸ“Š æ¯é¡¹ç›®å®éªŒæ•°: {experiments_per_project}")
    print(f"ğŸ“Š æ€»å®éªŒæ•°: {total_experiments}")
    
    for i, project_id in enumerate(projects, 1):
        print(f"\nğŸ”„ é¡¹ç›®è¿›åº¦: {i}/{total_projects}")
        
        stats = run_project_experiments(
            project_id=project_id,
            all_config_files=config_files,
            data_dir="data",
            save_to_drive=drive_mounted
        )
        
        all_stats.append(stats)
        if stats['success']:
            successful_projects += 1
        
        # æ˜¾ç¤ºå½“å‰ç»Ÿè®¡
        print(f"ğŸ“ˆ å½“å‰ç»Ÿè®¡: æˆåŠŸé¡¹ç›® {successful_projects}/{i}")
    
    # æœ€ç»ˆç»Ÿè®¡
    print(f"\nğŸ‰ æ‰¹é‡å®éªŒå®Œæˆ!")
    print("=" * 80)
    print(f"ğŸ“Š æœ€ç»ˆç»Ÿè®¡:")
    print(f"  æ€»é¡¹ç›®æ•°: {total_projects}")
    print(f"  æˆåŠŸé¡¹ç›®: {successful_projects} ({successful_projects/total_projects*100:.1f}%)")
    print(f"  å¤±è´¥é¡¹ç›®: {total_projects - successful_projects}")
    
    # è®¡ç®—æ€»å®éªŒç»Ÿè®¡
    total_experiments = sum(s['total_experiments'] for s in all_stats)
    total_successful = sum(s['successful'] for s in all_stats)
    total_failed = sum(s['failed'] for s in all_stats)
    
    print(f"\nğŸ“Š å®éªŒç»Ÿè®¡:")
    print(f"  æ€»å®éªŒæ•°: {total_experiments}")
    print(f"  æˆåŠŸå®éªŒ: {total_successful} ({total_successful/total_experiments*100:.1f}%)")
    print(f"  å¤±è´¥å®éªŒ: {total_failed} ({total_failed/total_experiments*100:.1f}%)")
    
    # æ˜¾ç¤ºDriveç»“æœ
    if drive_mounted:
        print(f"\nğŸ“ Google Driveç»“æœ:")
        drive_results = list_drive_results()
        if isinstance(drive_results, dict):
            print(f"  ğŸ“Š æ€»CSVæ–‡ä»¶æ•°: {drive_results['total_csv_files']}")
            print(f"  ğŸ“Š æ€»é¡¹ç›®æ•°: {drive_results['total_projects']}")
            
            # æ˜¾ç¤ºå‰10ä¸ªCSVæ–‡ä»¶
            print(f"  ğŸ“„ CSVæ–‡ä»¶åˆ—è¡¨:")
            for csv_file in drive_results['csv_files'][:10]:
                print(f"    ğŸ“„ {csv_file['filename']} ({csv_file['size']} bytes)")
            
            if drive_results['total_csv_files'] > 10:
                print(f"    ... è¿˜æœ‰ {drive_results['total_csv_files'] - 10} ä¸ªCSVæ–‡ä»¶")
            
            # æ˜¾ç¤ºé¡¹ç›®ç»Ÿè®¡
            print(f"  ğŸ“Š é¡¹ç›®ç»Ÿè®¡:")
            for project_id, stats in list(drive_results['project_stats'].items())[:10]:
                print(f"    ğŸ“ Project {project_id}: {stats['count']} ä¸ªCSVæ–‡ä»¶")
            
            if drive_results['total_projects'] > 10:
                print(f"    ... è¿˜æœ‰ {drive_results['total_projects'] - 10} ä¸ªé¡¹ç›®")
        else:
            print(f"  âŒ æ— æ³•è¯»å–Driveç»“æœ")
    
    # ä¿å­˜å®éªŒæŠ¥å‘Š
    report_file = os.path.join(results_dir, "experiment_report.csv")
    report_data = []
    for stats in all_stats:
        report_data.append({
            'project_id': stats['project_id'],
            'total_experiments': stats['total_experiments'],
            'successful': stats['successful'],
            'failed': stats['failed'],
            'success_rate': stats['successful'] / stats['total_experiments'] * 100,
            'total_time_minutes': stats['total_time'] / 60,
            'success': stats['success']
        })
    
    pd.DataFrame(report_data).to_csv(report_file, index=False)
    print(f"\nğŸ“Š å®éªŒæŠ¥å‘Šå·²ä¿å­˜: {report_file}")
    
    if drive_mounted:
        save_to_drive(report_file)
        print(f"ğŸ“Š å®éªŒæŠ¥å‘Šå·²ä¿å­˜åˆ°Drive")

if __name__ == "__main__":
    main()
