#!/usr/bin/env python3
"""
SolarPVé¡¹ç›® - æ‰¹é‡å®éªŒè„šæœ¬
åœ¨Colabä¸Šè¿è¡Œ100ä¸ªé¡¹ç›®çš„å®Œæ•´å®éªŒï¼Œä¿å­˜ç»“æœåˆ°Google Drive
"""

import os
import sys
import time
import subprocess
import yaml
import pandas as pd
from pathlib import Path

def check_drive_mount():
    """æ£€æŸ¥Google Driveæ˜¯å¦å·²æŒ‚è½½"""
    drive_path = "/content/drive/MyDrive"
    if os.path.exists(drive_path):
        print("âœ… Google Driveå·²æŒ‚è½½")
        return True
    else:
        print("âŒ Google DriveæœªæŒ‚è½½ï¼Œè¯·å…ˆæŒ‚è½½Drive")
        return False

def get_data_files():
    """æ‰«ædataç›®å½•ï¼Œè·å–æ‰€æœ‰é¡¹ç›®CSVæ–‡ä»¶"""
    data_dir = "data"
    if not os.path.exists(data_dir):
        print(f"âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
        return []
    
    csv_files = []
    for file in os.listdir(data_dir):
        if file.startswith("Project") and file.endswith(".csv"):
            project_id = file.replace("Project", "").replace(".csv", "")
            csv_files.append((project_id, os.path.join(data_dir, file)))
    
    csv_files.sort(key=lambda x: int(x[0]))
    return csv_files

def get_config_files():
    """è·å–æ‰€æœ‰é…ç½®æ–‡ä»¶"""
    config_dir = "config/projects"
    all_config_files = []
    
    if os.path.exists(config_dir):
        for project_dir in os.listdir(config_dir):
            project_path = os.path.join(config_dir, project_dir)
            if os.path.isdir(project_path):
                for file in os.listdir(project_path):
                    if file.endswith('.yaml') and file != 'config_index.yaml':
                        all_config_files.append(os.path.join(project_path, file))
    
    return all_config_files

def run_project_experiments(project_id, data_file, all_config_files, drive_save_dir):
    """è¿è¡Œå•ä¸ªé¡¹ç›®çš„æ‰€æœ‰å®éªŒ"""
    print(f"\n{'='*80}")
    print(f"ğŸš€ å¼€å§‹é¡¹ç›® {project_id} çš„å®éªŒ")
    print(f"{'='*80}")
    
    # åˆ›å»ºé¡¹ç›®CSVæ–‡ä»¶
    csv_file_path = os.path.join(drive_save_dir, f"{project_id}_results.csv")
    if not os.path.exists(csv_file_path):
        print(f"ğŸ“„ åˆ›å»ºé¡¹ç›®CSVæ–‡ä»¶: {csv_file_path}")
        empty_df = pd.DataFrame(columns=[
            'model', 'use_pv', 'use_hist_weather', 'use_forecast', 'weather_category',
            'use_time_encoding', 'past_days', 'model_complexity', 'epochs', 'batch_size',
            'learning_rate', 'train_time_sec', 'inference_time_sec', 'param_count',
            'samples_count', 'best_epoch', 'final_lr', 'mse', 'rmse', 'mae', 'nrmse',
            'r_square', 'smape', 'gpu_memory_used'
        ])
        empty_df.to_csv(csv_file_path, index=False)
        print(f"âœ… é¡¹ç›®CSVæ–‡ä»¶å·²åˆ›å»º")
    else:
        print(f"ğŸ“„ é¡¹ç›®CSVæ–‡ä»¶å·²å­˜åœ¨: {csv_file_path}")
    
    # è¿‡æ»¤å‡ºå½“å‰é¡¹ç›®çš„é…ç½®æ–‡ä»¶
    project_config_files = [f for f in all_config_files if f"Project{project_id}" in f or f"1140" in f]
    
    if not project_config_files:
        print(f"âš ï¸ æœªæ‰¾åˆ°é¡¹ç›® {project_id} çš„é…ç½®æ–‡ä»¶ï¼Œä½¿ç”¨Project1140çš„é…ç½®ä½œä¸ºæ¨¡æ¿")
        project_config_files = [f for f in all_config_files if "1140" in f]
    
    print(f"ğŸ“Š é¡¹ç›® {project_id}: å°†è¿è¡Œ {len(project_config_files)} ä¸ªå®éªŒ")
    print(f"ğŸ“ ç»“æœä¿å­˜åˆ°: {drive_save_dir}")
    
    stats = {
        'success': 0,
        'failed': 0,
        'errors': []
    }
    
    start_time = time.time()
    
    # è¿è¡Œæ¯ä¸ªå®éªŒ
    for i, config_file in enumerate(project_config_files, 1):
        print(f"\nğŸ”„ è¿›åº¦: {i}/{len(project_config_files)} - {os.path.basename(config_file)}")
        
        try:
            # ä¿®æ”¹é…ç½®æ–‡ä»¶ä¸­çš„æ•°æ®è·¯å¾„
            with open(config_file, 'r') as f:
                config = yaml.safe_load(f)
            
            print(f"ğŸ” è°ƒè¯•: åŸå§‹é…ç½®æ–‡ä»¶åŠ è½½å®Œæˆ")
            print(f"ğŸ” è°ƒè¯•: åŸå§‹config['train_params'] = {config.get('train_params', 'NOT_FOUND')}")
            
            # æ›´æ–°æ•°æ®è·¯å¾„å’Œplant_id
            config['data_path'] = data_file
            config['plant_id'] = project_id
            
            print(f"ğŸ” è°ƒè¯•: ä¿®æ”¹åconfig['train_params'] = {config.get('train_params', 'NOT_FOUND')}")
            print(f"ğŸ” è°ƒè¯•: ä¿®æ”¹åconfig['model'] = {config.get('model', 'NOT_FOUND')}")
            print(f"ğŸ” è°ƒè¯•: ä¿®æ”¹åconfig['model_params'] = {config.get('model_params', 'NOT_FOUND')}")
            
            # åˆ›å»ºä¸´æ—¶é…ç½®æ–‡ä»¶
            temp_config_file = f"temp_config_{project_id}_{i}.yaml"
            with open(temp_config_file, 'w') as f:
                yaml.dump(config, f)
            
            # è¿è¡Œå®éªŒ
            start_exp_time = time.time()
            result = subprocess.run(
                ['python', 'main.py', '--config', temp_config_file],
                capture_output=True,
                text=True,
                timeout=1800  # 30åˆ†é’Ÿè¶…æ—¶
            )
            duration = time.time() - start_exp_time
            
            # æ£€æŸ¥ç»“æœ
            has_error = "[ERROR]" in result.stdout or result.returncode != 0
            if not has_error and result.returncode == 0:
                stats['success'] += 1
                print(f"âœ… å®éªŒæˆåŠŸ! ç”¨æ—¶: {duration:.1f}ç§’")
                
                # æ˜¾ç¤ºç»“æœ
                if "ğŸ” è°ƒè¯•" in result.stdout:
                    print("ğŸ” å®éªŒè°ƒè¯•ä¿¡æ¯:")
                    for line in result.stdout.split('\n'):
                        if "ğŸ” è°ƒè¯•" in line:
                            print(f"   {line}")
                
                # æ˜¾ç¤ºå®éªŒç»“æœ
                if "CSVç»“æœå·²æ›´æ–°" not in result.stdout and "ğŸ” è°ƒè¯•" not in result.stdout:
                    print("ğŸ” å®Œæ•´æ ‡å‡†è¾“å‡º:")
                    print(result.stdout[-1000:])
                
                if result.stderr:
                    print("ğŸ” é”™è¯¯è¾“å‡º:")
                    print(result.stderr[-500:])
                
                if "CSVç»“æœå·²æ›´æ–°" in result.stdout:
                    print("âœ… CSVç»“æœå·²ä¿å­˜")
                else:
                    print("âš ï¸ æœªçœ‹åˆ°CSVä¿å­˜ä¿¡æ¯")
                
                # ç¡¬ç¼–ç ä¿å­˜ç»“æœåˆ°CSVæ–‡ä»¶ï¼ˆç‹¬ç«‹äºsave_excel_resultsè®¾ç½®ï¼‰
                print(f"ğŸ”§ ç¡¬ç¼–ç ä¿å­˜ç»“æœåˆ°: {csv_file_path}")
                
                # ä»å®éªŒè¾“å‡ºä¸­æå–ç»“æœ
                result_line = None
                inference_time = 0.0
                param_count = 0
                samples_count = 0
                best_epoch = 0
                final_lr = 0.0
                nrmse = 0.0
                smape = 0.0
                gpu_memory_used = 0
                
                # è°ƒè¯•ï¼šæ˜¾ç¤ºæ‰€æœ‰è¾“å‡ºè¡Œ
                print("ğŸ” è°ƒè¯•ï¼šæ£€æŸ¥å®éªŒè¾“å‡ºä¸­çš„METRICSè¡Œ")
                for line in result.stdout.split('\n'):
                    if "[METRICS]" in line:
                        print(f"   æ‰¾åˆ°METRICSè¡Œ: {line}")
                
                for line in result.stdout.split('\n'):
                    if "mse=" in line and "rmse=" in line and "mae=" in line and "r_square=" in line:
                        result_line = line
                    elif "[METRICS] inference_time=" in line:
                        try:
                            inference_time = float(line.split("inference_time=")[1].split(",")[0])
                            print(f"ğŸ” è°ƒè¯•ï¼šæå–inference_time={inference_time}")
                        except Exception as e:
                            print(f"ğŸ” è°ƒè¯•ï¼šinference_timeæå–å¤±è´¥: {e}")
                    elif "[METRICS]" in line and "param_count=" in line:
                        try:
                            param_count = int(line.split("param_count=")[1].split(",")[0])
                            print(f"ğŸ” è°ƒè¯•ï¼šæå–param_count={param_count}")
                        except Exception as e:
                            print(f"ğŸ” è°ƒè¯•ï¼šparam_countæå–å¤±è´¥: {e}")
                    elif "[METRICS]" in line and "samples_count=" in line:
                        try:
                            samples_count = int(line.split("samples_count=")[1].split()[0])
                            print(f"ğŸ” è°ƒè¯•ï¼šæå–samples_count={samples_count}")
                        except Exception as e:
                            print(f"ğŸ” è°ƒè¯•ï¼šsamples_countæå–å¤±è´¥: {e}")
                    elif "[METRICS] best_epoch=" in line:
                        try:
                            best_epoch = int(line.split("best_epoch=")[1].split(",")[0])
                            print(f"ğŸ” è°ƒè¯•ï¼šæå–best_epoch={best_epoch}")
                        except Exception as e:
                            print(f"ğŸ” è°ƒè¯•ï¼šbest_epochæå–å¤±è´¥: {e}")
                    elif "[METRICS]" in line and "final_lr=" in line:
                        try:
                            final_lr = float(line.split("final_lr=")[1].split()[0])
                            print(f"ğŸ” è°ƒè¯•ï¼šæå–final_lr={final_lr}")
                        except Exception as e:
                            print(f"ğŸ” è°ƒè¯•ï¼šfinal_lræå–å¤±è´¥: {e}")
                    elif "[METRICS] nrmse=" in line:
                        try:
                            nrmse = float(line.split("nrmse=")[1].split(",")[0])
                            print(f"ğŸ” è°ƒè¯•ï¼šæå–nrmse={nrmse}")
                        except Exception as e:
                            print(f"ğŸ” è°ƒè¯•ï¼šnrmseæå–å¤±è´¥: {e}")
                    elif "[METRICS]" in line and "smape=" in line:
                        try:
                            smape = float(line.split("smape=")[1].split(",")[0])
                            print(f"ğŸ” è°ƒè¯•ï¼šæå–smape={smape}")
                        except Exception as e:
                            print(f"ğŸ” è°ƒè¯•ï¼šsmapeæå–å¤±è´¥: {e}")
                    elif "[METRICS]" in line and "gpu_memory_used=" in line:
                        try:
                            gpu_memory_used = int(line.split("gpu_memory_used=")[1].split()[0])
                            print(f"ğŸ” è°ƒè¯•ï¼šæå–gpu_memory_used={gpu_memory_used}")
                        except Exception as e:
                            print(f"ğŸ” è°ƒè¯•ï¼šgpu_memory_usedæå–å¤±è´¥: {e}")
                
                if result_line:
                    # è§£æç»“æœ
                    import re
                    mse_match = re.search(r'mse=([0-9.]+)', result_line)
                    rmse_match = re.search(r'rmse=([0-9.]+)', result_line)
                    mae_match = re.search(r'mae=([0-9.]+)', result_line)
                    r_square_match = re.search(r'r_square=([0-9.]+)', result_line)
                    
                    if mse_match and rmse_match and mae_match and r_square_match:
                        # ä»é…ç½®æ–‡ä»¶åä¸­æå–æ›´å¤šä¿¡æ¯
                        config_filename = os.path.basename(config_file)
                        parts = config_filename.replace('.yaml', '').split('_')
                        
                        # è§£æé…ç½®æ–‡ä»¶å: LGBM_low_NWP_72h_TE.yaml æˆ– RF_low_NWP_plus_24h_TE.yaml
                        model_name = parts[0] if len(parts) > 0 else config.get('model', 'Unknown')
                        complexity = parts[1] if len(parts) > 1 else config.get('model_complexity', 'low')
                        
                        # å¤„ç†input_categoryï¼ˆå¯èƒ½æ˜¯NWPæˆ–NWP_plusï¼‰
                        if len(parts) > 2:
                            if parts[2] == 'NWP' and len(parts) > 3 and parts[3] == 'plus':
                                input_category = 'NWP_plus'
                                lookback_hours = parts[4].replace('h', '') if len(parts) > 4 else '24'
                                time_encoding = parts[5] == 'TE' if len(parts) > 5 else config.get('use_time_encoding', False)
                            else:
                                input_category = parts[2]
                                lookback_hours = parts[3].replace('h', '') if len(parts) > 3 else '24'
                                time_encoding = parts[4] == 'TE' if len(parts) > 4 else config.get('use_time_encoding', False)
                        else:
                            input_category = 'unknown'
                            lookback_hours = '24'
                            time_encoding = config.get('use_time_encoding', False)
                        
                        # è°ƒè¯•ä¿¡æ¯
                        print(f"ğŸ” é…ç½®æ–‡ä»¶åè§£æ: {config_filename}")
                        print(f"   è§£æç»“æœ: model={model_name}, complexity={complexity}, input_category={input_category}")
                        print(f"   lookback_hours={lookback_hours}, time_encoding={time_encoding}")
                        
                        # æ ¹æ®input_categoryç¡®å®šå…¶ä»–å‚æ•°
                        use_pv = input_category in ['PV', 'PV_plus_NWP', 'PV_plus_NWP_plus', 'PV_plus_HW']
                        use_hist_weather = input_category in ['PV_plus_HW']
                        use_forecast = input_category in ['PV_plus_NWP', 'PV_plus_NWP_plus', 'PV_plus_HW', 'NWP', 'NWP_plus']
                        
                        # è®¡ç®—past_daysï¼ˆåŸºäºlookback_hoursï¼‰
                        past_days = int(int(lookback_hours) / 24) if lookback_hours.isdigit() else 1
                        
                        # åˆ›å»ºç»“æœè¡Œ
                        result_row = {
                            'model': model_name,
                            'use_pv': use_pv,
                            'use_hist_weather': use_hist_weather,
                            'use_forecast': use_forecast,
                            'weather_category': config.get('weather_category', 'all_weather'),
                            'use_time_encoding': time_encoding,
                            'past_days': past_days,
                            'model_complexity': complexity,
                            'epochs': config.get('epochs', 50 if complexity == 'high' else 15),
                            'batch_size': config.get('train_params', {}).get('batch_size', 32),
                            'learning_rate': config.get('train_params', {}).get('learning_rate', 0.001),
                            'train_time_sec': round(duration, 4),
                            'inference_time_sec': inference_time,
                            'param_count': param_count,
                            'samples_count': samples_count,
                            'best_epoch': best_epoch,
                            'final_lr': final_lr,
                            'mse': float(mse_match.group(1)),
                            'rmse': float(rmse_match.group(1)),
                            'mae': float(mae_match.group(1)),
                            'nrmse': nrmse,
                            'r_square': float(r_square_match.group(1)),
                            'smape': smape,
                            'gpu_memory_used': gpu_memory_used
                        }
                        
                        # è¯»å–ç°æœ‰CSVæ–‡ä»¶
                        if os.path.exists(csv_file_path):
                            df = pd.read_csv(csv_file_path)
                        else:
                            df = pd.DataFrame()
                        
                        # æ·»åŠ æ–°è¡Œ
                        new_row_df = pd.DataFrame([result_row])
                        df = pd.concat([df, new_row_df], ignore_index=True)
                        
                        # ä¿å­˜CSVæ–‡ä»¶
                        df.to_csv(csv_file_path, index=False)
                        print(f"âœ… ç»“æœå·²ç¡¬ç¼–ç ä¿å­˜åˆ°CSVæ–‡ä»¶")
                        print(f"ğŸ“Š CSVæ–‡ä»¶å½“å‰è¡Œæ•°: {len(df)}")
                        print(f"ğŸ“Š æœ€æ–°å®éªŒ: {result_row['model']} - {result_row['mse']:.4f}")
                        print(f"ğŸ” è§£æçš„é…ç½®ä¿¡æ¯:")
                        print(f"   æ¨¡å‹: {result_row['model']}, å¤æ‚åº¦: {result_row['model_complexity']}")
                        print(f"   è¾“å…¥ç±»åˆ«: {input_category}, æ—¶é—´ç¼–ç : {result_row['use_time_encoding']}")
                        print(f"   PV: {result_row['use_pv']}, å†å²å¤©æ°”: {result_row['use_hist_weather']}, é¢„æµ‹å¤©æ°”: {result_row['use_forecast']}")
                        print(f"ğŸ” æå–çš„é¢å¤–å­—æ®µ:")
                        print(f"   æ¨ç†æ—¶é—´: {inference_time}s, å‚æ•°æ•°é‡: {param_count}, æ ·æœ¬æ•°é‡: {samples_count}")
                        print(f"   æœ€ä½³è½®æ¬¡: {best_epoch}, æœ€ç»ˆå­¦ä¹ ç‡: {final_lr}")
                        print(f"   NRMSE: {nrmse}, SMAPE: {smape}, GPUå†…å­˜: {gpu_memory_used}MB")
                    else:
                        print(f"âŒ æ— æ³•è§£æå®éªŒç»“æœ: {result_line}")
                else:
                    print(f"âŒ æœªæ‰¾åˆ°å®éªŒç»“æœè¡Œ")
            else:
                stats['failed'] += 1
                error_msg = f"è¿”å›ç : {result.returncode}, é”™è¯¯: {result.stderr[-200:]}"
                if "[ERROR]" in result.stdout:
                    # æå–é”™è¯¯ä¿¡æ¯
                    error_lines = [line for line in result.stdout.split('\n') if "[ERROR]" in line]
                    if error_lines:
                        error_msg = f"å®éªŒé”™è¯¯: {error_lines[-1]}"
                stats['errors'].append(error_msg)
                print(f"âŒ å®éªŒå¤±è´¥! {error_msg}")
                print(f"   æ ‡å‡†è¾“å‡º: {result.stdout[-500:]}")
                print(f"   é”™è¯¯è¾“å‡º: {result.stderr[-500:]}")
            
            # æ¸…ç†ä¸´æ—¶é…ç½®æ–‡ä»¶
            if os.path.exists(temp_config_file):
                os.remove(temp_config_file)
                
        except subprocess.TimeoutExpired:
            stats['failed'] += 1
            error_msg = "å®éªŒè¶…æ—¶ (30åˆ†é’Ÿ)"
            stats['errors'].append(error_msg)
            print(f"â° å®éªŒè¶…æ—¶: {error_msg}")
        except Exception as e:
            stats['failed'] += 1
            error_msg = f"å®éªŒå¼‚å¸¸: {str(e)}"
            stats['errors'].append(error_msg)
            print(f"ğŸ’¥ å®éªŒå¼‚å¸¸: {error_msg}")
    
    # è®¡ç®—æ€»ç”¨æ—¶
    total_time = time.time() - start_time
    print(f"\nğŸ“Š é¡¹ç›® {project_id} å®Œæˆ!")
    print(f"âœ… æˆåŠŸ: {stats['success']}")
    print(f"âŒ å¤±è´¥: {stats['failed']}")
    print(f"â±ï¸ æ€»ç”¨æ—¶: {total_time:.1f}ç§’")
    
    return stats

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸŒŸ SolarPVé¡¹ç›® - æ‰¹é‡å®éªŒè„šæœ¬")
    print("=" * 50)
    
    # æ£€æŸ¥DriveæŒ‚è½½
    if not check_drive_mount():
        return
    
    # æ‰«ææ•°æ®æ–‡ä»¶
    print("ğŸ“ æ‰«ææ•°æ®æ–‡ä»¶...")
    data_files = get_data_files()
    if not data_files:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•æ•°æ®æ–‡ä»¶")
        return
    
    print(f"ğŸ“Š æ‰¾åˆ° {len(data_files)} ä¸ªé¡¹ç›®: {[pid for pid, _ in data_files[:10]]}...")
    
    # æ£€æŸ¥é…ç½®æ–‡ä»¶
    print("ğŸ“ æ£€æŸ¥é…ç½®æ–‡ä»¶...")
    all_config_files = get_config_files()
    print(f"ğŸ“Š æ‰¾åˆ° {len(all_config_files)} ä¸ªé…ç½®æ–‡ä»¶")
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦ç”Ÿæˆé…ç½®æ–‡ä»¶
    if len(all_config_files) < len(data_files) * 100:
        print("ğŸ”§ é…ç½®æ–‡ä»¶ä¸è¶³ï¼Œæ­£åœ¨ç”Ÿæˆ...")
        try:
            result = subprocess.run([
                'python', 'scripts/generate_dynamic_project_configs.py'
            ], capture_output=True, text=True, timeout=300)
            if result.returncode == 0:
                print("âœ… é…ç½®æ–‡ä»¶ç”Ÿæˆå®Œæˆ")
                all_config_files = get_config_files()
                print(f"ğŸ“Š ç°åœ¨æœ‰ {len(all_config_files)} ä¸ªé…ç½®æ–‡ä»¶")
            else:
                print(f"âŒ é…ç½®æ–‡ä»¶ç”Ÿæˆå¤±è´¥: {result.stderr}")
                return
        except Exception as e:
            print(f"âŒ é…ç½®æ–‡ä»¶ç”Ÿæˆå¼‚å¸¸: {e}")
            return
    
    # ç¡¬ç¼–ç Driveä¿å­˜è·¯å¾„
    drive_save_dir = "/content/drive/MyDrive/Solar PV electricity/ablation results"
    os.makedirs(drive_save_dir, exist_ok=True)
    
    print(f"\nğŸš€ å¼€å§‹æ‰¹é‡å®éªŒ!")
    print(f"ğŸ“Š æ€»é¡¹ç›®æ•°: {len(data_files)}")
    print(f"ğŸ“Š æ¯é¡¹ç›®å®éªŒæ•°: 340")
    print(f"ğŸ“Š æ€»å®éªŒæ•°: {len(data_files) * 340}")
    
    # è¿è¡Œæ‰€æœ‰é¡¹ç›®
    total_stats = {'success': 0, 'failed': 0, 'errors': []}
    
    for i, (project_id, data_file) in enumerate(data_files, 1):
        print(f"\nğŸ”„ é¡¹ç›®è¿›åº¦: {i}/{len(data_files)}")
        
        project_stats = run_project_experiments(project_id, data_file, all_config_files, drive_save_dir)
        
        # ç´¯è®¡ç»Ÿè®¡
        total_stats['success'] += project_stats['success']
        total_stats['failed'] += project_stats['failed']
        total_stats['errors'].extend(project_stats['errors'])
    
    # æœ€ç»ˆç»Ÿè®¡
    print(f"\nğŸ‰ æ‰€æœ‰å®éªŒå®Œæˆ!")
    print(f"âœ… æ€»æˆåŠŸ: {total_stats['success']}")
    print(f"âŒ æ€»å¤±è´¥: {total_stats['failed']}")
    print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {drive_save_dir}")
    
    # æ˜¾ç¤ºDriveç»“æœ
    if os.path.exists(drive_save_dir):
        csv_files = [f for f in os.listdir(drive_save_dir) if f.endswith('_results.csv')]
        print(f"ğŸ“Š ç”Ÿæˆäº† {len(csv_files)} ä¸ªç»“æœæ–‡ä»¶")
        for csv_file in csv_files[:5]:  # æ˜¾ç¤ºå‰5ä¸ªæ–‡ä»¶
            file_path = os.path.join(drive_save_dir, csv_file)
            if os.path.exists(file_path):
                df = pd.read_csv(file_path)
                print(f"   {csv_file}: {len(df)} è¡Œç»“æœ")

if __name__ == "__main__":
    main()
