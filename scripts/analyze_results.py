#!/usr/bin/env python3
"""
æ¶ˆèå®éªŒç»“æœåˆ†æè„šæœ¬
ç”¨äºåˆ†æ360ä¸ªæ¶ˆèå®éªŒçš„ç»“æœï¼Œç”Ÿæˆç»Ÿè®¡æŠ¥å‘Šå’Œå¯è§†åŒ–å›¾è¡¨
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import argparse
import yaml

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei']
plt.rcParams['axes.unicode_minus'] = False

class AblationResultsAnalyzer:
    """æ¶ˆèå®éªŒç»“æœåˆ†æå™¨"""
    
    def __init__(self, results_dir="results/ablation"):
        self.results_dir = Path(results_dir)
        self.summary_file = self.results_dir / "experiment_summary.csv"
        self.failed_file = self.results_dir / "failed_configs.csv"
        
    def load_results(self):
        """åŠ è½½å®éªŒç»“æœ"""
        if not self.summary_file.exists():
            print(f"âŒ ç»“æœæ–‡ä»¶ä¸å­˜åœ¨: {self.summary_file}")
            return None
        
        df = pd.read_csv(self.summary_file)
        print(f"âœ… åŠ è½½äº† {len(df)} ä¸ªå®éªŒç»“æœ")
        return df
    
    def load_failed_configs(self):
        """åŠ è½½å¤±è´¥é…ç½®"""
        if not self.failed_file.exists():
            print("âœ… æ²¡æœ‰å¤±è´¥çš„é…ç½®")
            return pd.DataFrame()
        
        df = pd.read_csv(self.failed_file)
        print(f"âš ï¸  å‘ç° {len(df)} ä¸ªå¤±è´¥çš„é…ç½®")
        return df
    
    def analyze_overall_performance(self, df):
        """åˆ†ææ€»ä½“æ€§èƒ½"""
        print("\nğŸ“Š æ€»ä½“æ€§èƒ½åˆ†æ")
        print("=" * 50)
        
        completed_df = df[df['status'] == 'completed']
        print(f"æˆåŠŸå®Œæˆçš„å®éªŒ: {len(completed_df)}")
        print(f"å¤±è´¥çš„å®éªŒ: {len(df) - len(completed_df)}")
        print(f"æˆåŠŸç‡: {len(completed_df)/len(df)*100:.1f}%")
        
        if len(completed_df) > 0:
            metrics = ['mae', 'rmse', 'r2']
            for metric in metrics:
                if metric in completed_df.columns:
                    values = completed_df[metric].dropna()
                    if len(values) > 0:
                        print(f"\n{metric.upper()}:")
                        print(f"  å¹³å‡å€¼: {values.mean():.4f}")
                        print(f"  æ ‡å‡†å·®: {values.std():.4f}")
                        print(f"  æœ€å°å€¼: {values.min():.4f}")
                        print(f"  æœ€å¤§å€¼: {values.max():.4f}")
    
    def analyze_model_performance(self, df):
        """åˆ†ææ¨¡å‹æ€§èƒ½"""
        print("\nğŸ¤– æ¨¡å‹æ€§èƒ½åˆ†æ")
        print("=" * 50)
        
        completed_df = df[df['status'] == 'completed'].copy()
        if len(completed_df) == 0:
            print("æ²¡æœ‰æˆåŠŸå®Œæˆçš„å®éªŒ")
            return
        
        # æå–æ¨¡å‹åç§°
        completed_df['model'] = completed_df['config_name'].str.split('_').str[0]
        
        # æŒ‰æ¨¡å‹åˆ†ç»„ç»Ÿè®¡
        model_stats = completed_df.groupby('model').agg({
            'mae': ['mean', 'std', 'count'],
            'rmse': ['mean', 'std'],
            'r2': ['mean', 'std'],
            'duration': 'mean'
        }).round(4)
        
        print("æ¨¡å‹æ€§èƒ½ç»Ÿè®¡:")
        print(model_stats)
        
        # æ‰¾å‡ºæœ€ä½³æ¨¡å‹
        best_models = {}
        for metric in ['mae', 'rmse']:
            if metric in completed_df.columns:
                best_idx = completed_df[metric].idxmin()
                best_model = completed_df.loc[best_idx, 'model']
                best_value = completed_df.loc[best_idx, metric]
                best_models[metric] = (best_model, best_value)
        
        print(f"\næœ€ä½³æ¨¡å‹:")
        for metric, (model, value) in best_models.items():
            print(f"  {metric.upper()}: {model} ({value:.4f})")
    
    def analyze_input_features(self, df):
        """åˆ†æè¾“å…¥ç‰¹å¾æ•ˆæœ"""
        print("\nğŸ” è¾“å…¥ç‰¹å¾æ•ˆæœåˆ†æ")
        print("=" * 50)
        
        completed_df = df[df['status'] == 'completed'].copy()
        if len(completed_df) == 0:
            print("æ²¡æœ‰æˆåŠŸå®Œæˆçš„å®éªŒ")
            return
        
        # è§£æè¾“å…¥ç‰¹å¾ç±»åˆ«
        def extract_input_category(config_name):
            if 'PV_plus_NWP_plus' in config_name:
                return 'PV+NWP+'
            elif 'PV_plus_NWP' in config_name:
                return 'PV+NWP'
            elif 'PV_plus_HW' in config_name:
                return 'PV+HW'
            elif 'NWP_plus' in config_name and 'PV' not in config_name:
                return 'NWP+'
            elif 'NWP' in config_name and 'PV' not in config_name:
                return 'NWP'
            elif 'PV' in config_name and 'plus' not in config_name:
                return 'PV'
            else:
                return 'Unknown'
        
        completed_df['input_category'] = completed_df['config_name'].apply(extract_input_category)
        
        # æŒ‰è¾“å…¥ç‰¹å¾åˆ†ç»„ç»Ÿè®¡
        input_stats = completed_df.groupby('input_category').agg({
            'mae': ['mean', 'std', 'count'],
            'rmse': ['mean', 'std'],
            'r2': ['mean', 'std']
        }).round(4)
        
        print("è¾“å…¥ç‰¹å¾æ•ˆæœç»Ÿè®¡:")
        print(input_stats)
        
        # æ‰¾å‡ºæœ€ä½³è¾“å…¥ç‰¹å¾ç»„åˆ
        best_inputs = {}
        for metric in ['mae', 'rmse']:
            if metric in completed_df.columns:
                best_idx = completed_df[metric].idxmin()
                best_input = completed_df.loc[best_idx, 'input_category']
                best_value = completed_df.loc[best_idx, metric]
                best_inputs[metric] = (best_input, best_value)
        
        print(f"\næœ€ä½³è¾“å…¥ç‰¹å¾ç»„åˆ:")
        for metric, (input_cat, value) in best_inputs.items():
            print(f"  {metric.upper()}: {input_cat} ({value:.4f})")
    
    def analyze_hyperparameters(self, df):
        """åˆ†æè¶…å‚æ•°æ•ˆæœ"""
        print("\nâš™ï¸ è¶…å‚æ•°æ•ˆæœåˆ†æ")
        print("=" * 50)
        
        completed_df = df[df['status'] == 'completed'].copy()
        if len(completed_df) == 0:
            print("æ²¡æœ‰æˆåŠŸå®Œæˆçš„å®éªŒ")
            return
        
        # è§£æè¶…å‚æ•°
        def extract_hyperparams(config_name):
            parts = config_name.split('_')
            model = parts[0]
            complexity = parts[1]
            
            # æå–å›çœ‹çª—å£
            lookback = None
            for part in parts:
                if part.endswith('h'):
                    lookback = int(part[:-1])
                    break
            
            # æå–æ—¶é—´ç¼–ç 
            te = 'TE' in config_name
            
            return {
                'model': model,
                'complexity': complexity,
                'lookback': lookback,
                'time_encoding': te
            }
        
        # æ·»åŠ è¶…å‚æ•°åˆ—
        hyperparams_df = completed_df['config_name'].apply(extract_hyperparams)
        for col in ['model', 'complexity', 'lookback', 'time_encoding']:
            completed_df[col] = hyperparams_df.apply(lambda x: x[col])
        
        # åˆ†æå¤æ‚åº¦æ•ˆæœ
        complexity_stats = completed_df.groupby('complexity')['mae'].agg(['mean', 'std', 'count']).round(4)
        print("æ¨¡å‹å¤æ‚åº¦æ•ˆæœ:")
        print(complexity_stats)
        
        # åˆ†æå›çœ‹çª—å£æ•ˆæœ
        lookback_stats = completed_df.groupby('lookback')['mae'].agg(['mean', 'std', 'count']).round(4)
        print("\nå›çœ‹çª—å£æ•ˆæœ:")
        print(lookback_stats)
        
        # åˆ†ææ—¶é—´ç¼–ç æ•ˆæœ
        te_stats = completed_df.groupby('time_encoding')['mae'].agg(['mean', 'std', 'count']).round(4)
        print("\næ—¶é—´ç¼–ç æ•ˆæœ:")
        print(te_stats)
    
    def create_visualizations(self, df):
        """åˆ›å»ºå¯è§†åŒ–å›¾è¡¨"""
        print("\nğŸ“ˆ ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨")
        print("=" * 50)
        
        completed_df = df[df['status'] == 'completed'].copy()
        if len(completed_df) == 0:
            print("æ²¡æœ‰æˆåŠŸå®Œæˆçš„å®éªŒï¼Œè·³è¿‡å¯è§†åŒ–")
            return
        
        # æå–æ¨¡å‹åç§°
        completed_df['model'] = completed_df['config_name'].str.split('_').str[0]
        
        # åˆ›å»ºå›¾è¡¨ç›®å½•
        plots_dir = self.results_dir / "plots"
        plots_dir.mkdir(exist_ok=True)
        
        # 1. æ¨¡å‹æ€§èƒ½å¯¹æ¯”ç®±çº¿å›¾
        plt.figure(figsize=(12, 8))
        sns.boxplot(data=completed_df, x='model', y='mae')
        plt.title('ä¸åŒæ¨¡å‹çš„MAEåˆ†å¸ƒ')
        plt.xlabel('æ¨¡å‹')
        plt.ylabel('MAE')
        plt.xticks(rotation=45)
        plt.tight_layout()
        plt.savefig(plots_dir / "model_mae_comparison.png", dpi=300, bbox_inches='tight')
        plt.close()
        
        # 2. æ¨¡å‹æ€§èƒ½å¯¹æ¯”æ•£ç‚¹å›¾
        plt.figure(figsize=(10, 8))
        sns.scatterplot(data=completed_df, x='rmse', y='mae', hue='model', alpha=0.7)
        plt.title('RMSE vs MAE (æŒ‰æ¨¡å‹ç€è‰²)')
        plt.xlabel('RMSE')
        plt.ylabel('MAE')
        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        plt.tight_layout()
        plt.savefig(plots_dir / "rmse_vs_mae.png", dpi=300, bbox_inches='tight')
        plt.close()
        
        # 3. è®­ç»ƒæ—¶é—´ vs æ€§èƒ½
        plt.figure(figsize=(10, 8))
        sns.scatterplot(data=completed_df, x='duration', y='mae', hue='model', alpha=0.7)
        plt.title('è®­ç»ƒæ—¶é—´ vs MAE')
        plt.xlabel('è®­ç»ƒæ—¶é—´ (ç§’)')
        plt.ylabel('MAE')
        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        plt.tight_layout()
        plt.savefig(plots_dir / "training_time_vs_mae.png", dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"âœ… å›¾è¡¨å·²ä¿å­˜åˆ°: {plots_dir}")
    
    def generate_report(self, df, failed_df):
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        print("\nğŸ“ ç”Ÿæˆåˆ†ææŠ¥å‘Š")
        print("=" * 50)
        
        report_file = self.results_dir / "analysis_report.md"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("# Project1140 æ¶ˆèå®éªŒç»“æœåˆ†ææŠ¥å‘Š\n\n")
            f.write(f"**åˆ†ææ—¶é—´**: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            # æ€»ä½“ç»Ÿè®¡
            f.write("## æ€»ä½“ç»Ÿè®¡\n\n")
            completed_df = df[df['status'] == 'completed']
            f.write(f"- **æ€»å®éªŒæ•°**: {len(df)}\n")
            f.write(f"- **æˆåŠŸå®Œæˆ**: {len(completed_df)}\n")
            f.write(f"- **å¤±è´¥å®éªŒ**: {len(df) - len(completed_df)}\n")
            f.write(f"- **æˆåŠŸç‡**: {len(completed_df)/len(df)*100:.1f}%\n\n")
            
            if len(completed_df) > 0:
                # æ€§èƒ½ç»Ÿè®¡
                f.write("## æ€§èƒ½æŒ‡æ ‡ç»Ÿè®¡\n\n")
                metrics = ['mae', 'rmse', 'r2']
                for metric in metrics:
                    if metric in completed_df.columns:
                        values = completed_df[metric].dropna()
                        if len(values) > 0:
                            f.write(f"### {metric.upper()}\n")
                            f.write(f"- **å¹³å‡å€¼**: {values.mean():.4f}\n")
                            f.write(f"- **æ ‡å‡†å·®**: {values.std():.4f}\n")
                            f.write(f"- **æœ€å°å€¼**: {values.min():.4f}\n")
                            f.write(f"- **æœ€å¤§å€¼**: {values.max():.4f}\n\n")
                
                # æœ€ä½³ç»“æœ
                f.write("## æœ€ä½³ç»“æœ\n\n")
                for metric in ['mae', 'rmse']:
                    if metric in completed_df.columns:
                        best_idx = completed_df[metric].idxmin()
                        best_config = completed_df.loc[best_idx, 'config_name']
                        best_value = completed_df.loc[best_idx, metric]
                        f.write(f"- **æœ€ä½³{metric.upper()}**: {best_config} ({best_value:.4f})\n")
            
            # å¤±è´¥åˆ†æ
            if len(failed_df) > 0:
                f.write("\n## å¤±è´¥åˆ†æ\n\n")
                status_counts = failed_df['status'].value_counts()
                f.write("### å¤±è´¥ç±»å‹åˆ†å¸ƒ\n\n")
                for status, count in status_counts.items():
                    f.write(f"- **{status}**: {count}\n")
        
        print(f"âœ… åˆ†ææŠ¥å‘Šå·²ä¿å­˜: {report_file}")
    
    def run_analysis(self):
        """è¿è¡Œå®Œæ•´åˆ†æ"""
        print("ğŸ” å¼€å§‹åˆ†ææ¶ˆèå®éªŒç»“æœ")
        print("=" * 50)
        
        # åŠ è½½æ•°æ®
        df = self.load_results()
        if df is None:
            return
        
        failed_df = self.load_failed_configs()
        
        # è¿è¡Œåˆ†æ
        self.analyze_overall_performance(df)
        self.analyze_model_performance(df)
        self.analyze_input_features(df)
        self.analyze_hyperparameters(df)
        self.create_visualizations(df)
        self.generate_report(df, failed_df)
        
        print("\nğŸ‰ åˆ†æå®Œæˆï¼")
        print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {self.results_dir}")

def main():
    parser = argparse.ArgumentParser(description="åˆ†ææ¶ˆèå®éªŒç»“æœ")
    parser.add_argument("--results-dir", default="results/ablation", help="ç»“æœç›®å½•")
    
    args = parser.parse_args()
    
    analyzer = AblationResultsAnalyzer(args.results_dir)
    analyzer.run_analysis()

if __name__ == "__main__":
    main()
