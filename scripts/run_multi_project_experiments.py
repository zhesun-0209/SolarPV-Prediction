#!/usr/bin/env python3
"""
è¿è¡Œ100ä¸ªProjectçš„æ¶ˆèå®éªŒ
æ”¯æŒæ–­ç‚¹ç»­è®­ã€å®æ—¶ä¿å­˜åˆ°Google Drive
"""

import os
import sys
import time
import yaml
import pandas as pd
import numpy as np
from datetime import datetime
from pathlib import Path
import subprocess
import argparse
from concurrent.futures import ProcessPoolExecutor, as_completed
import logging
import signal
import threading
from typing import Dict, List, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(str(Path(__file__).parent.parent))

from utils.drive_results_saver import DriveResultsSaver
from utils.checkpoint_manager import CheckpointManager

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('multi_project_experiments.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class MultiProjectExperimentRunner:
    """å¤šProjectå®éªŒè¿è¡Œå™¨"""
    
    def __init__(self, 
                 drive_path: str = "/content/drive/MyDrive/Solar PV electricity/ablation results",
                 max_workers: int = 4,
                 batch_size: int = 10):
        self.drive_saver = DriveResultsSaver(drive_path)
        self.checkpoint_manager = CheckpointManager(drive_path)
        self.max_workers = max_workers
        self.batch_size = batch_size
        
        # åˆ›å»ºä¸´æ—¶ç»“æœç›®å½•
        self.temp_results_dir = Path("./temp_results")
        self.temp_results_dir.mkdir(parents=True, exist_ok=True)
        
        # è¿è¡ŒçŠ¶æ€
        self.running = True
        self.stats = {
            'total_experiments': 0,
            'completed_experiments': 0,
            'failed_experiments': 0,
            'start_time': None
        }
        
        # è®¾ç½®ä¿¡å·å¤„ç†
        signal.signal(signal.SIGINT, self._signal_handler)
        signal.signal(signal.SIGTERM, self._signal_handler)
        
        logger.info(f"å¤šProjectå®éªŒè¿è¡Œå™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"æœ€å¤§å¹¶å‘æ•°: {max_workers}")
        logger.info(f"æ‰¹æ¬¡å¤§å°: {batch_size}")
    
    def _signal_handler(self, signum, frame):
        """ä¿¡å·å¤„ç†å™¨ï¼Œç”¨äºä¼˜é›…å…³é—­"""
        logger.info(f"æ”¶åˆ°ä¿¡å· {signum}ï¼Œå¼€å§‹ä¼˜é›…å…³é—­...")
        self.running = False
    
    def run_single_experiment(self, project_id: str, config_info: Dict) -> Dict:
        """è¿è¡Œå•ä¸ªå®éªŒ"""
        try:
            config_name = config_info['name']
            config = config_info['config']
            config_file = config_info['file_path']
            
            logger.info(f"ğŸš€ å¼€å§‹å®éªŒ: {project_id} - {config_name}")
            
            # åˆ›å»ºå®éªŒç‰¹å®šçš„ç»“æœç›®å½•
            exp_results_dir = self.temp_results_dir / project_id / config_name
            exp_results_dir.mkdir(parents=True, exist_ok=True)
            
            # æ›´æ–°é…ç½®ä¸­çš„ä¿å­˜è·¯å¾„
            config['save_dir'] = str(exp_results_dir)
            config['save_options']['save_model'] = False
            config['save_options']['save_summary'] = False
            config['save_options']['save_predictions'] = False
            config['save_options']['save_training_log'] = False
            config['save_options']['save_excel_results'] = False
            
            # ä¿å­˜æ›´æ–°çš„é…ç½®
            updated_config_file = exp_results_dir / "config.yaml"
            with open(updated_config_file, 'w', encoding='utf-8') as f:
                yaml.dump(config, f, default_flow_style=False, allow_unicode=True)
            
            # è¿è¡Œå®éªŒ
            start_time = time.time()
            
            # è°ƒç”¨ä¸»ç¨‹åº
            cmd = [sys.executable, "main.py", "--config", str(updated_config_file)]
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=3600)  # 1å°æ—¶è¶…æ—¶
            
            end_time = time.time()
            duration = end_time - start_time
            
            if result.returncode == 0:
                logger.info(f"âœ… å®éªŒå®Œæˆ: {project_id} - {config_name} (è€—æ—¶: {duration:.1f}ç§’)")
                
                # æ”¶é›†ç»“æœ
                result_data = self._collect_experiment_results(
                    project_id, config_name, config, duration, exp_results_dir
                )
                
                # ä¿å­˜åˆ°Drive
                self.drive_saver.save_experiment_result(project_id, result_data)
                
                return {
                    'project_id': project_id,
                    'config_name': config_name,
                    'status': 'completed',
                    'duration': duration,
                    'result_data': result_data
                }
            else:
                logger.error(f"âŒ å®éªŒå¤±è´¥: {project_id} - {config_name}")
                logger.error(f"é”™è¯¯è¾“å‡º: {result.stderr}")
                
                # ä¿å­˜å¤±è´¥ç»“æœ
                result_data = {
                    'config_name': config_name,
                    'status': 'failed',
                    'duration': duration,
                    'error_message': result.stderr
                }
                
                self.drive_saver.save_experiment_result(project_id, result_data)
                
                return {
                    'project_id': project_id,
                    'config_name': config_name,
                    'status': 'failed',
                    'duration': duration,
                    'error': result.stderr
                }
                
        except subprocess.TimeoutExpired:
            logger.error(f"â° å®éªŒè¶…æ—¶: {project_id} - {config_name}")
            
            result_data = {
                'config_name': config_name,
                'status': 'timeout',
                'duration': 3600,
                'error_message': 'Experiment timeout (1 hour)'
            }
            
            self.drive_saver.save_experiment_result(project_id, result_data)
            
            return {
                'project_id': project_id,
                'config_name': config_name,
                'status': 'timeout',
                'duration': 3600,
                'error': 'Timeout'
            }
        except Exception as e:
            logger.error(f"ğŸ’¥ å®éªŒå¼‚å¸¸: {project_id} - {config_name}: {e}")
            
            result_data = {
                'config_name': config_name,
                'status': 'error',
                'duration': 0,
                'error_message': str(e)
            }
            
            self.drive_saver.save_experiment_result(project_id, result_data)
            
            return {
                'project_id': project_id,
                'config_name': config_name,
                'status': 'error',
                'duration': 0,
                'error': str(e)
            }
    
    def _collect_experiment_results(self, project_id: str, config_name: str, 
                                  config: Dict, duration: float, 
                                  exp_results_dir: Path) -> Dict:
        """æ”¶é›†å®éªŒç»“æœ"""
        result_data = {
            'config_name': config_name,
            'status': 'completed',
            'duration': duration,
            'timestamp': datetime.now().isoformat(),
            
            # é…ç½®ä¿¡æ¯
            'model': config.get('model', ''),
            'model_complexity': config.get('model_complexity', ''),
            'input_category': self._extract_input_category(config_name),
            'lookback_hours': config.get('past_hours', 24),
            'use_time_encoding': config.get('use_time_encoding', False),
            
            # é»˜è®¤å€¼
            'mae': np.nan,
            'rmse': np.nan,
            'r2': np.nan,
            'mape': np.nan,
            'train_time_sec': np.nan,
            'inference_time_sec': np.nan,
            'param_count': np.nan,
            'samples_count': np.nan
        }
        
        # å°è¯•ä»ç»“æœæ–‡ä»¶ä¸­è¯»å–æŒ‡æ ‡
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰ç»“æœæ–‡ä»¶
            results_files = list(exp_results_dir.glob("*.csv"))
            if results_files:
                # è¯»å–ç¬¬ä¸€ä¸ªCSVæ–‡ä»¶ï¼ˆé€šå¸¸æ˜¯ç»“æœæ–‡ä»¶ï¼‰
                df = pd.read_csv(results_files[0])
                
                # å°è¯•æå–æŒ‡æ ‡
                if 'MAE' in df.columns:
                    result_data['mae'] = df['MAE'].iloc[0] if len(df) > 0 else np.nan
                if 'RMSE' in df.columns:
                    result_data['rmse'] = df['RMSE'].iloc[0] if len(df) > 0 else np.nan
                if 'RÂ²' in df.columns:
                    result_data['r2'] = df['RÂ²'].iloc[0] if len(df) > 0 else np.nan
                if 'MAPE' in df.columns:
                    result_data['mape'] = df['MAPE'].iloc[0] if len(df) > 0 else np.nan
                
        except Exception as e:
            logger.warning(f"æ— æ³•è¯»å–ç»“æœæ–‡ä»¶: {e}")
        
        return result_data
    
    def _extract_input_category(self, config_name: str) -> str:
        """ä»é…ç½®åç§°ä¸­æå–è¾“å…¥ç‰¹å¾ç±»åˆ«"""
        if 'PV_plus_NWP_plus' in config_name:
            return 'PV_plus_NWP_plus'
        elif 'PV_plus_NWP' in config_name:
            return 'PV_plus_NWP'
        elif 'PV_plus_HW' in config_name:
            return 'PV_plus_HW'
        elif 'NWP_plus' in config_name and 'PV' not in config_name:
            return 'NWP_plus'
        elif 'NWP' in config_name and 'PV' not in config_name:
            return 'NWP'
        elif 'PV' in config_name and 'plus' not in config_name:
            return 'PV'
        else:
            return 'Unknown'
    
    def run_project_experiments(self, project_id: str) -> Dict:
        """è¿è¡Œå•ä¸ªProjectçš„æ‰€æœ‰å®éªŒ"""
        logger.info(f"ğŸ“ å¼€å§‹å¤„ç†Project: {project_id}")
        
        # è·å–å¾…æ‰§è¡Œçš„å®éªŒ
        pending_configs = self.checkpoint_manager.get_pending_experiments(project_id)
        
        if not pending_configs:
            logger.info(f"âœ… {project_id} æ‰€æœ‰å®éªŒå·²å®Œæˆ")
            return {
                'project_id': project_id,
                'total_experiments': 0,
                'completed_experiments': 0,
                'failed_experiments': 0,
                'duration': 0
            }
        
        logger.info(f"ğŸ“Š {project_id} å¾…æ‰§è¡Œå®éªŒ: {len(pending_configs)}")
        
        # è¿è¡Œå®éªŒ
        start_time = time.time()
        completed_count = 0
        failed_count = 0
        
        for i, config_info in enumerate(pending_configs):
            if not self.running:
                logger.info(f"ğŸ›‘ æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œä¸­æ–­ {project_id} å®éªŒ")
                break
            
            try:
                result = self.run_single_experiment(project_id, config_info)
                
                if result['status'] == 'completed':
                    completed_count += 1
                else:
                    failed_count += 1
                
                # æ›´æ–°ç»Ÿè®¡
                self.stats['completed_experiments'] += 1
                if result['status'] != 'completed':
                    self.stats['failed_experiments'] += 1
                
                # å®šæœŸåŒæ­¥åˆ°Drive
                if (i + 1) % 10 == 0:
                    self.drive_saver.sync_to_drive()
                    logger.info(f"ğŸ“¤ {project_id} å·²åŒæ­¥ {i + 1}/{len(pending_configs)} ä¸ªå®éªŒ")
                
            except Exception as e:
                logger.error(f"ğŸ’¥ {project_id} å®éªŒå¼‚å¸¸: {e}")
                failed_count += 1
                self.stats['failed_experiments'] += 1
        
        end_time = time.time()
        duration = end_time - start_time
        
        # æœ€ç»ˆåŒæ­¥
        self.drive_saver.sync_to_drive()
        
        logger.info(f"ğŸ‰ {project_id} å®Œæˆ: {completed_count} æˆåŠŸ, {failed_count} å¤±è´¥, è€—æ—¶: {duration:.1f}ç§’")
        
        return {
            'project_id': project_id,
            'total_experiments': len(pending_configs),
            'completed_experiments': completed_count,
            'failed_experiments': failed_count,
            'duration': duration
        }
    
    def run_all_projects(self, project_ids: List[str] = None):
        """è¿è¡Œæ‰€æœ‰Projectçš„å®éªŒ"""
        if project_ids is None:
            # è·å–æ‰€æœ‰æœªå®Œæˆçš„Project
            project_ids = self.checkpoint_manager.get_incomplete_projects()
        
        if not project_ids:
            logger.info("ğŸ‰ æ‰€æœ‰Projectå®éªŒå·²å®Œæˆ!")
            return
        
        logger.info(f"ğŸš€ å¼€å§‹è¿è¡Œ {len(project_ids)} ä¸ªProjectçš„å®éªŒ")
        
        self.stats['start_time'] = datetime.now()
        self.stats['total_experiments'] = sum(
            len(self.checkpoint_manager.get_pending_experiments(pid)) 
            for pid in project_ids
        )
        
        logger.info(f"ğŸ“Š æ€»å®éªŒæ•°: {self.stats['total_experiments']}")
        
        # æŒ‰æ‰¹æ¬¡å¤„ç†Project
        for i in range(0, len(project_ids), self.batch_size):
            if not self.running:
                logger.info("ğŸ›‘ æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œä¸­æ–­æ‰€æœ‰å®éªŒ")
                break
            
            batch = project_ids[i:i + self.batch_size]
            logger.info(f"ğŸ“¦ å¤„ç†æ‰¹æ¬¡ {i//self.batch_size + 1}: {batch}")
            
            # å¹¶è¡Œè¿è¡Œæ‰¹æ¬¡å†…çš„Project
            with ProcessPoolExecutor(max_workers=self.max_workers) as executor:
                future_to_project = {
                    executor.submit(self.run_project_experiments, project_id): project_id
                    for project_id in batch
                }
                
                for future in as_completed(future_to_project):
                    project_id = future_to_project[future]
                    try:
                        result = future.result()
                        logger.info(f"âœ… {project_id} æ‰¹æ¬¡å®Œæˆ: {result}")
                    except Exception as e:
                        logger.error(f"âŒ {project_id} æ‰¹æ¬¡å¤±è´¥: {e}")
            
            # æ‰¹æ¬¡é—´åŒæ­¥
            self.drive_saver.sync_to_drive()
            
            # ç”Ÿæˆè¿›åº¦æŠ¥å‘Š
            self.checkpoint_manager.save_progress_report()
            
            logger.info(f"ğŸ“Š å½“å‰è¿›åº¦: {self.stats['completed_experiments']}/{self.stats['total_experiments']}")
        
        # æœ€ç»ˆç»Ÿè®¡
        self._print_final_statistics()
    
    def _print_final_statistics(self):
        """æ‰“å°æœ€ç»ˆç»Ÿè®¡ä¿¡æ¯"""
        if self.stats['start_time']:
            total_duration = (datetime.now() - self.stats['start_time']).total_seconds()
            logger.info("\n" + "=" * 60)
            logger.info("ğŸ‰ æ‰€æœ‰å®éªŒå®Œæˆ!")
            logger.info(f"ğŸ“Š æ€»å®éªŒæ•°: {self.stats['total_experiments']}")
            logger.info(f"âœ… æˆåŠŸå®Œæˆ: {self.stats['completed_experiments']}")
            logger.info(f"âŒ å¤±è´¥å®éªŒ: {self.stats['failed_experiments']}")
            logger.info(f"â±ï¸ æ€»è€—æ—¶: {total_duration/3600:.1f} å°æ—¶")
            logger.info(f"ğŸ“ˆ æˆåŠŸç‡: {self.stats['completed_experiments']/self.stats['total_experiments']*100:.1f}%")
            logger.info("=" * 60)

def main():
    parser = argparse.ArgumentParser(description="è¿è¡Œ100ä¸ªProjectçš„æ¶ˆèå®éªŒ")
    parser.add_argument("--drive-path", default="/content/drive/MyDrive/Solar PV electricity/ablation results",
                       help="Google Driveç»“æœä¿å­˜è·¯å¾„")
    parser.add_argument("--max-workers", type=int, default=4,
                       help="æœ€å¤§å¹¶å‘æ•°")
    parser.add_argument("--batch-size", type=int, default=10,
                       help="æ‰¹æ¬¡å¤§å°")
    parser.add_argument("--project-ids", nargs="+",
                       help="æŒ‡å®šè¦è¿è¡Œçš„Project IDåˆ—è¡¨")
    
    args = parser.parse_args()
    
    runner = MultiProjectExperimentRunner(
        drive_path=args.drive_path,
        max_workers=args.max_workers,
        batch_size=args.batch_size
    )
    
    try:
        runner.run_all_projects(args.project_ids)
    except KeyboardInterrupt:
        logger.info("ğŸ›‘ ç”¨æˆ·ä¸­æ–­ï¼Œå¼€å§‹ä¼˜é›…å…³é—­...")
        runner.running = False
    except Exception as e:
        logger.error(f"ğŸ’¥ è¿è¡Œå¼‚å¸¸: {e}")
        raise

if __name__ == "__main__":
    main()
