#!/usr/bin/env python3
"""
é«˜æ€§èƒ½100ä¸ªProjectæ¶ˆèå®éªŒè¿è¡Œå™¨
é’ˆå¯¹A100 GPUä¼˜åŒ–çš„å¹¶è¡Œç­–ç•¥
"""

import os
import sys
import time
import yaml
import pandas as pd
import numpy as np
from datetime import datetime
from pathlib import Path
import subprocess
import argparse
from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor, as_completed
import logging
import signal
import threading
import multiprocessing as mp
import torch
import queue
import psutil

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(str(Path(__file__).parent.parent))

from utils.drive_results_saver import DriveResultsSaver
from utils.checkpoint_manager import CheckpointManager

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('high_performance_experiments.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class HighPerformanceExperimentRunner:
    """é«˜æ€§èƒ½å®éªŒè¿è¡Œå™¨ - é’ˆå¯¹A100ä¼˜åŒ–"""
    
    def __init__(self, 
                 drive_path: str = "/content/drive/MyDrive/Solar PV electricity/ablation results",
                 max_gpu_experiments: int = 8,  # GPUå¹¶è¡Œå®éªŒæ•°
                 max_cpu_experiments: int = 16,  # CPUå¹¶è¡Œå®éªŒæ•°
                 batch_size: int = 20):
        self.drive_saver = DriveResultsSaver(drive_path)
        self.checkpoint_manager = CheckpointManager(drive_path)
        
        # å¹¶è¡Œç­–ç•¥å‚æ•°
        self.max_gpu_experiments = max_gpu_experiments
        self.max_cpu_experiments = max_cpu_experiments
        self.batch_size = batch_size
        
        # åˆ›å»ºä¸´æ—¶ç»“æœç›®å½•
        self.temp_results_dir = Path("./temp_results")
        self.temp_results_dir.mkdir(parents=True, exist_ok=True)
        
        # è¿è¡ŒçŠ¶æ€
        self.running = True
        self.stats = {
            'total_experiments': 0,
            'completed_experiments': 0,
            'failed_experiments': 0,
            'gpu_experiments': 0,
            'cpu_experiments': 0,
            'start_time': None
        }
        
        # è®¾ç½®ä¿¡å·å¤„ç†
        signal.signal(signal.SIGINT, self._signal_handler)
        signal.signal(signal.SIGTERM, self._signal_handler)
        
        # æ£€æµ‹ç³»ç»Ÿèµ„æº
        self._detect_system_resources()
        
        logger.info(f"é«˜æ€§èƒ½å®éªŒè¿è¡Œå™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"GPUå¹¶è¡Œæ•°: {self.max_gpu_experiments}")
        logger.info(f"CPUå¹¶è¡Œæ•°: {self.max_cpu_experiments}")
        logger.info(f"æ‰¹æ¬¡å¤§å°: {self.batch_size}")
    
    def _detect_system_resources(self):
        """æ£€æµ‹ç³»ç»Ÿèµ„æº"""
        # æ£€æµ‹GPU
        if torch.cuda.is_available():
            gpu_count = torch.cuda.device_count()
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3  # GB
            logger.info(f"ğŸš€ æ£€æµ‹åˆ° {gpu_count} ä¸ªGPUï¼Œæ€»å†…å­˜: {gpu_memory:.1f}GB")
            
            # æ ¹æ®GPUå†…å­˜è°ƒæ•´å¹¶è¡Œæ•°
            if gpu_memory >= 80:  # A100 80GB
                self.max_gpu_experiments = min(16, gpu_count * 4)
                logger.info(f"ğŸ¯ A100æ£€æµ‹åˆ°ï¼Œä¼˜åŒ–GPUå¹¶è¡Œæ•°ä¸º: {self.max_gpu_experiments}")
            elif gpu_memory >= 40:  # A100 40GB æˆ–å…¶ä»–é«˜ç«¯GPU
                self.max_gpu_experiments = min(12, gpu_count * 3)
                logger.info(f"ğŸ¯ é«˜ç«¯GPUæ£€æµ‹åˆ°ï¼Œä¼˜åŒ–GPUå¹¶è¡Œæ•°ä¸º: {self.max_gpu_experiments}")
            else:
                self.max_gpu_experiments = min(8, gpu_count * 2)
        else:
            logger.warning("âš ï¸ æœªæ£€æµ‹åˆ°GPUï¼Œå°†ä½¿ç”¨CPUæ¨¡å¼")
            self.max_gpu_experiments = 0
        
        # æ£€æµ‹CPU
        cpu_count = mp.cpu_count()
        memory_gb = psutil.virtual_memory().total / 1024**3
        
        # æ ¹æ®CPUå’Œå†…å­˜è°ƒæ•´CPUå¹¶è¡Œæ•°
        if memory_gb >= 128:  # å¤§å†…å­˜ç³»ç»Ÿ
            self.max_cpu_experiments = min(cpu_count * 2, 32)
        elif memory_gb >= 64:  # ä¸­ç­‰å†…å­˜ç³»ç»Ÿ
            self.max_cpu_experiments = min(cpu_count, 24)
        else:  # å°å†…å­˜ç³»ç»Ÿ
            self.max_cpu_experiments = min(cpu_count // 2, 16)
        
        logger.info(f"ğŸ’» CPUæ ¸å¿ƒæ•°: {cpu_count}, å†…å­˜: {memory_gb:.1f}GB")
        logger.info(f"ğŸ¯ ä¼˜åŒ–CPUå¹¶è¡Œæ•°ä¸º: {self.max_cpu_experiments}")
    
    def _signal_handler(self, signum, frame):
        """ä¿¡å·å¤„ç†å™¨ï¼Œç”¨äºä¼˜é›…å…³é—­"""
        logger.info(f"æ”¶åˆ°ä¿¡å· {signum}ï¼Œå¼€å§‹ä¼˜é›…å…³é—­...")
        self.running = False
    
    def _classify_experiment_type(self, config):
        """åˆ†ç±»å®éªŒç±»å‹ï¼ˆGPU vs CPUï¼‰"""
        model = config.get('model', '')
        
        # æ·±åº¦å­¦ä¹ æ¨¡å‹ä½¿ç”¨GPU
        gpu_models = {'LSTM', 'GRU', 'TCN', 'Transformer'}
        if model in gpu_models:
            return 'gpu'
        else:
            return 'cpu'
    
    def _run_gpu_experiment_batch(self, experiments):
        """æ‰¹é‡è¿è¡ŒGPUå®éªŒ"""
        if not experiments:
            return []
        
        results = []
        
        # ä½¿ç”¨ThreadPoolExecutorè¿›è¡ŒGPUå®éªŒçš„å¹¶è¡Œ
        with ThreadPoolExecutor(max_workers=self.max_gpu_experiments) as executor:
            future_to_exp = {
                executor.submit(self._run_single_experiment, exp): exp
                for exp in experiments
            }
            
            for future in as_completed(future_to_exp):
                if not self.running:
                    break
                
                exp = future_to_exp[future]
                try:
                    result = future.result()
                    results.append(result)
                    
                    if result['status'] == 'completed':
                        self.stats['gpu_experiments'] += 1
                        logger.info(f"ğŸš€ GPUå®éªŒå®Œæˆ: {exp['project_id']} - {exp['config_name']}")
                    else:
                        logger.error(f"âŒ GPUå®éªŒå¤±è´¥: {exp['project_id']} - {exp['config_name']}")
                    
                except Exception as e:
                    logger.error(f"ğŸ’¥ GPUå®éªŒå¼‚å¸¸: {exp['project_id']} - {exp['config_name']}: {e}")
                    results.append({
                        'project_id': exp['project_id'],
                        'config_name': exp['config_name'],
                        'status': 'error',
                        'error': str(e)
                    })
        
        return results
    
    def _run_cpu_experiment_batch(self, experiments):
        """æ‰¹é‡è¿è¡ŒCPUå®éªŒ"""
        if not experiments:
            return []
        
        results = []
        
        # ä½¿ç”¨ProcessPoolExecutorè¿›è¡ŒCPUå®éªŒçš„å¹¶è¡Œ
        with ProcessPoolExecutor(max_workers=self.max_cpu_experiments) as executor:
            future_to_exp = {
                executor.submit(self._run_single_experiment, exp): exp
                for exp in experiments
            }
            
            for future in as_completed(future_to_exp):
                if not self.running:
                    break
                
                exp = future_to_exp[future]
                try:
                    result = future.result()
                    results.append(result)
                    
                    if result['status'] == 'completed':
                        self.stats['cpu_experiments'] += 1
                        logger.info(f"ğŸ’» CPUå®éªŒå®Œæˆ: {exp['project_id']} - {exp['config_name']}")
                    else:
                        logger.error(f"âŒ CPUå®éªŒå¤±è´¥: {exp['project_id']} - {exp['config_name']}")
                    
                except Exception as e:
                    logger.error(f"ğŸ’¥ CPUå®éªŒå¼‚å¸¸: {exp['project_id']} - {exp['config_name']}: {e}")
                    results.append({
                        'project_id': exp['project_id'],
                        'config_name': exp['config_name'],
                        'status': 'error',
                        'error': str(e)
                    })
        
        return results
    
    def _run_single_experiment(self, experiment_info):
        """è¿è¡Œå•ä¸ªå®éªŒï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰"""
        try:
            project_id = experiment_info['project_id']
            config_name = experiment_info['config_name']
            config = experiment_info['config']
            config_file = experiment_info['file_path']
            
            # åˆ›å»ºå®éªŒç‰¹å®šçš„ç»“æœç›®å½•
            exp_results_dir = self.temp_results_dir / project_id / config_name
            exp_results_dir.mkdir(parents=True, exist_ok=True)
            
            # æ›´æ–°é…ç½®ä¸­çš„ä¿å­˜è·¯å¾„
            config['save_dir'] = str(exp_results_dir)
            config['save_options']['save_model'] = False
            config['save_options']['save_summary'] = False
            config['save_options']['save_predictions'] = False
            config['save_options']['save_training_log'] = False
            config['save_options']['save_excel_results'] = False
            
            # ä¼˜åŒ–è®­ç»ƒå‚æ•°ï¼ˆé’ˆå¯¹A100ï¼‰
            if self._classify_experiment_type(config) == 'gpu':
                # GPUå®éªŒä¼˜åŒ–
                config['train_params']['batch_size'] = min(64, config['train_params'].get('batch_size', 32) * 2)
                config['train_params']['learning_rate'] = config['train_params'].get('learning_rate', 5e-4) * 1.5
                # å¢åŠ æ··åˆç²¾åº¦è®­ç»ƒ
                config['train_params']['use_amp'] = True
            
            # ä¿å­˜æ›´æ–°çš„é…ç½®
            updated_config_file = exp_results_dir / "config.yaml"
            with open(updated_config_file, 'w', encoding='utf-8') as f:
                yaml.dump(config, f, default_flow_style=False, allow_unicode=True)
            
            # è¿è¡Œå®éªŒ
            start_time = time.time()
            
            # è°ƒç”¨ä¸»ç¨‹åº
            cmd = [sys.executable, "main.py", "--config", str(updated_config_file)]
            
            # è®¾ç½®ç¯å¢ƒå˜é‡ä¼˜åŒ–
            env = os.environ.copy()
            env['CUDA_VISIBLE_DEVICES'] = '0'  # ä½¿ç”¨ç¬¬ä¸€ä¸ªGPU
            env['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'
            
            result = subprocess.run(
                cmd, 
                capture_output=True, 
                text=True, 
                timeout=1800,  # 30åˆ†é’Ÿè¶…æ—¶ï¼ˆä¼˜åŒ–ååº”è¯¥æ›´å¿«ï¼‰
                env=env
            )
            
            end_time = time.time()
            duration = end_time - start_time
            
            if result.returncode == 0:
                # æ”¶é›†ç»“æœ
                result_data = self._collect_experiment_results(
                    project_id, config_name, config, duration, exp_results_dir
                )
                
                # ä¿å­˜åˆ°Drive
                self.drive_saver.save_experiment_result(project_id, result_data)
                
                return {
                    'project_id': project_id,
                    'config_name': config_name,
                    'status': 'completed',
                    'duration': duration,
                    'result_data': result_data
                }
            else:
                # ä¿å­˜å¤±è´¥ç»“æœ
                result_data = {
                    'config_name': config_name,
                    'status': 'failed',
                    'duration': duration,
                    'error_message': result.stderr
                }
                
                self.drive_saver.save_experiment_result(project_id, result_data)
                
                return {
                    'project_id': project_id,
                    'config_name': config_name,
                    'status': 'failed',
                    'duration': duration,
                    'error': result.stderr
                }
                
        except subprocess.TimeoutExpired:
            result_data = {
                'config_name': config_name,
                'status': 'timeout',
                'duration': 1800,
                'error_message': 'Experiment timeout (30 minutes)'
            }
            
            self.drive_saver.save_experiment_result(project_id, result_data)
            
            return {
                'project_id': project_id,
                'config_name': config_name,
                'status': 'timeout',
                'duration': 1800,
                'error': 'Timeout'
            }
        except Exception as e:
            result_data = {
                'config_name': config_name,
                'status': 'error',
                'duration': 0,
                'error_message': str(e)
            }
            
            self.drive_saver.save_experiment_result(project_id, result_data)
            
            return {
                'project_id': project_id,
                'config_name': config_name,
                'status': 'error',
                'duration': 0,
                'error': str(e)
            }
    
    def _collect_experiment_results(self, project_id: str, config_name: str, 
                                  config: dict, duration: float, 
                                  exp_results_dir: Path) -> dict:
        """æ”¶é›†å®éªŒç»“æœ"""
        result_data = {
            'config_name': config_name,
            'status': 'completed',
            'duration': duration,
            'timestamp': datetime.now().isoformat(),
            
            # é…ç½®ä¿¡æ¯
            'model': config.get('model', ''),
            'model_complexity': config.get('model_complexity', ''),
            'input_category': self._extract_input_category(config_name),
            'lookback_hours': config.get('past_hours', 24),
            'use_time_encoding': config.get('use_time_encoding', False),
            
            # é»˜è®¤å€¼
            'mae': np.nan,
            'rmse': np.nan,
            'r2': np.nan,
            'mape': np.nan,
            'train_time_sec': np.nan,
            'inference_time_sec': np.nan,
            'param_count': np.nan,
            'samples_count': np.nan
        }
        
        # å°è¯•ä»ç»“æœæ–‡ä»¶ä¸­è¯»å–æŒ‡æ ‡
        try:
            results_files = list(exp_results_dir.glob("*.csv"))
            if results_files:
                df = pd.read_csv(results_files[0])
                
                if 'MAE' in df.columns:
                    result_data['mae'] = df['MAE'].iloc[0] if len(df) > 0 else np.nan
                if 'RMSE' in df.columns:
                    result_data['rmse'] = df['RMSE'].iloc[0] if len(df) > 0 else np.nan
                if 'RÂ²' in df.columns:
                    result_data['r2'] = df['RÂ²'].iloc[0] if len(df) > 0 else np.nan
                if 'MAPE' in df.columns:
                    result_data['mape'] = df['MAPE'].iloc[0] if len(df) > 0 else np.nan
                
        except Exception as e:
            logger.warning(f"æ— æ³•è¯»å–ç»“æœæ–‡ä»¶: {e}")
        
        return result_data
    
    def _extract_input_category(self, config_name: str) -> str:
        """ä»é…ç½®åç§°ä¸­æå–è¾“å…¥ç‰¹å¾ç±»åˆ«"""
        if 'PV_plus_NWP_plus' in config_name:
            return 'PV_plus_NWP_plus'
        elif 'PV_plus_NWP' in config_name:
            return 'PV_plus_NWP'
        elif 'PV_plus_HW' in config_name:
            return 'PV_plus_HW'
        elif 'NWP_plus' in config_name and 'PV' not in config_name:
            return 'NWP_plus'
        elif 'NWP' in config_name and 'PV' not in config_name:
            return 'NWP'
        elif 'PV' in config_name and 'plus' not in config_name:
            return 'PV'
        else:
            return 'Unknown'
    
    def run_high_performance_experiments(self, project_ids: list = None):
        """è¿è¡Œé«˜æ€§èƒ½å®éªŒ"""
        if project_ids is None:
            project_ids = self.checkpoint_manager.get_incomplete_projects()
        
        if not project_ids:
            logger.info("ğŸ‰ æ‰€æœ‰Projectå®éªŒå·²å®Œæˆ!")
            return
        
        logger.info(f"ğŸš€ å¼€å§‹é«˜æ€§èƒ½è¿è¡Œ {len(project_ids)} ä¸ªProjectçš„å®éªŒ")
        
        self.stats['start_time'] = datetime.now()
        
        # æ”¶é›†æ‰€æœ‰å¾…æ‰§è¡Œçš„å®éªŒ
        all_experiments = []
        for project_id in project_ids:
            pending_configs = self.checkpoint_manager.get_pending_experiments(project_id)
            for config_info in pending_configs:
                all_experiments.append({
                    'project_id': project_id,
                    'config_name': config_info['name'],
                    'config': config_info['config'],
                    'file_path': config_info['file_path']
                })
        
        self.stats['total_experiments'] = len(all_experiments)
        logger.info(f"ğŸ“Š æ€»å®éªŒæ•°: {self.stats['total_experiments']}")
        
        # åˆ†ç±»å®éªŒ
        gpu_experiments = []
        cpu_experiments = []
        
        for exp in all_experiments:
            exp_type = self._classify_experiment_type(exp['config'])
            if exp_type == 'gpu':
                gpu_experiments.append(exp)
            else:
                cpu_experiments.append(exp)
        
        logger.info(f"ğŸ¯ GPUå®éªŒ: {len(gpu_experiments)} ä¸ª")
        logger.info(f"ğŸ’» CPUå®éªŒ: {len(cpu_experiments)} ä¸ª")
        
        # åˆ›å»ºä¸¤ä¸ªçº¿ç¨‹åˆ†åˆ«å¤„ç†GPUå’ŒCPUå®éªŒ
        gpu_thread = threading.Thread(target=self._run_gpu_experiments_loop, args=(gpu_experiments,))
        cpu_thread = threading.Thread(target=self._run_cpu_experiments_loop, args=(cpu_experiments,))
        
        # å¯åŠ¨çº¿ç¨‹
        gpu_thread.start()
        cpu_thread.start()
        
        # ç­‰å¾…å®Œæˆ
        gpu_thread.join()
        cpu_thread.join()
        
        # æœ€ç»ˆç»Ÿè®¡
        self._print_final_statistics()
    
    def _run_gpu_experiments_loop(self, experiments):
        """GPUå®éªŒå¾ªç¯"""
        for i in range(0, len(experiments), self.batch_size):
            if not self.running:
                break
            
            batch = experiments[i:i + self.batch_size]
            logger.info(f"ğŸš€ å¤„ç†GPUæ‰¹æ¬¡ {i//self.batch_size + 1}: {len(batch)} ä¸ªå®éªŒ")
            
            results = self._run_gpu_experiment_batch(batch)
            
            # æ›´æ–°ç»Ÿè®¡
            for result in results:
                self.stats['completed_experiments'] += 1
                if result['status'] != 'completed':
                    self.stats['failed_experiments'] += 1
            
            # æ‰¹æ¬¡é—´åŒæ­¥
            self.drive_saver.sync_to_drive()
            
            logger.info(f"ğŸ“Š GPUè¿›åº¦: {self.stats['gpu_experiments']} å®Œæˆ")
    
    def _run_cpu_experiments_loop(self, experiments):
        """CPUå®éªŒå¾ªç¯"""
        for i in range(0, len(experiments), self.batch_size):
            if not self.running:
                break
            
            batch = experiments[i:i + self.batch_size]
            logger.info(f"ğŸ’» å¤„ç†CPUæ‰¹æ¬¡ {i//self.batch_size + 1}: {len(batch)} ä¸ªå®éªŒ")
            
            results = self._run_cpu_experiment_batch(batch)
            
            # æ›´æ–°ç»Ÿè®¡
            for result in results:
                self.stats['completed_experiments'] += 1
                if result['status'] != 'completed':
                    self.stats['failed_experiments'] += 1
            
            # æ‰¹æ¬¡é—´åŒæ­¥
            self.drive_saver.sync_to_drive()
            
            logger.info(f"ğŸ“Š CPUè¿›åº¦: {self.stats['cpu_experiments']} å®Œæˆ")
    
    def _print_final_statistics(self):
        """æ‰“å°æœ€ç»ˆç»Ÿè®¡ä¿¡æ¯"""
        if self.stats['start_time']:
            total_duration = (datetime.now() - self.stats['start_time']).total_seconds()
            logger.info("\n" + "=" * 60)
            logger.info("ğŸ‰ é«˜æ€§èƒ½å®éªŒå®Œæˆ!")
            logger.info(f"ğŸ“Š æ€»å®éªŒæ•°: {self.stats['total_experiments']}")
            logger.info(f"ğŸš€ GPUå®éªŒ: {self.stats['gpu_experiments']}")
            logger.info(f"ğŸ’» CPUå®éªŒ: {self.stats['cpu_experiments']}")
            logger.info(f"âœ… æˆåŠŸå®Œæˆ: {self.stats['completed_experiments']}")
            logger.info(f"âŒ å¤±è´¥å®éªŒ: {self.stats['failed_experiments']}")
            logger.info(f"â±ï¸ æ€»è€—æ—¶: {total_duration/3600:.1f} å°æ—¶")
            logger.info(f"ğŸ“ˆ æˆåŠŸç‡: {self.stats['completed_experiments']/self.stats['total_experiments']*100:.1f}%")
            logger.info(f"ğŸš€ å¹³å‡é€Ÿåº¦: {self.stats['completed_experiments']/total_duration*3600:.1f} å®éªŒ/å°æ—¶")
            logger.info("=" * 60)

def main():
    parser = argparse.ArgumentParser(description="é«˜æ€§èƒ½è¿è¡Œ100ä¸ªProjectçš„æ¶ˆèå®éªŒ")
    parser.add_argument("--drive-path", default="/content/drive/MyDrive/Solar PV electricity/ablation results",
                       help="Google Driveç»“æœä¿å­˜è·¯å¾„")
    parser.add_argument("--max-gpu-experiments", type=int, default=16,
                       help="GPUå¹¶è¡Œå®éªŒæ•°")
    parser.add_argument("--max-cpu-experiments", type=int, default=24,
                       help="CPUå¹¶è¡Œå®éªŒæ•°")
    parser.add_argument("--batch-size", type=int, default=20,
                       help="æ‰¹æ¬¡å¤§å°")
    parser.add_argument("--project-ids", nargs="+",
                       help="æŒ‡å®šè¦è¿è¡Œçš„Project IDåˆ—è¡¨")
    
    args = parser.parse_args()
    
    runner = HighPerformanceExperimentRunner(
        drive_path=args.drive_path,
        max_gpu_experiments=args.max_gpu_experiments,
        max_cpu_experiments=args.max_cpu_experiments,
        batch_size=args.batch_size
    )
    
    try:
        runner.run_high_performance_experiments(args.project_ids)
    except KeyboardInterrupt:
        logger.info("ğŸ›‘ ç”¨æˆ·ä¸­æ–­ï¼Œå¼€å§‹ä¼˜é›…å…³é—­...")
        runner.running = False
    except Exception as e:
        logger.error(f"ğŸ’¥ è¿è¡Œå¼‚å¸¸: {e}")
        raise

if __name__ == "__main__":
    main()
