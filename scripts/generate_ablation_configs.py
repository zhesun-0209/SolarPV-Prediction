#!/usr/bin/env python3
"""
ç”ŸæˆProject1140æ¶ˆèå®éªŒçš„æ‰€æœ‰é…ç½®æ–‡ä»¶
æ ¹æ®3.7 Controlled ablation studyè®¾è®¡ç”Ÿæˆ360ä¸ªå®éªŒé…ç½®
"""

import os
import yaml
from itertools import product

def create_config_dir():
    """åˆ›å»ºé…ç½®ç›®å½•"""
    config_dir = "config/ablation"
    os.makedirs(config_dir, exist_ok=True)
    return config_dir

def get_model_complexity_params():
    """è·å–æ¨¡å‹å¤æ‚åº¦å‚æ•°"""
    return {
        'low': {
            'epochs': 15,
            'tree_params': {
                'n_estimators': 50,
                'max_depth': 5,
                'learning_rate': 0.1
            },
            'dl_params': {
                'd_model': 64,
                'num_heads': 4,
                'num_layers': 6,
                'hidden_dim': 32,
                'dropout': 0.1,
                'tcn_channels': [64, 64, 32],
                'kernel_size': 3
            }
        },
        'high': {
            'epochs': 50,
            'tree_params': {
                'n_estimators': 200,
                'max_depth': 12,
                'learning_rate': 0.01
            },
            'dl_params': {
                'd_model': 256,
                'num_heads': 16,
                'num_layers': 18,
                'hidden_dim': 128,
                'dropout': 0.3,
                'tcn_channels': [128, 128, 64, 32],
                'kernel_size': 3
            }
        }
    }

def generate_base_config():
    """ç”ŸæˆåŸºç¡€é…ç½®æ¨¡æ¿"""
    return {
        'data_path': './data/Project1140.csv',
        'save_dir': './results/ablation',
        'future_hours': 24,
        'train_ratio': 0.8,
        'val_ratio': 0.1,
        'plot_days': 7,
        'start_date': '2022-01-01',
        'end_date': '2024-09-28',
        'train_params': {
            'batch_size': 32,
            'learning_rate': 5e-4,
            'loss_type': 'mse',
            'future_hours': 24
        },
        'save_options': {
            'save_model': False,
            'save_summary': True,
            'save_predictions': True,
            'save_training_log': False,
            'save_excel_results': True
        }
    }

def create_feature_config(input_category, lookback_hours, use_time_encoding):
    """åˆ›å»ºç‰¹å¾é…ç½®"""
    # 11ä¸ªå¤©æ°”ç‰¹å¾ (ä¸_predåç¼€å¯¹åº”çš„å†å²å¤©æ°”ç‰¹å¾)
    weather_features = [
        'global_tilted_irradiance', 'vapour_pressure_deficit', 'relative_humidity_2m',
        'temperature_2m', 'wind_gusts_10m', 'cloud_cover_low', 'wind_speed_100m',
        'snow_depth', 'dew_point_2m', 'precipitation', 'surface_pressure'
    ]
    
    config = {
        'past_hours': lookback_hours,
        'use_time_encoding': use_time_encoding,
        'weather_category': 'ablation_11_features'
    }
    
    # æ ¹æ®è¾“å…¥ç±»åˆ«è®¾ç½®ç‰¹å¾
    if input_category == 'PV':
        config.update({
            'use_pv': True,
            'use_hist_weather': False,
            'use_forecast': False,
            'input_category': 'PV_only'
        })
    elif input_category == 'PV+NWP':
        config.update({
            'use_pv': True,
            'use_hist_weather': False,
            'use_forecast': True,
            'input_category': 'PV_plus_NWP'
        })
    elif input_category == 'PV+NWP+':
        config.update({
            'use_pv': True,
            'use_hist_weather': False,
            'use_forecast': True,
            'use_ideal_nwp': True,
            'input_category': 'PV_plus_ideal_NWP'
        })
    elif input_category == 'PV+HW':
        config.update({
            'use_pv': True,
            'use_hist_weather': True,
            'use_forecast': False,
            'input_category': 'PV_plus_HW'
        })
    elif input_category == 'NWP':
        config.update({
            'use_pv': False,
            'use_hist_weather': False,
            'use_forecast': True,
            'input_category': 'NWP_only'
        })
    elif input_category == 'NWP+':
        config.update({
            'use_pv': False,
            'use_hist_weather': False,
            'use_forecast': True,
            'use_ideal_nwp': True,
            'input_category': 'ideal_NWP_only'
        })
    
    return config

def create_model_config(model_name, complexity, complexity_params):
    """åˆ›å»ºæ¨¡å‹é…ç½®"""
    config = {
        'model': model_name,
        'model_complexity': complexity
    }
    
    if model_name == 'LSR':
        # LSRåŸºçº¿æ¨¡å‹ï¼Œä¸åŒºåˆ†å¤æ‚åº¦
        config.update({
            'epoch_params': {'low': 1, 'high': 1},
            'model_params': {
                'low': {'fit_intercept': True},
                'high': {'fit_intercept': True}
            }
        })
    elif model_name in ['RF', 'XGB', 'LGBM']:
        # æ ‘æ¨¡å‹
        config.update({
            'epoch_params': complexity_params,
            'model_params': {
                'ml_low': complexity_params['low']['tree_params'],
                'ml_high': complexity_params['high']['tree_params']
            }
        })
    else:
        # æ·±åº¦å­¦ä¹ æ¨¡å‹
        config.update({
            'epoch_params': complexity_params,
            'model_params': {
                'low': complexity_params['low']['dl_params'],
                'high': complexity_params['high']['dl_params']
            }
        })
    
    return config

def generate_all_configs():
    """ç”Ÿæˆæ‰€æœ‰360ä¸ªå®éªŒé…ç½®"""
    config_dir = create_config_dir()
    complexity_params = get_model_complexity_params()
    base_config = generate_base_config()
    
    # å®éªŒå‚æ•°
    input_categories = ['PV', 'PV+NWP', 'PV+NWP+', 'PV+HW', 'NWP', 'NWP+']
    lookback_hours = [24, 72]
    time_encoding = [False, True]
    complexities = ['low', 'high']
    models = ['RF', 'XGB', 'LGBM', 'LSTM', 'GRU', 'TCN', 'Transformer']
    baseline_model = 'LSR'
    
    config_count = 0
    
    # ç”Ÿæˆä¸»è¦æ¨¡å‹é…ç½® (7ä¸ªæ¨¡å‹ Ã— 2å¤æ‚åº¦ = 336ä¸ªé…ç½®)
    for input_cat, lookback, te, complexity, model in product(
        input_categories, lookback_hours, time_encoding, complexities, models
    ):
        config = base_config.copy()
        
        # æ·»åŠ ç‰¹å¾é…ç½®
        feature_config = create_feature_config(input_cat, lookback, te)
        config.update(feature_config)
        
        # æ·»åŠ æ¨¡å‹é…ç½®
        model_config = create_model_config(model, complexity, complexity_params)
        config.update(model_config)
        
        # ç”Ÿæˆé…ç½®æ–‡ä»¶å
        config_name = f"{model}_{complexity}_{input_cat.replace('+', '_plus_')}_{lookback}h_{'TE' if te else 'noTE'}.yaml"
        config_path = os.path.join(config_dir, config_name)
        
        # ä¿å­˜é…ç½®æ–‡ä»¶
        with open(config_path, 'w', encoding='utf-8') as f:
            yaml.dump(config, f, default_flow_style=False, allow_unicode=True, sort_keys=False)
        
        config_count += 1
        if config_count % 50 == 0:
            print(f"å·²ç”Ÿæˆ {config_count} ä¸ªé…ç½®æ–‡ä»¶...")
    
    # ç”ŸæˆLSRåŸºçº¿æ¨¡å‹é…ç½® (24ä¸ªé…ç½®ï¼Œä¸åŒºåˆ†å¤æ‚åº¦)
    for input_cat, lookback, te in product(input_categories, lookback_hours, time_encoding):
        config = base_config.copy()
        
        # æ·»åŠ ç‰¹å¾é…ç½®
        feature_config = create_feature_config(input_cat, lookback, te)
        config.update(feature_config)
        
        # æ·»åŠ LSRæ¨¡å‹é…ç½®
        model_config = create_model_config(baseline_model, 'low', complexity_params)
        config.update(model_config)
        
        # ç”Ÿæˆé…ç½®æ–‡ä»¶å
        config_name = f"LSR_baseline_{input_cat.replace('+', '_plus_')}_{lookback}h_{'TE' if te else 'noTE'}.yaml"
        config_path = os.path.join(config_dir, config_name)
        
        # ä¿å­˜é…ç½®æ–‡ä»¶
        with open(config_path, 'w', encoding='utf-8') as f:
            yaml.dump(config, f, default_flow_style=False, allow_unicode=True, sort_keys=False)
        
        config_count += 1
    
    print(f"æ€»å…±ç”Ÿæˆäº† {config_count} ä¸ªé…ç½®æ–‡ä»¶")
    print(f"é…ç½®æ–‡ä»¶ä¿å­˜åœ¨: {config_dir}")
    
    # ç”Ÿæˆé…ç½®ç´¢å¼•æ–‡ä»¶
    generate_config_index(config_dir, config_count)
    
    return config_count

def generate_config_index(config_dir, total_configs):
    """ç”Ÿæˆé…ç½®ç´¢å¼•æ–‡ä»¶"""
    index_file = os.path.join(config_dir, "config_index.yaml")
    
    index_data = {
        'total_configs': total_configs,
        'experiment_design': {
            'input_categories': 6,
            'lookback_hours': 2,
            'time_encoding': 2,
            'model_complexity': 2,
            'ml_models': 7,
            'baseline_model': 1
        },
        'calculation': {
            'main_models': '6 Ã— 2 Ã— 2 Ã— 2 Ã— 7 = 336',
            'baseline_model': '6 Ã— 2 Ã— 2 Ã— 1 = 24',
            'total': '336 + 24 = 360'
        },
        'input_categories': [
            'PV - ä»…å†å²PVåŠŸç‡',
            'PV+NWP - å†å²PV + ç›®æ ‡æ—¥NWP',
            'PV+NWP+ - å†å²PV + ç†æƒ³NWP',
            'PV+HW - å†å²PV + å†å²HW',
            'NWP - ä»…ç›®æ ‡æ—¥NWP',
            'NWP+ - ä»…ç†æƒ³NWP'
        ],
        'models': {
            'ml_models': ['RF', 'XGB', 'LGBM', 'LSTM', 'GRU', 'TCN', 'Transformer'],
            'baseline': ['LSR']
        },
        'weather_features': [
            'global_tilted_irradiance', 'vapour_pressure_deficit', 'relative_humidity_2m',
            'temperature_2m', 'wind_gusts_10m', 'cloud_cover_low', 'wind_speed_100m',
            'snow_depth', 'dew_point_2m', 'precipitation', 'surface_pressure'
        ]
    }
    
    with open(index_file, 'w', encoding='utf-8') as f:
        yaml.dump(index_data, f, default_flow_style=False, allow_unicode=True, sort_keys=False)
    
    print(f"é…ç½®ç´¢å¼•æ–‡ä»¶å·²ç”Ÿæˆ: {index_file}")

if __name__ == "__main__":
    print("å¼€å§‹ç”ŸæˆProject1140æ¶ˆèå®éªŒé…ç½®æ–‡ä»¶...")
    print("å®éªŒè®¾è®¡: 6è¾“å…¥ç±»åˆ« Ã— 2å›çœ‹çª—å£ Ã— 2æ—¶é—´ç¼–ç  Ã— 2å¤æ‚åº¦ Ã— 7æ¨¡å‹ + 24åŸºçº¿ = 360é…ç½®")
    
    total_configs = generate_all_configs()
    
    print(f"\nâœ… é…ç½®ç”Ÿæˆå®Œæˆ!")
    print(f"ğŸ“ é…ç½®æ–‡ä»¶ç›®å½•: config/ablation/")
    print(f"ğŸ“Š æ€»é…ç½®æ•°: {total_configs}")
    print(f"ğŸ“‹ ç´¢å¼•æ–‡ä»¶: config/ablation/config_index.yaml")
