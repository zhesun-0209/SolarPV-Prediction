#!/usr/bin/env python3
"""
GPUä¸“ç”¨å®éªŒè¿è¡Œå™¨ - æ‰€æœ‰æ¨¡å‹éƒ½å¼ºåˆ¶ä½¿ç”¨GPU
åŒ…æ‹¬ä¼ ç»ŸMLæ¨¡å‹çš„GPUç‰ˆæœ¬
"""

import os
import sys
import time
import yaml
import pandas as pd
import numpy as np
from datetime import datetime
from pathlib import Path
import subprocess
import argparse
from concurrent.futures import ThreadPoolExecutor, as_completed
import logging
import signal
import threading
import torch
import queue
from typing import Dict, List, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(str(Path(__file__).parent.parent))

from utils.drive_results_saver import DriveResultsSaver
from utils.checkpoint_manager import CheckpointManager

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('gpu_only_experiments.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class GPUOnlyExperimentRunner:
    """GPUä¸“ç”¨å®éªŒè¿è¡Œå™¨ - æ‰€æœ‰æ¨¡å‹éƒ½ä½¿ç”¨GPU"""
    
    def __init__(self, 
                 drive_path: str = "/content/drive/MyDrive/Solar PV electricity/ablation results",
                 max_gpu_experiments: int = 24,  # å¤§å¹…å¢åŠ GPUå¹¶è¡Œæ•°
                 batch_size: int = 30):
        self.drive_saver = DriveResultsSaver(drive_path)
        self.checkpoint_manager = CheckpointManager(drive_path)
        
        # GPUä¸“ç”¨å‚æ•°
        self.max_gpu_experiments = max_gpu_experiments
        self.batch_size = batch_size
        
        # åˆ›å»ºä¸´æ—¶ç»“æœç›®å½•
        self.temp_results_dir = Path("./temp_results")
        self.temp_results_dir.mkdir(parents=True, exist_ok=True)
        
        # è¿è¡ŒçŠ¶æ€
        self.running = True
        self.stats = {
            'total_experiments': 0,
            'completed_experiments': 0,
            'failed_experiments': 0,
            'gpu_experiments': 0,
            'start_time': None
        }
        
        # è®¾ç½®ä¿¡å·å¤„ç†
        signal.signal(signal.SIGINT, self._signal_handler)
        signal.signal(signal.SIGTERM, self._signal_handler)
        
        # æ£€æµ‹GPUèµ„æº
        self._detect_gpu_resources()
        
        logger.info(f"GPUä¸“ç”¨å®éªŒè¿è¡Œå™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"GPUå¹¶è¡Œæ•°: {self.max_gpu_experiments}")
        logger.info(f"æ‰¹æ¬¡å¤§å°: {self.batch_size}")
    
    def _detect_gpu_resources(self):
        """æ£€æµ‹GPUèµ„æº"""
        if torch.cuda.is_available():
            self.gpu_count = torch.cuda.device_count()
            self.gpu_memory_total = []
            
            for i in range(self.gpu_count):
                props = torch.cuda.get_device_properties(i)
                total_memory = props.total_memory / 1024**3  # GB
                self.gpu_memory_total.append(total_memory)
                logger.info(f"GPU {i}: {props.name} ({total_memory:.1f}GB)")
            
            # æ ¹æ®GPUå†…å­˜è°ƒæ•´å¹¶è¡Œæ•°
            max_memory = max(self.gpu_memory_total)
            if max_memory >= 80:  # A100 80GB
                self.max_gpu_experiments = min(32, self.gpu_count * 8)
                logger.info(f"ğŸ¯ A100 80GBæ£€æµ‹åˆ°ï¼Œä¼˜åŒ–GPUå¹¶è¡Œæ•°ä¸º: {self.max_gpu_experiments}")
            elif max_memory >= 40:  # A100 40GB
                self.max_gpu_experiments = min(24, self.gpu_count * 6)
                logger.info(f"ğŸ¯ A100 40GBæ£€æµ‹åˆ°ï¼Œä¼˜åŒ–GPUå¹¶è¡Œæ•°ä¸º: {self.max_gpu_experiments}")
            elif max_memory >= 24:  # RTX 3090/4090
                self.max_gpu_experiments = min(16, self.gpu_count * 4)
                logger.info(f"ğŸ¯ é«˜ç«¯GPUæ£€æµ‹åˆ°ï¼Œä¼˜åŒ–GPUå¹¶è¡Œæ•°ä¸º: {self.max_gpu_experiments}")
            else:
                self.max_gpu_experiments = min(8, self.gpu_count * 2)
                logger.info(f"ğŸ’» æ ‡å‡†GPUï¼Œè®¾ç½®å¹¶è¡Œæ•°ä¸º: {self.max_gpu_experiments}")
        else:
            logger.error("âŒ æœªæ£€æµ‹åˆ°GPUï¼Œæ— æ³•è¿è¡ŒGPUä¸“ç”¨å®éªŒ")
            sys.exit(1)
    
    def _signal_handler(self, signum, frame):
        """ä¿¡å·å¤„ç†å™¨ï¼Œç”¨äºä¼˜é›…å…³é—­"""
        logger.info(f"æ”¶åˆ°ä¿¡å· {signum}ï¼Œå¼€å§‹ä¼˜é›…å…³é—­...")
        self.running = False
    
    def _optimize_config_for_gpu(self, config):
        """ä¸ºGPUä¼˜åŒ–é…ç½®"""
        model = config.get('model', '')
        
        # å¼ºåˆ¶è®¾ç½®GPUç›¸å…³å‚æ•°
        config['use_gpu'] = True
        config['device'] = 'cuda'
        
        # æ ¹æ®æ¨¡å‹ç±»å‹è®¾ç½®GPUç‰¹å®šå‚æ•°
        if model in ['LSTM', 'GRU', 'TCN', 'Transformer']:
            # æ·±åº¦å­¦ä¹ æ¨¡å‹
            config['train_params']['use_amp'] = True
            config['train_params']['batch_size'] = min(128, config['train_params'].get('batch_size', 32) * 4)
            config['train_params']['gradient_accumulation_steps'] = 2
        elif model in ['RF', 'XGB', 'LGBM']:
            # æ ‘æ¨¡å‹GPUç‰ˆæœ¬
            config['train_params']['tree_method'] = 'gpu_hist'  # XGBoost GPU
            config['train_params']['gpu_id'] = 0
            config['train_params']['predictor'] = 'gpu_predictor'
            
            # LightGBM GPU
            if model == 'LGBM':
                config['train_params']['device'] = 'gpu'
                config['train_params']['gpu_platform_id'] = 0
                config['train_params']['gpu_device_id'] = 0
            
            # å¢åŠ æ ·æœ¬æ•°é‡ä»¥å……åˆ†åˆ©ç”¨GPU
            config['train_params']['n_estimators'] = config['train_params'].get('n_estimators', 100) * 2
            config['train_params']['batch_size'] = 1024  # å¤§æ‰¹æ¬¡å¤„ç†
            
        elif model == 'LSR':
            # çº¿æ€§å›å½’ä¹Ÿå¯ä»¥ä½¿ç”¨GPU
            config['train_params']['batch_size'] = 2048  # å¤§æ‰¹æ¬¡å¤„ç†
        
        # é€šç”¨GPUä¼˜åŒ–
        config['train_params']['num_workers'] = min(8, os.cpu_count())
        config['train_params']['pin_memory'] = True
        
        return config
    
    def _run_single_experiment(self, experiment_info):
        """è¿è¡Œå•ä¸ªGPUå®éªŒ"""
        try:
            project_id = experiment_info['project_id']
            config_name = experiment_info['config_name']
            config = experiment_info['config']
            config_file = experiment_info['file_path']
            
            # åˆ›å»ºå®éªŒç‰¹å®šçš„ç»“æœç›®å½•
            exp_results_dir = self.temp_results_dir / project_id / config_name
            exp_results_dir.mkdir(parents=True, exist_ok=True)
            
            # æ›´æ–°é…ç½®ä¸­çš„ä¿å­˜è·¯å¾„
            config['save_dir'] = str(exp_results_dir)
            config['save_options']['save_model'] = False
            config['save_options']['save_summary'] = False
            config['save_options']['save_predictions'] = False
            config['save_options']['save_training_log'] = False
            config['save_options']['save_excel_results'] = False
            
            # GPUä¼˜åŒ–é…ç½®
            config = self._optimize_config_for_gpu(config)
            
            # ä¿å­˜æ›´æ–°çš„é…ç½®
            updated_config_file = exp_results_dir / "config.yaml"
            with open(updated_config_file, 'w', encoding='utf-8') as f:
                yaml.dump(config, f, default_flow_style=False, allow_unicode=True)
            
            # è¿è¡Œå®éªŒ
            start_time = time.time()
            
            # è°ƒç”¨ä¸»ç¨‹åº
            cmd = [sys.executable, "main.py", "--config", str(updated_config_file)]
            
            # è®¾ç½®GPUç¯å¢ƒå˜é‡
            env = os.environ.copy()
            env['CUDA_VISIBLE_DEVICES'] = '0'
            env['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'
            env['PYTORCH_CUDNN_V8_API_ENABLED'] = '1'
            
            # å¼ºåˆ¶ä½¿ç”¨GPU
            env['FORCE_GPU'] = '1'
            env['USE_GPU'] = '1'
            
            result = subprocess.run(
                cmd, 
                capture_output=True, 
                text=True, 
                timeout=1200,  # 20åˆ†é’Ÿè¶…æ—¶ï¼ˆGPUåº”è¯¥æ›´å¿«ï¼‰
                env=env
            )
            
            end_time = time.time()
            duration = end_time - start_time
            
            if result.returncode == 0:
                logger.info(f"âœ… GPUå®éªŒå®Œæˆ: {project_id} - {config_name} (è€—æ—¶: {duration:.1f}ç§’)")
                
                # æ”¶é›†ç»“æœ
                result_data = self._collect_experiment_results(
                    project_id, config_name, config, duration, exp_results_dir
                )
                
                # ä¿å­˜åˆ°Drive
                self.drive_saver.save_experiment_result(project_id, result_data)
                
                return {
                    'project_id': project_id,
                    'config_name': config_name,
                    'status': 'completed',
                    'duration': duration,
                    'result_data': result_data
                }
            else:
                logger.error(f"âŒ GPUå®éªŒå¤±è´¥: {project_id} - {config_name}")
                logger.error(f"é”™è¯¯è¾“å‡º: {result.stderr}")
                
                # ä¿å­˜å¤±è´¥ç»“æœ
                result_data = {
                    'config_name': config_name,
                    'status': 'failed',
                    'duration': duration,
                    'error_message': result.stderr
                }
                
                self.drive_saver.save_experiment_result(project_id, result_data)
                
                return {
                    'project_id': project_id,
                    'config_name': config_name,
                    'status': 'failed',
                    'duration': duration,
                    'error': result.stderr
                }
                
        except subprocess.TimeoutExpired:
            logger.error(f"â° GPUå®éªŒè¶…æ—¶: {project_id} - {config_name}")
            
            result_data = {
                'config_name': config_name,
                'status': 'timeout',
                'duration': 1200,
                'error_message': 'GPU experiment timeout (20 minutes)'
            }
            
            self.drive_saver.save_experiment_result(project_id, result_data)
            
            return {
                'project_id': project_id,
                'config_name': config_name,
                'status': 'timeout',
                'duration': 1200,
                'error': 'Timeout'
            }
        except Exception as e:
            logger.error(f"ğŸ’¥ GPUå®éªŒå¼‚å¸¸: {project_id} - {config_name}: {e}")
            
            result_data = {
                'config_name': config_name,
                'status': 'error',
                'duration': 0,
                'error_message': str(e)
            }
            
            self.drive_saver.save_experiment_result(project_id, result_data)
            
            return {
                'project_id': project_id,
                'config_name': config_name,
                'status': 'error',
                'duration': 0,
                'error': str(e)
            }
    
    def _collect_experiment_results(self, project_id: str, config_name: str, 
                                  config: dict, duration: float, 
                                  exp_results_dir: Path) -> dict:
        """æ”¶é›†å®éªŒç»“æœ"""
        result_data = {
            'config_name': config_name,
            'status': 'completed',
            'duration': duration,
            'timestamp': datetime.now().isoformat(),
            
            # é…ç½®ä¿¡æ¯
            'model': config.get('model', ''),
            'model_complexity': config.get('model_complexity', ''),
            'input_category': self._extract_input_category(config_name),
            'lookback_hours': config.get('past_hours', 24),
            'use_time_encoding': config.get('use_time_encoding', False),
            'use_gpu': True,  # æ ‡è®°ä¸ºGPUå®éªŒ
            
            # é»˜è®¤å€¼
            'mae': np.nan,
            'rmse': np.nan,
            'r2': np.nan,
            'mape': np.nan,
            'train_time_sec': np.nan,
            'inference_time_sec': np.nan,
            'param_count': np.nan,
            'samples_count': np.nan
        }
        
        # å°è¯•ä»ç»“æœæ–‡ä»¶ä¸­è¯»å–æŒ‡æ ‡
        try:
            # ä¼˜å…ˆæŸ¥æ‰¾Excelæ–‡ä»¶
            excel_files = list(exp_results_dir.glob("*.xlsx"))
            if excel_files:
                df = pd.read_excel(excel_files[0])
                
                # ä½¿ç”¨å°å†™åˆ—åï¼ˆExcelæ–‡ä»¶ä¸­ä½¿ç”¨çš„ï¼‰
                if 'mae' in df.columns:
                    result_data['mae'] = df['mae'].iloc[0] if len(df) > 0 else np.nan
                if 'rmse' in df.columns:
                    result_data['rmse'] = df['rmse'].iloc[0] if len(df) > 0 else np.nan
                if 'r_square' in df.columns:
                    result_data['r2'] = df['r_square'].iloc[0] if len(df) > 0 else np.nan
                if 'smape' in df.columns:
                    result_data['mape'] = df['smape'].iloc[0] if len(df) > 0 else np.nan
                if 'train_time_sec' in df.columns:
                    result_data['train_time_sec'] = df['train_time_sec'].iloc[0] if len(df) > 0 else np.nan
                if 'inference_time_sec' in df.columns:
                    result_data['inference_time_sec'] = df['inference_time_sec'].iloc[0] if len(df) > 0 else np.nan
                if 'param_count' in df.columns:
                    result_data['param_count'] = df['param_count'].iloc[0] if len(df) > 0 else np.nan
                if 'samples_count' in df.columns:
                    result_data['samples_count'] = df['samples_count'].iloc[0] if len(df) > 0 else np.nan
                    
            else:
                # å›é€€åˆ°CSVæ–‡ä»¶
                csv_files = list(exp_results_dir.glob("*.csv"))
                if csv_files:
                    df = pd.read_csv(csv_files[0])
                    
                    # å°è¯•å¤šç§å¯èƒ½çš„åˆ—å
                    if 'mae' in df.columns:
                        result_data['mae'] = df['mae'].iloc[0] if len(df) > 0 else np.nan
                    elif 'MAE' in df.columns:
                        result_data['mae'] = df['MAE'].iloc[0] if len(df) > 0 else np.nan
                        
                    if 'rmse' in df.columns:
                        result_data['rmse'] = df['rmse'].iloc[0] if len(df) > 0 else np.nan
                    elif 'RMSE' in df.columns:
                        result_data['rmse'] = df['RMSE'].iloc[0] if len(df) > 0 else np.nan
                        
                    if 'r_square' in df.columns:
                        result_data['r2'] = df['r_square'].iloc[0] if len(df) > 0 else np.nan
                    elif 'RÂ²' in df.columns:
                        result_data['r2'] = df['RÂ²'].iloc[0] if len(df) > 0 else np.nan
                    elif 'r2' in df.columns:
                        result_data['r2'] = df['r2'].iloc[0] if len(df) > 0 else np.nan
                        
                    if 'smape' in df.columns:
                        result_data['mape'] = df['smape'].iloc[0] if len(df) > 0 else np.nan
                    elif 'MAPE' in df.columns:
                        result_data['mape'] = df['MAPE'].iloc[0] if len(df) > 0 else np.nan
                
        except Exception as e:
            logger.warning(f"æ— æ³•è¯»å–ç»“æœæ–‡ä»¶: {e}")
        
        return result_data
    
    def _extract_input_category(self, config_name: str) -> str:
        """ä»é…ç½®åç§°ä¸­æå–è¾“å…¥ç‰¹å¾ç±»åˆ«"""
        if 'PV_plus_NWP_plus' in config_name:
            return 'PV_plus_NWP_plus'
        elif 'PV_plus_NWP' in config_name:
            return 'PV_plus_NWP'
        elif 'PV_plus_HW' in config_name:
            return 'PV_plus_HW'
        elif 'NWP_plus' in config_name and 'PV' not in config_name:
            return 'NWP_plus'
        elif 'NWP' in config_name and 'PV' not in config_name:
            return 'NWP'
        elif 'PV' in config_name and 'plus' not in config_name:
            return 'PV'
        else:
            return 'Unknown'
    
    def run_gpu_only_experiments(self, project_ids: list = None):
        """è¿è¡ŒGPUä¸“ç”¨å®éªŒ"""
        if project_ids is None:
            project_ids = self.checkpoint_manager.get_incomplete_projects()
        
        if not project_ids:
            logger.info("ğŸ‰ æ‰€æœ‰Projectå®éªŒå·²å®Œæˆ!")
            return
        
        logger.info(f"ğŸš€ å¼€å§‹GPUä¸“ç”¨è¿è¡Œ {len(project_ids)} ä¸ªProjectçš„å®éªŒ")
        
        self.stats['start_time'] = datetime.now()
        
        # æ”¶é›†æ‰€æœ‰å¾…æ‰§è¡Œçš„å®éªŒ
        all_experiments = []
        for project_id in project_ids:
            pending_configs = self.checkpoint_manager.get_pending_experiments(project_id)
            for config_info in pending_configs:
                all_experiments.append({
                    'project_id': project_id,
                    'config_name': config_info['name'],
                    'config': config_info['config'],
                    'file_path': config_info['file_path']
                })
        
        self.stats['total_experiments'] = len(all_experiments)
        logger.info(f"ğŸ“Š æ€»å®éªŒæ•°: {self.stats['total_experiments']}")
        
        # ä½¿ç”¨ThreadPoolExecutorè¿›è¡ŒGPUå¹¶è¡Œ
        for i in range(0, len(all_experiments), self.batch_size):
            if not self.running:
                break
            
            batch = all_experiments[i:i + self.batch_size]
            logger.info(f"ğŸš€ å¤„ç†GPUæ‰¹æ¬¡ {i//self.batch_size + 1}: {len(batch)} ä¸ªå®éªŒ")
            
            with ThreadPoolExecutor(max_workers=self.max_gpu_experiments) as executor:
                future_to_exp = {
                    executor.submit(self._run_single_experiment, exp): exp
                    for exp in batch
                }
                
                for future in as_completed(future_to_exp):
                    if not self.running:
                        break
                    
                    exp = future_to_exp[future]
                    try:
                        result = future.result()
                        
                        self.stats['completed_experiments'] += 1
                        if result['status'] == 'completed':
                            self.stats['gpu_experiments'] += 1
                        else:
                            self.stats['failed_experiments'] += 1
                        
                        # ç»“æœå·²åœ¨_run_single_experimentä¸­ä¿å­˜ï¼Œæ— éœ€é‡å¤ä¿å­˜
                        
                    except Exception as e:
                        logger.error(f"ğŸ’¥ GPUå®éªŒå¼‚å¸¸: {exp['project_id']} - {exp['config_name']}: {e}")
                        self.stats['failed_experiments'] += 1
            
            # æ‰¹æ¬¡é—´åŒæ­¥
            self.drive_saver.sync_to_drive()
            
            logger.info(f"ğŸ“Š GPUè¿›åº¦: {self.stats['gpu_experiments']}/{self.stats['total_experiments']}")
        
        # æœ€ç»ˆç»Ÿè®¡
        self._print_final_statistics()
    
    def _print_final_statistics(self):
        """æ‰“å°æœ€ç»ˆç»Ÿè®¡ä¿¡æ¯"""
        if self.stats['start_time']:
            total_duration = (datetime.now() - self.stats['start_time']).total_seconds()
            logger.info("\n" + "=" * 60)
            logger.info("ğŸ‰ GPUä¸“ç”¨å®éªŒå®Œæˆ!")
            logger.info(f"ğŸ“Š æ€»å®éªŒæ•°: {self.stats['total_experiments']}")
            logger.info(f"ğŸš€ GPUå®éªŒ: {self.stats['gpu_experiments']}")
            logger.info(f"âœ… æˆåŠŸå®Œæˆ: {self.stats['completed_experiments']}")
            logger.info(f"âŒ å¤±è´¥å®éªŒ: {self.stats['failed_experiments']}")
            logger.info(f"â±ï¸ æ€»è€—æ—¶: {total_duration/3600:.1f} å°æ—¶")
            logger.info(f"ğŸ“ˆ æˆåŠŸç‡: {self.stats['completed_experiments']/self.stats['total_experiments']*100:.1f}%")
            logger.info(f"ğŸš€ å¹³å‡é€Ÿåº¦: {self.stats['completed_experiments']/total_duration*3600:.1f} å®éªŒ/å°æ—¶")
            logger.info("=" * 60)

def main():
    parser = argparse.ArgumentParser(description="GPUä¸“ç”¨è¿è¡Œ100ä¸ªProjectçš„æ¶ˆèå®éªŒ")
    parser.add_argument("--drive-path", default="/content/drive/MyDrive/Solar PV electricity/ablation results",
                       help="Google Driveç»“æœä¿å­˜è·¯å¾„")
    parser.add_argument("--max-gpu-experiments", type=int, default=24,
                       help="GPUå¹¶è¡Œå®éªŒæ•°")
    parser.add_argument("--batch-size", type=int, default=30,
                       help="æ‰¹æ¬¡å¤§å°")
    parser.add_argument("--project-ids", nargs="+",
                       help="æŒ‡å®šè¦è¿è¡Œçš„Project IDåˆ—è¡¨")
    
    args = parser.parse_args()
    
    runner = GPUOnlyExperimentRunner(
        drive_path=args.drive_path,
        max_gpu_experiments=args.max_gpu_experiments,
        batch_size=args.batch_size
    )
    
    try:
        runner.run_gpu_only_experiments(args.project_ids)
    except KeyboardInterrupt:
        logger.info("ğŸ›‘ ç”¨æˆ·ä¸­æ–­ï¼Œå¼€å§‹ä¼˜é›…å…³é—­...")
        runner.running = False
    except Exception as e:
        logger.error(f"ğŸ’¥ è¿è¡Œå¼‚å¸¸: {e}")
        raise

if __name__ == "__main__":
    main()
