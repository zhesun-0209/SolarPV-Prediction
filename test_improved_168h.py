#!/usr/bin/env python3
"""
æµ‹è¯•æ”¹è¿›çš„LSTMå’ŒGRUæ¨¡å‹ - 168å°æ—¶é¢„æµ‹
ä½¿ç”¨æ®‹å·®è¿æ¥å’Œä¼˜åŒ–æ¿€æ´»å‡½æ•°è§£å†³å‘¨æœŸæ€§é—®é¢˜
"""

import os
import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt
from models.rnn_models import LSTM, GRU

def load_real_data():
    """åŠ è½½çœŸå®çš„Project1140æ•°æ®ï¼ŒæŒ‰ç…§colab_batch_experimentsçš„ç‰¹å¾ç»„åˆ"""
    print("ğŸ”§ åŠ è½½çœŸå®çš„Project1140æ•°æ®...")
    
    import pandas as pd
    
    data_path = "data/Project1140.csv"
    if not os.path.exists(data_path):
        print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_path}")
        return None
    
    df = pd.read_csv(data_path)
    print(f"âœ… åŸå§‹æ•°æ®å½¢çŠ¶: {df.shape}")
    
    # é€‰æ‹©ç‰¹å¾åˆ— - æŒ‰ç…§colab_batch_experimentsçš„NWP+ç‰¹å¾ç»„åˆ
    feature_cols = []
    
    # ç›®æ ‡å˜é‡ - Capacity Factor (0-100æ•´æ•°èŒƒå›´ï¼Œä¸æ ‡å‡†åŒ–)
    if 'Capacity Factor' in df.columns:
        feature_cols.append('Capacity Factor')
        print("âœ… ç›®æ ‡å˜é‡: Capacity Factor (èŒƒå›´0-100æ•´æ•°)")
    else:
        print("âŒ æœªæ‰¾åˆ°'Capacity Factor'åˆ—")
        return None
    
    # PVç‰¹å¾ - Electricity Generated (ä½œä¸ºè¾“å…¥ç‰¹å¾)
    if 'Electricity Generated' in df.columns:
        feature_cols.append('Electricity Generated')
        print("âœ… æ·»åŠ PVç‰¹å¾: Electricity Generated")
    
    # NWPé¢„æµ‹ç‰¹å¾ (6ä¸ªä¸»è¦ç‰¹å¾)
    nwp_cols = [col for col in df.columns if col.endswith('_pred')]
    if nwp_cols:
        selected_nwp = [col for col in nwp_cols if any(x in col for x in [
            'temperature_2m_pred', 'relative_humidity_2m_pred', 'surface_pressure_pred',
            'wind_speed_100m_pred', 'global_tilted_irradiance_pred', 'cloud_cover_low_pred'
        ])]
        feature_cols.extend(selected_nwp)
        print(f"âœ… æ·»åŠ NWPé¢„æµ‹ç‰¹å¾: {selected_nwp}")
    
    # å†å²å¤©æ°”ç‰¹å¾ (6ä¸ªä¸»è¦ç‰¹å¾)
    hist_weather_cols = [col for col in df.columns if any(x in col for x in [
        'temperature_2m', 'relative_humidity_2m', 'surface_pressure',
        'wind_speed_10m', 'global_tilted_irradiance', 'cloud_cover'
    ]) and not col.endswith('_pred')]
    
    if hist_weather_cols:
        feature_cols.extend(hist_weather_cols[:6])  # é€‰æ‹©å‰6ä¸ªå†å²å¤©æ°”ç‰¹å¾
        print(f"âœ… æ·»åŠ å†å²å¤©æ°”ç‰¹å¾: {hist_weather_cols[:6]}")
    
    # æ—¶é—´ç‰¹å¾ - æ ¹æ®use_time_encodingå†³å®š
    time_features = []
    if 'Hour (Eastern Time, Daylight-Adjusted)' in df.columns:
        hour = df['Hour (Eastern Time, Daylight-Adjusted)'].values
        time_features.extend([
            np.sin(2 * np.pi * hour / 24),  # å°æ—¶çš„æ­£å¼¦ç¼–ç 
            np.cos(2 * np.pi * hour / 24)   # å°æ—¶çš„ä½™å¼¦ç¼–ç 
        ])
        print("âœ… æ·»åŠ æ—¶é—´ç‰¹å¾: Hour (æ­£ä½™å¼¦ç¼–ç )")
    
    if 'Month' in df.columns:
        month = df['Month'].values
        time_features.extend([
            np.sin(2 * np.pi * month / 12),  # æœˆä»½çš„æ­£å¼¦ç¼–ç 
            np.cos(2 * np.pi * month / 12)   # æœˆä»½çš„ä½™å¼¦ç¼–ç 
        ])
        print("âœ… æ·»åŠ æ—¶é—´ç‰¹å¾: Month (æ­£ä½™å¼¦ç¼–ç )")
    
    # ç¡®ä¿æ‰€æœ‰ç‰¹å¾åˆ—éƒ½å­˜åœ¨
    available_cols = [col for col in feature_cols if col in df.columns]
    print(f"âœ… åŸºç¡€ç‰¹å¾åˆ—è¡¨ ({len(available_cols)}ä¸ª): {available_cols}")
    
    if len(available_cols) < 2:
        print("âŒ ç‰¹å¾åˆ—ä¸è¶³")
        return None
    
    # æå–åŸºç¡€æ•°æ®å¹¶å¤„ç†ç¼ºå¤±å€¼
    base_data = df[available_cols].fillna(method='ffill').fillna(method='bfill').values.astype(np.float32)
    
    # æ·»åŠ æ—¶é—´ç‰¹å¾
    if time_features:
        time_array = np.column_stack(time_features).astype(np.float32)
        data = np.column_stack([base_data, time_array])
        print(f"âœ… æ·»åŠ æ—¶é—´ç¼–ç ç‰¹å¾: {len(time_features)}ä¸ª")
    else:
        data = base_data
    
    print(f"âœ… æœ€ç»ˆæ•°æ®å½¢çŠ¶: {data.shape}")
    print(f"âœ… æ•°æ®èŒƒå›´: {data.min():.2f} - {data.max():.2f}")
    print(f"âœ… Capacity FactorèŒƒå›´: {data[:, 0].min():.0f} - {data[:, 0].max():.0f} (æ•´æ•°)")
    
    return data

def prepare_sequences(data, past_hours=72, future_hours=24):
    """å‡†å¤‡åºåˆ—æ•°æ®ï¼ŒCapacity Factorä½œä¸ºç›®æ ‡å˜é‡ï¼ŒæŒ‰ç…§colab_batch_experimentsé…ç½®"""
    print("ğŸ”§ å‡†å¤‡åºåˆ—æ•°æ®...")
    print(f"ğŸ“Š è¾“å…¥é•¿åº¦: {past_hours}å°æ—¶, é¢„æµ‹é•¿åº¦: {future_hours}å°æ—¶")
    
    # åˆ†ç¦»ç›®æ ‡å˜é‡å’Œç‰¹å¾
    capacity_factor = data[:, 0:1]  # Capacity Factor (0-100æ•´æ•°èŒƒå›´ï¼Œä¸æ ‡å‡†åŒ–)
    features = data[:, 1:]  # å…¶ä»–ç‰¹å¾ (éœ€è¦æ ‡å‡†åŒ–)
    
    # åªå¯¹ç‰¹å¾è¿›è¡Œæ ‡å‡†åŒ–
    from sklearn.preprocessing import StandardScaler
    scaler = StandardScaler()
    features_scaled = scaler.fit_transform(features)
    
    # é‡æ–°ç»„åˆæ•°æ® - Capacity Factorä¸æ ‡å‡†åŒ–
    data_scaled = np.column_stack([capacity_factor, features_scaled])
    
    X, y = [], []
    for i in range(past_hours, len(data_scaled) - future_hours + 1):
        X.append(data_scaled[i-past_hours:i])  # è¾“å…¥åºåˆ—ï¼šæ‰€æœ‰ç‰¹å¾
        y.append(data_scaled[i:i+future_hours, 0])  # ç›®æ ‡åºåˆ—ï¼šCapacity Factor (ç¬¬ä¸€åˆ—ï¼Œæœªæ ‡å‡†åŒ–)
    
    X = np.array(X, dtype=np.float32)
    y = np.array(y, dtype=np.float32)
    
    print(f"âœ… åºåˆ—æ•°æ®å½¢çŠ¶: X={X.shape}, y={y.shape}")
    print(f"âœ… ç›®æ ‡å˜é‡èŒƒå›´ (Capacity Factor): {y.min():.0f} - {y.max():.0f} (æ•´æ•°)")
    
    # åˆ†å‰²æ•°æ®
    train_size = int(0.8 * len(X))
    val_size = int(0.1 * len(X))
    
    X_train = X[:train_size]
    y_train = y[:train_size]
    X_val = X[train_size:train_size+val_size]
    y_val = y[train_size:train_size+val_size]
    X_test = X[train_size+val_size:]
    y_test = y[train_size+val_size:]
    
    print(f"âœ… è®­ç»ƒé›†: {X_train.shape}, éªŒè¯é›†: {X_val.shape}, æµ‹è¯•é›†: {X_test.shape}")
    
    return (X_train, y_train, X_val, y_val, X_test, y_test), scaler

def train_model(model, X_train, y_train, X_val, y_val, config):
    """è®­ç»ƒæ¨¡å‹"""
    print(f"ğŸš€ å¼€å§‹è®­ç»ƒ{config['model']}æ¨¡å‹...")
    print(f"ğŸ“Š è®­ç»ƒæ•°æ®: {X_train.shape}, éªŒè¯æ•°æ®: {X_val.shape}")
    print(f"ğŸ¯ ç›®æ ‡å˜é‡èŒƒå›´: {y_train.min():.2f} - {y_train.max():.2f}")
    print(f"âš™ï¸ æ¨¡å‹é…ç½®: hidden_dim={config['hidden_dim']}, num_layers={config['num_layers']}, dropout={config['dropout']}")
    print(f"ğŸ“ˆ è®­ç»ƒå‚æ•°: epochs={config['epochs']}, batch_size={config['batch_size']}, lr={config['learning_rate']}")
    
    # æ£€æŸ¥GPUå¯ç”¨æ€§
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ–¥ï¸ ä½¿ç”¨è®¾å¤‡: {device}")
    if torch.cuda.is_available():
        print(f"ğŸš€ GPUå‹å·: {torch.cuda.get_device_name(0)}")
        print(f"ğŸ’¾ GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    
    # å°†æ¨¡å‹ç§»åŠ¨åˆ°GPU
    model = model.to(device)
    
    # è½¬æ¢ä¸ºPyTorchå¼ é‡å¹¶ç§»åŠ¨åˆ°GPU
    X_train_tensor = torch.FloatTensor(X_train).to(device)
    y_train_tensor = torch.FloatTensor(y_train).to(device)
    X_val_tensor = torch.FloatTensor(X_val).to(device)
    y_val_tensor = torch.FloatTensor(y_val).to(device)
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_dataset = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)
    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True)
    
    # ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°
    optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'], weight_decay=1e-4)
    criterion = nn.MSELoss()
    
    # è®­ç»ƒå¾ªç¯
    best_val_loss = float('inf')
    patience_counter = 0
    train_losses = []
    val_losses = []
    
    print("=" * 60)
    print("ğŸ”„ å¼€å§‹è®­ç»ƒå¾ªç¯...")
    print("=" * 60)
    
    for epoch in range(config['epochs']):
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        train_loss = 0.0
        
        for batch_X, batch_y in train_loader:
            optimizer.zero_grad()
            
            # åˆ†ç¦»å†å²æ•°æ®å’Œé¢„æµ‹æ•°æ®
            hist_data = batch_X[:, :config['past_hours']]  # å†å²æ•°æ®
            fcst_data = batch_X[:, config['past_hours']:]  # é¢„æµ‹æ•°æ®
            
            # å‰å‘ä¼ æ’­
            outputs = model(hist_data, fcst_data)
            loss = criterion(outputs, batch_y)
            
            # æ£€æŸ¥NaN
            if torch.isnan(loss):
                print(f"âŒ Epoch {epoch+1} å‡ºç°NaNæŸå¤±ï¼Œè·³è¿‡æ­¤æ‰¹æ¬¡")
                continue
            
            # åå‘ä¼ æ’­
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # æ¢¯åº¦è£å‰ª
            optimizer.step()
            
            train_loss += loss.item()
        
        # éªŒè¯é˜¶æ®µ
        model.eval()
        with torch.no_grad():
            hist_val = X_val_tensor[:, :config['past_hours']]
            fcst_val = X_val_tensor[:, config['past_hours']:]
            val_outputs = model(hist_val, fcst_val)
            val_loss = criterion(val_outputs, y_val_tensor).item()
        
        avg_train_loss = train_loss / len(train_loader)
        train_losses.append(avg_train_loss)
        val_losses.append(val_loss)
        
        # æ—©åœæ£€æŸ¥
        if val_loss < best_val_loss - config['min_delta']:
            best_val_loss = val_loss
            patience_counter = 0
        else:
            patience_counter += 1
        
        # æ¯5ä¸ªepochè¾“å‡ºä¸€æ¬¡ä¿¡æ¯
        if epoch % 5 == 0 or epoch == config['epochs'] - 1:
            current_lr = optimizer.param_groups[0]['lr']
            gpu_memory = f"{torch.cuda.memory_allocated()/1024**3:.1f}GB" if torch.cuda.is_available() else "CPU"
            print(f"Epoch {epoch+1:3d}/{config['epochs']:3d} | "
                  f"Train Loss: {avg_train_loss:.6f} | "
                  f"Val Loss: {val_loss:.6f} | "
                  f"LR: {current_lr:.2e} | "
                  f"Patience: {patience_counter}/{config['patience']} | "
                  f"GPU: {gpu_memory}")
        
        if patience_counter >= config['patience']:
            print(f"ğŸ›‘ æ—©åœäºç¬¬ {epoch+1} è½®")
            break
    
    print("=" * 60)
    print(f"âœ… {config['model']}è®­ç»ƒå®Œæˆ!")
    print(f"ğŸ“ˆ æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.6f}")
    print(f"ğŸ“Š æœ€ç»ˆè®­ç»ƒæŸå¤±: {train_losses[-1]:.6f}")
    print(f"ğŸ“Š æœ€ç»ˆéªŒè¯æŸå¤±: {val_losses[-1]:.6f}")
    
    # æ¸…ç†GPUå†…å­˜
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        print(f"ğŸ§¹ GPUå†…å­˜å·²æ¸…ç†: {torch.cuda.memory_allocated()/1024**3:.1f}GB")
    
    print("=" * 60)
    return train_losses, val_losses

def generate_predictions(model, X_test, y_test, config, model_name):
    """ç”Ÿæˆé¢„æµ‹å¹¶å¯è§†åŒ– - 168å°æ—¶ï¼ˆ7å¤©ï¼‰è¿ç»­é¢„æµ‹å¯¹æ¯”å›¾"""
    print(f"ğŸ¨ ç”Ÿæˆ{model_name}çš„168å°æ—¶è¿ç»­é¢„æµ‹å¯¹æ¯”å›¾...")
    
    # æ£€æŸ¥è®¾å¤‡
    device = next(model.parameters()).device
    print(f"ğŸ–¥ï¸ ä½¿ç”¨è®¾å¤‡: {device}")
    
    # é€‰æ‹©æµ‹è¯•é›†å‰168ä¸ªæ—¶é—´æ­¥ï¼ˆ7å¤© * 24å°æ—¶ï¼‰
    n_timesteps = min(168, len(X_test))
    sample_indices = list(range(n_timesteps))
    
    model.eval()
    with torch.no_grad():
        predictions = []
        ground_truths = []
        
        for idx in sample_indices:
            # å‡†å¤‡è¾“å…¥æ•°æ®å¹¶ç§»åŠ¨åˆ°GPU
            X_sample = torch.FloatTensor(X_test[idx:idx+1]).to(device)
            hist_data = X_sample[:, :config['past_hours']]
            fcst_data = X_sample[:, config['past_hours']:]
            
            # ç”Ÿæˆé¢„æµ‹
            pred = model(hist_data, fcst_data)
            pred_np = pred.cpu().numpy()[0]
            
            # åªå–ç¬¬ä¸€ä¸ªæ—¶é—´æ­¥çš„é¢„æµ‹å€¼ï¼ˆ24å°æ—¶é¢„æµ‹çš„ç¬¬ä¸€ä¸ªå°æ—¶ï¼‰
            predictions.append(pred_np[0])
            ground_truths.append(y_test[idx][0])
    
    # åˆ›å»º168å°æ—¶è¿ç»­é¢„æµ‹å¯¹æ¯”å›¾
    plt.figure(figsize=(20, 8))
    
    # æ—¶é—´è½´ï¼š168å°æ—¶ = 7å¤©
    time_hours = np.arange(168)
    time_days = time_hours / 24  # è½¬æ¢ä¸ºå¤©æ•°
    
    # ç»˜åˆ¶é¢„æµ‹å’ŒçœŸå®å€¼
    plt.plot(time_hours, ground_truths, 'b-', label='Ground Truth', linewidth=2, alpha=0.8)
    plt.plot(time_hours, predictions, 'r--', label=f'{model_name} Prediction', linewidth=2, alpha=0.8)
    
    # è®¾ç½®å›¾å½¢å±æ€§
    plt.title(f'{model_name} Model: 168-Hour Continuous Prediction vs Ground Truth (First 7 Days of Test Set)', 
              fontsize=16, fontweight='bold')
    plt.xlabel('Time (Hours)', fontsize=14)
    plt.ylabel('Capacity Factor (0-100)', fontsize=14)
    plt.legend(fontsize=12)
    plt.grid(True, alpha=0.3)
    
    # æ·»åŠ å¤©æ•°æ ‡è®°
    ax = plt.gca()
    ax2 = ax.twiny()
    ax2.set_xlim(ax.get_xlim())
    ax2.set_xticks(np.arange(0, 169, 24))  # æ¯24å°æ—¶ä¸€ä¸ªæ ‡è®°
    ax2.set_xticklabels([f'Day {i+1}' for i in range(8)])  # Day 1 åˆ° Day 8
    ax2.set_xlabel('Days', fontsize=14)
    
    # è®¾ç½®yè½´èŒƒå›´
    all_values = ground_truths + predictions
    y_min, y_max = min(all_values), max(all_values)
    y_range = y_max - y_min
    plt.ylim(y_min - 0.1 * y_range, y_max + 0.1 * y_range)
    
    # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
    mse = np.mean((np.array(predictions) - np.array(ground_truths)) ** 2)
    rmse = np.sqrt(mse)
    mae = np.mean(np.abs(np.array(predictions) - np.array(ground_truths)))
    
    stats_text = f'RMSE: {rmse:.3f}\nMAE: {mae:.3f}'
    plt.text(0.02, 0.98, stats_text, transform=plt.gca().transAxes, 
             verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8),
             fontsize=12)
    
    plt.tight_layout()
    save_path = f'improved_{model_name.lower()}_168h_prediction.png'
    plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')
    plt.show()
    
    print(f"âœ… {model_name} 168å°æ—¶è¿ç»­é¢„æµ‹å¯¹æ¯”å›¾å·²ä¿å­˜åˆ°: {save_path}")
    print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯: RMSE={rmse:.3f}, MAE={mae:.3f}")
    
    return predictions, ground_truths

def plot_168h_comparison(models, scaler):
    """ç»˜åˆ¶168å°æ—¶è¿ç»­é¢„æµ‹å¯¹æ¯”å›¾ - LSTM vs GRU"""
    print("ğŸ“Š ç»˜åˆ¶168å°æ—¶è¿ç»­é¢„æµ‹å¯¹æ¯”å›¾...")
    
    fig, axes = plt.subplots(2, 1, figsize=(20, 12))
    
    # è·å–168å°æ—¶çš„è¿ç»­é¢„æµ‹æ•°æ®
    lstm_pred = models['LSTM']['predictions']
    gru_pred = models['GRU']['predictions']
    y_true = models['LSTM']['ground_truths']
    
    # Capacity Factorä¸éœ€è¦åæ ‡å‡†åŒ–ï¼Œå·²ç»æ˜¯0-100èŒƒå›´
    lstm_pred_denorm = lstm_pred
    gru_pred_denorm = gru_pred
    y_true_denorm = y_true
    
    # ç»˜åˆ¶é¢„æµ‹ç»“æœ
    time_hours = np.arange(168)
    axes[0].plot(time_hours, y_true_denorm, 'b-', label='Ground Truth', linewidth=2, alpha=0.8)
    axes[0].plot(time_hours, lstm_pred_denorm, 'r--', label='LSTM Prediction', linewidth=2, alpha=0.8)
    axes[0].plot(time_hours, gru_pred_denorm, 'g--', label='GRU Prediction', linewidth=2, alpha=0.8)
    
    axes[0].set_title('LSTM vs GRU: 168-Hour Continuous Prediction Comparison (First 7 Days of Test Set)', 
                      fontsize=16, fontweight='bold')
    axes[0].set_xlabel('Time (Hours)', fontsize=14)
    axes[0].set_ylabel('Capacity Factor (0-100)', fontsize=14)
    axes[0].legend(fontsize=12)
    axes[0].grid(True, alpha=0.3)
    
    # æ·»åŠ å¤©æ•°æ ‡è®°
    ax = axes[0]
    ax2 = ax.twiny()
    ax2.set_xlim(ax.get_xlim())
    ax2.set_xticks(np.arange(0, 169, 24))  # æ¯24å°æ—¶ä¸€ä¸ªæ ‡è®°
    ax2.set_xticklabels([f'Day {i+1}' for i in range(8)])  # Day 1 åˆ° Day 8
    ax2.set_xlabel('Days', fontsize=14)
    
    # ç»˜åˆ¶è¯¯å·®å¯¹æ¯”
    lstm_error = np.abs(lstm_pred_denorm - y_true_denorm)
    gru_error = np.abs(gru_pred_denorm - y_true_denorm)
    
    axes[1].plot(time_hours, lstm_error, 'r-', label='LSTM Error', linewidth=2, alpha=0.8)
    axes[1].plot(time_hours, gru_error, 'g-', label='GRU Error', linewidth=2, alpha=0.8)
    
    axes[1].set_title('Prediction Error Comparison (Capacity Factor)', fontsize=16, fontweight='bold')
    axes[1].set_xlabel('Time (Hours)', fontsize=14)
    axes[1].set_ylabel('Absolute Error (0-100)', fontsize=14)
    axes[1].legend(fontsize=12)
    axes[1].grid(True, alpha=0.3)
    
    # æ·»åŠ å¤©æ•°æ ‡è®°åˆ°è¯¯å·®å›¾
    ax = axes[1]
    ax2 = ax.twiny()
    ax2.set_xlim(ax.get_xlim())
    ax2.set_xticks(np.arange(0, 169, 24))  # æ¯24å°æ—¶ä¸€ä¸ªæ ‡è®°
    ax2.set_xticklabels([f'Day {i+1}' for i in range(8)])  # Day 1 åˆ° Day 8
    ax2.set_xlabel('Days', fontsize=14)
    
    # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
    lstm_rmse = np.sqrt(np.mean(lstm_error ** 2))
    gru_rmse = np.sqrt(np.mean(gru_error ** 2))
    lstm_mae = np.mean(lstm_error)
    gru_mae = np.mean(gru_error)
    
    stats_text = f'LSTM: RMSE={lstm_rmse:.3f}, MAE={lstm_mae:.3f}\nGRU: RMSE={gru_rmse:.3f}, MAE={gru_mae:.3f}'
    axes[0].text(0.02, 0.98, stats_text, transform=axes[0].transAxes, 
                 verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8),
                 fontsize=11)
    
    plt.tight_layout()
    save_path = 'improved_lstm_gru_comparison_168h.png'
    plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')
    plt.show()
    
    print(f"âœ… 168å°æ—¶è¿ç»­é¢„æµ‹å¯¹æ¯”å›¾å·²ä¿å­˜ä¸º: {save_path}")
    print(f"ğŸ“Š LSTMç»Ÿè®¡: RMSE={lstm_rmse:.3f}, MAE={lstm_mae:.3f}")
    print(f"ğŸ“Š GRUç»Ÿè®¡: RMSE={gru_rmse:.3f}, MAE={gru_mae:.3f}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ æµ‹è¯•æ”¹è¿›çš„RNNæ¨¡å‹ - 168å°æ—¶é¢„æµ‹ (7å¤©é¢„æµ‹)")
    print("=" * 70)
    
    # æ£€æŸ¥GPUå¯ç”¨æ€§
    print(f"ğŸ–¥ï¸ PyTorchç‰ˆæœ¬: {torch.__version__}")
    print(f"ğŸ”§ CUDAå¯ç”¨: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"ğŸš€ GPUå‹å·: {torch.cuda.get_device_name(0)}")
        print(f"ğŸ’¾ GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
        print(f"ğŸ”¥ CUDAç‰ˆæœ¬: {torch.version.cuda}")
    else:
        print("âš ï¸ æœªæ£€æµ‹åˆ°GPUï¼Œå°†ä½¿ç”¨CPUè®­ç»ƒï¼ˆé€Ÿåº¦è¾ƒæ…¢ï¼‰")
    print("=" * 70)
    
    # åˆ›å»ºé…ç½® - æŒ‰ç…§yamlä¸­low complexityçš„é…ç½®
    config = {
        'model': 'LSTM',
        'hidden_dim': 32,        # low: 32
        'num_layers': 6,         # low: 6
        'dropout': 0.1,          # low: 0.1
        'd_model': 64,           # low: 64
        'num_heads': 4,          # low: 4
        'future_hours': 24,      # 24å°æ—¶é¢„æµ‹
        'past_hours': 72,        # 72å°æ—¶å†å²
        'use_forecast': True,
        'epochs': 50,            # low: 50
        'batch_size': 64,        # low: 64
        'learning_rate': 0.001,  # low: 0.001
        'patience': 10,
        'min_delta': 0.001
    }
    
    # åŠ è½½çœŸå®æ•°æ®
    data = load_real_data()
    if data is None:
        print("âŒ æ— æ³•åŠ è½½æ•°æ®ï¼Œé€€å‡ºç¨‹åº")
        return
    
    # å‡†å¤‡åºåˆ—æ•°æ®
    data_splits, scaler = prepare_sequences(data, config['past_hours'], config['future_hours'])
    X_train, y_train, X_val, y_val, X_test, y_test = data_splits
    
    # æµ‹è¯•LSTMå’ŒGRU
    models = {}
    for model_type in ['LSTM', 'GRU']:
        print(f"\n{'='*50}")
        print(f"æµ‹è¯• {model_type} æ¨¡å‹")
        print(f"{'='*50}")
        
        config['model'] = model_type
        hist_dim = X_train.shape[-1]
        fcst_dim = X_train.shape[-1] if config.get('use_forecast', False) else 0
        
        if model_type == 'LSTM':
            model = LSTM(hist_dim, fcst_dim, config)
        else:
            model = GRU(hist_dim, fcst_dim, config)
        
        print(f"âœ… {model_type}å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
        
        # è®­ç»ƒæ¨¡å‹
        train_losses, val_losses = train_model(model, X_train, y_train, X_val, y_val, config)
        
        # ç”Ÿæˆé¢„æµ‹
        predictions, ground_truths = generate_predictions(model, X_test, y_test, config, model_type)
        
        models[model_type] = {
            'model': model,
            'train_losses': train_losses,
            'val_losses': val_losses,
            'predictions': predictions,
            'ground_truths': ground_truths
        }
    
    # ç»˜åˆ¶è®­ç»ƒæ›²çº¿å¯¹æ¯”
    plt.figure(figsize=(18, 6))
    
    plt.subplot(1, 3, 1)
    plt.plot(models['LSTM']['train_losses'], label='LSTM Train', color='blue', linewidth=2)
    plt.plot(models['LSTM']['val_losses'], label='LSTM Val', color='blue', linestyle='--', linewidth=2)
    plt.plot(models['GRU']['train_losses'], label='GRU Train', color='red', linewidth=2)
    plt.plot(models['GRU']['val_losses'], label='GRU Val', color='red', linestyle='--', linewidth=2)
    plt.xlabel('Epoch', fontsize=12)
    plt.ylabel('Loss', fontsize=12)
    plt.title('Training Progress Comparison (168h)', fontsize=14, fontweight='bold')
    plt.legend(fontsize=11)
    plt.grid(True, alpha=0.3)
    
    # é¢„æµ‹ç²¾åº¦å¯¹æ¯” (åæ ‡å‡†åŒ–å)
    plt.subplot(1, 3, 2)
    
    # Capacity Factorä¸éœ€è¦åæ ‡å‡†åŒ–ï¼Œå·²ç»æ˜¯0-100èŒƒå›´
    lstm_preds_denorm = models['LSTM']['predictions']
    lstm_gts_denorm = models['LSTM']['ground_truths']
    gru_preds_denorm = models['GRU']['predictions']
    gru_gts_denorm = models['GRU']['ground_truths']
    
    lstm_rmse = [np.sqrt(np.mean((pred - gt) ** 2)) for pred, gt in zip(lstm_preds_denorm, lstm_gts_denorm)]
    gru_rmse = [np.sqrt(np.mean((pred - gt) ** 2)) for pred, gt in zip(gru_preds_denorm, gru_gts_denorm)]
    
    plt.bar(['LSTM', 'GRU'], [np.mean(lstm_rmse), np.mean(gru_rmse)], color=['blue', 'red'], alpha=0.7)
    plt.ylabel('Average RMSE (Capacity Factor)', fontsize=12)
    plt.title('Prediction Accuracy Comparison (168h)', fontsize=14, fontweight='bold')
    plt.grid(True, alpha=0.3)
    
    # å‚æ•°æ•°é‡å¯¹æ¯”
    plt.subplot(1, 3, 3)
    lstm_params = sum(p.numel() for p in models['LSTM']['model'].parameters())
    gru_params = sum(p.numel() for p in models['GRU']['model'].parameters())
    
    plt.bar(['LSTM', 'GRU'], [lstm_params, gru_params], color=['blue', 'red'], alpha=0.7)
    plt.ylabel('Number of Parameters', fontsize=12)
    plt.title('Model Complexity Comparison', fontsize=14, fontweight='bold')
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    save_path = 'improved_rnn_comparison_168h.png'
    plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')
    plt.show()
    
    print(f"âœ… æ¨¡å‹å¯¹æ¯”å›¾å·²ä¿å­˜ä¸º: {save_path}")
    
    # ç»˜åˆ¶168å°æ—¶é¢„æµ‹å¯¹æ¯”å›¾
    print("\nğŸ“Š ç»˜åˆ¶168å°æ—¶é¢„æµ‹å¯¹æ¯”å›¾...")
    plot_168h_comparison(models, scaler)
    
    print("\nğŸ¯ æ”¹è¿›æ•ˆæœæ€»ç»“:")
    print("   - ä½¿ç”¨æ®‹å·®è¿æ¥ï¼Œæ”¹å–„æ¢¯åº¦æµå’Œè®­ç»ƒç¨³å®šæ€§")
    print("   - ä¼˜åŒ–æ¿€æ´»å‡½æ•°ç»„åˆ (ReLU + Sigmoid)ï¼Œè§£å†³å‘¨æœŸæ€§é—®é¢˜")
    print("   - ç»Ÿä¸€äº†LSTMå’ŒGRUçš„æ¶æ„é…ç½®")
    print("   - é…ç½®ï¼š72å°æ—¶è¾“å…¥ â†’ 168å°æ—¶é¢„æµ‹ (7å¤©)")
    print("   - æ¢¯åº¦è£å‰ªé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸é—®é¢˜")
    print("   - ä½¿ç”¨çœŸå®Project1140æ•°æ®è®­ç»ƒï¼Œç›®æ ‡å˜é‡ä¸ºCapacity Factor (0-100æ•´æ•°)")
    print("   - ç‰¹å¾ç»„åˆï¼šPV + NWPé¢„æµ‹ + å†å²å¤©æ°” + æ—¶é—´ç¼–ç ")
    print("   - æ—¶é—´ç‰¹å¾ä½¿ç”¨æ­£ä½™å¼¦ç¼–ç ï¼Œæé«˜å‘¨æœŸæ€§å»ºæ¨¡èƒ½åŠ›")
    print("   - Capacity Factorä¸è¿›è¡Œæ ‡å‡†åŒ–ï¼Œä¿æŒ0-100æ•´æ•°èŒƒå›´")
    print("   - å¢åŠ æ¨¡å‹å¤æ‚åº¦ä»¥é€‚åº”168å°æ—¶é•¿åºåˆ—é¢„æµ‹")
    print("   - æ‰€æœ‰å›¾è¡¨ä½¿ç”¨è‹±æ–‡æ ‡ç­¾ï¼Œä¾¿äºå›½é™…äº¤æµ")

if __name__ == "__main__":
    main()
