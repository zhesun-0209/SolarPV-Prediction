#!/usr/bin/env python3
"""
æ”¹è¿›LSTMå’ŒGRUæ¨¡å‹æµ‹è¯•è„šæœ¬ - æ–¹æ¡ˆ1
å€Ÿé‰´TransformeræˆåŠŸçš„æ ¸å¿ƒè¦ç´ æ¥è§£å†³å‘¨æœŸæ€§é—®é¢˜
"""

import os
import sys
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
from pathlib import Path
import warnings
import random

# è®¾ç½®éšæœºç§å­ç¡®ä¿ç»“æœå¯é‡ç°
torch.manual_seed(42)
np.random.seed(42)
random.seed(42)
warnings.filterwarnings('ignore')

# è®¾ç½®matplotlibå‚æ•°
plt.rcParams['font.family'] = 'Arial'
plt.rcParams['font.size'] = 12

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from data.data_utils import load_raw_data, preprocess_features, create_sliding_windows, split_data

class ImprovedLSTM(nn.Module):
    """æ”¹è¿›çš„LSTMæ¨¡å‹ - å€Ÿé‰´TransformeræˆåŠŸè¦ç´ """
    def __init__(self, hist_dim: int, fcst_dim: int, config: dict):
        super().__init__()
        self.cfg = config
        hidden = config['hidden_dim']
        layers = config['num_layers']

        self.hist_proj = nn.Linear(hist_dim, hidden) if hist_dim > 0 else None
        self.fcst_proj = nn.Linear(fcst_dim, hidden) if config.get('use_forecast', False) and fcst_dim > 0 else None

        # LSTMå±‚ä¿æŒä¸å˜
        self.lstm = nn.LSTM(hidden, hidden, num_layers=layers,
                           batch_first=True, dropout=config['dropout'])

        # æ”¹è¿›1: ä½¿ç”¨ReLU + Sigmoidæ¿€æ´»å‡½æ•° (å€Ÿé‰´TransformeræˆåŠŸè¦ç´ )
        self.head = nn.Sequential(
            nn.Linear(hidden, hidden // 2),
            nn.ReLU(),  # æ”¹ä¸ºReLU (æ›´å¥½çš„æ¢¯åº¦æµ)
            nn.Dropout(config['dropout']),
            nn.Linear(hidden // 2, config['future_hours']),
            nn.Sigmoid()  # æ”¹ä¸ºSigmoidï¼Œè¾“å‡º[0,1]
        )

    def forward(self, hist: torch.Tensor, fcst: torch.Tensor = None) -> torch.Tensor:
        seqs = []

        if self.hist_proj is not None and hist.shape[-1] > 0:
            h_proj = self.hist_proj(hist)
            seqs.append(h_proj)

        if self.fcst_proj is not None and fcst is not None and fcst.shape[-1] > 0:
            f_proj = self.fcst_proj(fcst)
            seqs.append(f_proj)

        if not seqs:
            raise ValueError("Both hist and forecast inputs are missing or zero-dimensional.")

        seq = torch.cat(seqs, dim=1)  # (B, past+future, hidden)
        out, _ = self.lstm(seq)        # (B, seq_len, hidden)
        
        # ä½¿ç”¨æœ€åæ—¶é—´æ­¥
        last_output = out[:, -1, :]    # (B, hidden)
        result = self.head(last_output) # (B, future_hours)
        
        # æ”¹è¿›2: ä¹˜ä»¥100è½¬æ¢ä¸ºç™¾åˆ†æ¯” (å€Ÿé‰´TransformeræˆåŠŸè¦ç´ )
        return result * 100

class ImprovedGRU(nn.Module):
    """æ”¹è¿›çš„GRUæ¨¡å‹ - å€Ÿé‰´TransformeræˆåŠŸè¦ç´ """
    def __init__(self, hist_dim: int, fcst_dim: int, config: dict):
        super().__init__()
        self.cfg = config
        hidden = config['hidden_dim']
        layers = config['num_layers']

        self.hist_proj = nn.Linear(hist_dim, hidden) if hist_dim > 0 else None
        self.fcst_proj = nn.Linear(fcst_dim, hidden) if config.get('use_forecast', False) and fcst_dim > 0 else None

        # GRUå±‚ä¿æŒä¸å˜
        self.gru = nn.GRU(hidden, hidden, num_layers=layers,
                          batch_first=True, dropout=config['dropout'])

        # æ”¹è¿›1: ä½¿ç”¨ReLU + Sigmoidæ¿€æ´»å‡½æ•° (å€Ÿé‰´TransformeræˆåŠŸè¦ç´ )
        self.head = nn.Sequential(
            nn.Linear(hidden, hidden // 2),
            nn.ReLU(),  # æ”¹ä¸ºReLU (æ›´å¥½çš„æ¢¯åº¦æµ)
            nn.Dropout(config['dropout']),
            nn.Linear(hidden // 2, config['future_hours']),
            nn.Sigmoid()  # æ”¹ä¸ºSigmoidï¼Œè¾“å‡º[0,1]
        )

    def forward(self, hist: torch.Tensor, fcst: torch.Tensor = None) -> torch.Tensor:
        seqs = []

        if self.hist_proj is not None and hist.shape[-1] > 0:
            h_proj = self.hist_proj(hist)
            seqs.append(h_proj)

        if self.fcst_proj is not None and fcst is not None and fcst.shape[-1] > 0:
            f_proj = self.fcst_proj(fcst)
            seqs.append(f_proj)

        if not seqs:
            raise ValueError("Both hist and forecast inputs are missing or zero-dimensional.")

        seq = torch.cat(seqs, dim=1)  # (B, past+future, hidden)
        out, _ = self.gru(seq)        # (B, seq_len, hidden)
        
        # ä½¿ç”¨æœ€åæ—¶é—´æ­¥
        last_output = out[:, -1, :]    # (B, hidden)
        result = self.head(last_output) # (B, future_hours)
        
        # æ”¹è¿›2: ä¹˜ä»¥100è½¬æ¢ä¸ºç™¾åˆ†æ¯” (å€Ÿé‰´TransformeræˆåŠŸè¦ç´ )
        return result * 100

class EarlyStopping:
    """æ—©åœæœºåˆ¶"""
    def __init__(self, patience=10, min_delta=0.001):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.best_loss = float('inf')
    
    def __call__(self, val_loss):
        if val_loss < self.best_loss - self.min_delta:
            self.best_loss = val_loss
            self.counter = 0
        else:
            self.counter += 1
        
        return self.counter >= self.patience

def train_improved_rnn_model(model_name, config, Xh_tr, Xf_tr, y_tr, hrs_tr, dates_tr,
                           Xh_va, Xf_va, y_va, hrs_va, dates_va,
                           Xh_te, Xf_te, y_te, hrs_te, dates_te):
    """è®­ç»ƒæ”¹è¿›çš„RNNæ¨¡å‹"""
    print(f"ğŸš€ è®­ç»ƒæ”¹è¿›çš„ {model_name} æ¨¡å‹...")
    
    # è®¾ç½®è®¾å¤‡
    device = torch.device("cpu")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    def make_loader(Xh, Xf, y, hrs, bs, shuffle=False):
        tensors = [torch.tensor(Xh, dtype=torch.float32),
                   torch.tensor(hrs, dtype=torch.long)]
        if Xf is not None:
            tensors.insert(1, torch.tensor(Xf, dtype=torch.float32))
        tensors.append(torch.tensor(y, dtype=torch.float32))
        return torch.utils.data.DataLoader(
            torch.utils.data.TensorDataset(*tensors), 
            batch_size=bs, 
            shuffle=shuffle
        )
    
    # æ”¹è¿›3: ä½¿ç”¨æ›´å¤§çš„æ‰¹æ¬¡å¤§å° (å€Ÿé‰´TransformeræˆåŠŸè¦ç´ )
    bs = 64  # ä»32æ”¹ä¸º64
    train_loader = make_loader(Xh_tr, Xf_tr, y_tr, hrs_tr, bs, shuffle=True)
    val_loader = make_loader(Xh_va, Xf_va, y_va, hrs_va, bs)
    test_loader = make_loader(Xh_te, Xf_te, y_te, hrs_te, bs)
    
    # åˆ›å»ºæ”¹è¿›çš„æ¨¡å‹
    complexity = config['model_complexity']
    mp = config['model_params'][complexity].copy()
    mp['use_forecast'] = config.get('use_forecast', False)
    mp['past_hours'] = config['past_hours']
    mp['future_hours'] = config['future_hours']
    
    hist_dim = Xh_tr.shape[2]
    fcst_dim = Xf_tr.shape[2] if Xf_tr is not None else 0
    
    if model_name == 'LSTM':
        model = ImprovedLSTM(hist_dim, fcst_dim, mp)
    elif model_name == 'GRU':
        model = ImprovedGRU(hist_dim, fcst_dim, mp)
    else:
        raise ValueError(f"Unsupported model: {model_name}")
    
    model.to(device)
    
    # æ”¹è¿›4: ä½¿ç”¨AdamWä¼˜åŒ–å™¨ (å€Ÿé‰´TransformeræˆåŠŸè¦ç´ )
    optimizer = torch.optim.AdamW(model.parameters(), lr=config['train_params']['learning_rate'], weight_decay=0.01)
    
    # æ”¹è¿›5: æ·»åŠ å­¦ä¹ ç‡è°ƒåº¦å™¨ (å€Ÿé‰´TransformeræˆåŠŸè¦ç´ )
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode='min', factor=0.5, patience=5, verbose=True
    )
    
    # æŸå¤±å‡½æ•°ä¿æŒä¸å˜ (MSE)
    criterion = nn.MSELoss()
    
    # æ”¹è¿›6: æ—©åœæœºåˆ¶
    early_stopping = EarlyStopping(patience=10, min_delta=0.001)
    
    # æ”¹è¿›7: å¢åŠ è®­ç»ƒè½®æ•° (å€Ÿé‰´TransformeræˆåŠŸè¦ç´ )
    best_val_loss = float('inf')
    best_model_state = None
    
    for epoch in range(50):  # ä»15æ”¹ä¸º50
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        total_train_loss = 0
        for batch in train_loader:
            if Xf_tr is not None:
                xh, xf, hrs, y_batch = batch
                xh, xf = xh.to(device), xf.to(device)
                pred = model(xh, xf)
            else:
                xh, hrs, y_batch = batch
                xh = xh.to(device)
                pred = model(xh)
            
            y_batch = y_batch.to(device)
            loss = criterion(pred, y_batch)
            
            optimizer.zero_grad()
            loss.backward()
            
            # æ”¹è¿›8: æ¢¯åº¦è£å‰ª (é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸)
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            
            optimizer.step()
            
            total_train_loss += loss.item()
        
        # éªŒè¯é˜¶æ®µ
        model.eval()
        total_val_loss = 0
        with torch.no_grad():
            for batch in val_loader:
                if Xf_tr is not None:
                    xh, xf, hrs, y_batch = batch
                    xh, xf = xh.to(device), xf.to(device)
                    pred = model(xh, xf)
                else:
                    xh, hrs, y_batch = batch
                    xh = xh.to(device)
                    pred = model(xh)
                
                y_batch = y_batch.to(device)
                loss = criterion(pred, y_batch)
                total_val_loss += loss.item()
        
        avg_train_loss = total_train_loss / len(train_loader)
        avg_val_loss = total_val_loss / len(val_loader)
        
        # å­¦ä¹ ç‡è°ƒåº¦
        scheduler.step(avg_val_loss)
        
        if epoch % 5 == 0:
            print(f"  Epoch {epoch+1}/50, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}")
        
        # æ—©åœæ£€æŸ¥
        if early_stopping(avg_val_loss):
            print(f"  æ—©åœäºç¬¬ {epoch+1} è½®")
            break
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            best_model_state = model.state_dict().copy()
    
    # åŠ è½½æœ€ä½³æ¨¡å‹
    if best_model_state is not None:
        model.load_state_dict(best_model_state)
    
    print(f"âœ… æ”¹è¿›çš„ {model_name} è®­ç»ƒå®Œæˆ")
    
    # æµ‹è¯•é˜¶æ®µ
    model.eval()
    predictions = []
    with torch.no_grad():
        for batch in test_loader:
            if Xf_tr is not None:
                xh, xf, hrs, y_batch = batch
                xh, xf = xh.to(device), xf.to(device)
                pred = model(xh, xf)
            else:
                xh, hrs, y_batch = batch
                xh = xh.to(device)
                pred = model(xh)
            predictions.append(pred.cpu().numpy())
    
    predictions = np.concatenate(predictions, axis=0)
    return y_te, predictions

def calculate_metrics(y_true, y_pred):
    """è®¡ç®—è¯„ä¼°æŒ‡æ ‡"""
    mse = np.mean((y_true - y_pred) ** 2)
    rmse = np.sqrt(mse)
    mae = np.mean(np.abs(y_true - y_pred))
    correlation = np.corrcoef(y_true.flatten(), y_pred.flatten())[0, 1]
    
    # è®¡ç®—å“åº”æ¯”ä¾‹
    gt_diff = np.diff(y_true, axis=1)
    pred_diff = np.diff(y_pred, axis=1)
    response_ratio = np.mean(np.abs(pred_diff) / (np.abs(gt_diff) + 1e-8))
    
    # è®¡ç®—å”¯ä¸€å€¼æ¯”ä¾‹
    unique_ratio = len(np.unique(y_pred.round(2))) / y_pred.size
    
    return {
        'RMSE': rmse,
        'MAE': mae,
        'Correlation': correlation,
        'Response_Ratio': response_ratio,
        'Unique_Ratio': unique_ratio
    }

def main():
    print("ğŸš€ å¼€å§‹æ”¹è¿›LSTMå’ŒGRUæ¨¡å‹æµ‹è¯•ï¼ˆæ–¹æ¡ˆ1ï¼‰...")
    print("=" * 60)
    
    # åŠ è½½æ•°æ®
    print("\nğŸ“Š åŠ è½½æ•°æ®...")
    df = load_raw_data('data/Project1140.csv')
    print(f"âœ… æ•°æ®åŠ è½½å®Œæˆ: {len(df)} è¡Œ")
    
    # é…ç½®
    config = {
        'data_path': 'data/Project1140.csv',
        'start_date': '2022-01-01',
        'end_date': '2024-09-28',
        'model_complexity': 'low',
        'model_params': {
            'low': {
                'd_model': 64,
                'dropout': 0.1,
                'hidden_dim': 32,
                'num_heads': 4,
                'num_layers': 6
            }
        },
        'past_hours': 72,
        'future_hours': 24,
        'train_params': {
            'batch_size': 64,  # æ”¹è¿›ï¼šæ›´å¤§çš„æ‰¹æ¬¡å¤§å°
            'learning_rate': 0.001
        },
        'train_ratio': 0.8,
        'val_ratio': 0.1,
        'use_forecast': True,
        'use_hist_weather': False,
        'use_ideal_nwp': True,
        'use_pv': True,
        'use_time_encoding': False,
        'weather_category': 'all_weather'
    }
    
    # æ•°æ®é¢„å¤„ç†
    df_clean, hist_feats, fcst_feats, scaler_hist, scaler_fcst, scaler_target = preprocess_features(df, config)
    
    # åˆ›å»ºæ»‘åŠ¨çª—å£
    X_hist, X_fcst, y, hours, dates = create_sliding_windows(
        df_clean, 
        config['past_hours'], 
        config['future_hours'], 
        hist_feats, 
        fcst_feats, 
        no_hist_power=not config.get('use_pv', True)
    )
    
    # åˆ†å‰²æ•°æ®
    Xh_tr, Xf_tr, y_tr, hrs_tr, dates_tr, \
    Xh_va, Xf_va, y_va, hrs_va, dates_va, \
    Xh_te, Xf_te, y_te, hrs_te, dates_te = split_data(
        X_hist, X_fcst, y, hours, dates,
        train_ratio=config["train_ratio"],
        val_ratio=config["val_ratio"]
    )
    
    # è®­ç»ƒæ”¹è¿›çš„æ¨¡å‹
    models = ['LSTM', 'GRU']  # åªè®­ç»ƒLSTMå’ŒGRU
    results = {}
    
    for model_name in models:
        try:
            y_te, predictions = train_improved_rnn_model(
                model_name, config,
                Xh_tr, Xf_tr, y_tr, hrs_tr, dates_tr,
                Xh_va, Xf_va, y_va, hrs_va, dates_va,
                Xh_te, Xf_te, y_te, hrs_te, dates_te
            )
            results[model_name] = (y_te, predictions)
        except Exception as e:
            print(f"âŒ {model_name} è®­ç»ƒå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    # ä¿å­˜ç»“æœ
    if results:
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = 'improved_lstm_gru_results'
        os.makedirs(output_dir, exist_ok=True)
        
        # ä¿å­˜CSVç»“æœ
        data = {}
        first_model = list(results.keys())[0]
        y_true = results[first_model][0]
        n_samples = min(168, len(y_true))
        data['Ground_Truth'] = y_true[:n_samples].flatten()
        
        for model_name, (_, y_pred) in results.items():
            data[f'{model_name}_Prediction'] = y_pred[:n_samples].flatten()
        
        data['Timestep'] = range(len(data['Ground_Truth']))
        df_results = pd.DataFrame(data)
        csv_path = os.path.join(output_dir, 'improved_lstm_gru_predictions.csv')
        df_results.to_csv(csv_path, index=False)
        print(f"ğŸ’¾ æ”¹è¿›é¢„æµ‹ç»“æœå·²ä¿å­˜: {csv_path}")
        
        # è®¡ç®—ç»Ÿè®¡
        print(f"\nğŸ“Š æ”¹è¿›æ¨¡å‹é¢„æµ‹ç»Ÿè®¡:")
        for model_name, (_, y_pred) in results.items():
            pred_values = data[f'{model_name}_Prediction']
            mse = np.mean((data['Ground_Truth'] - pred_values) ** 2)
            rmse = np.sqrt(mse)
            mae = np.mean(np.abs(data['Ground_Truth'] - pred_values))
            correlation = np.corrcoef(data['Ground_Truth'], pred_values)[0, 1]
            
            # è®¡ç®—å”¯ä¸€å€¼æ¯”ä¾‹ï¼ˆé¿å…å‘¨æœŸæ€§ï¼‰
            unique_ratio = len(np.unique(pred_values.round(2))) / len(pred_values)
            
            print(f"  {model_name}: RMSE={rmse:.2f}, MAE={mae:.2f}, Correlation={correlation:.4f}")
            print(f"    å“åº”æ¯”ä¾‹: {correlation:.4f}")
            print(f"    å”¯ä¸€å€¼æ¯”ä¾‹: {unique_ratio:.4f} (è¶Šé«˜è¶Šå¥½)")
    
    print(f"\nâœ… æ”¹è¿›LSTMå’ŒGRUæµ‹è¯•å®Œæˆï¼")

if __name__ == "__main__":
    main()