#!/usr/bin/env python3
"""
Colabå…¨å‚æ•°ç»„åˆå®éªŒè„šæœ¬
åœ¨Colabä¸­è¿è¡Œæ‰€æœ‰å‚ã€æ‰€æœ‰æ¨¡å‹ã€æ‰€æœ‰å‚æ•°ç»„åˆ
"""

import os
import subprocess
import sys
import time
from datetime import datetime
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

def check_environment():
    """æ£€æŸ¥ç¯å¢ƒ"""
    print("ğŸ” æ£€æŸ¥ç¯å¢ƒ...")
    
    # æ£€æŸ¥CUDA
    try:
        import torch
        print(f"CUDA available: {torch.cuda.is_available()}")
        if torch.cuda.is_available():
            print(f"Device: {torch.cuda.get_device_name(0)}")
    except ImportError:
        print("PyTorch not available")
    
    # æ£€æŸ¥æ•°æ®æ–‡ä»¶
    if os.path.exists('data/Project1033.csv'):
        print("âœ… æ•°æ®æ–‡ä»¶å­˜åœ¨")
    else:
        print("âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨")
        return False
    
    return True

def setup_a100():
    """è®¾ç½®A100ä¼˜åŒ–"""
    try:
        import torch
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.allow_tf32 = True
        torch.backends.cudnn.benchmark = True
        torch.cuda.set_per_process_memory_fraction(0.9)
        print("âœ… A100ä¼˜åŒ–è®¾ç½®å®Œæˆ")
    except ImportError:
        print("PyTorch not available, skipping A100 optimization")

def run_experiment(model, hist_weather, forecast, complexity, description):
    """è¿è¡Œå•ä¸ªå®éªŒ"""
    print(f"\nğŸš€ {description}")
    print("-" * 60)
    
    cmd = [
        sys.executable, 'main.py',
        '--config', 'config/default.yaml',
        '--model', model,
        '--use_hist_weather', hist_weather,
        '--use_forecast', forecast,
        '--model_complexity', complexity,
        '--past_days', '3'
    ]
    
    start_time = time.time()
    result = subprocess.run(cmd, capture_output=True, text=True)
    end_time = time.time()
    
    if result.returncode == 0:
        print(f"âœ… {description} å®Œæˆ (è€—æ—¶: {end_time - start_time:.2f}ç§’)")
        return True
    else:
        print(f"âŒ {description} å¤±è´¥")
        print(f"é”™è¯¯: {result.stderr}")
        return False

def run_full_experiments():
    """è¿è¡Œå…¨å‚æ•°ç»„åˆå®éªŒ"""
    print("\nğŸ”¬ å…¨å‚æ•°ç»„åˆå®éªŒ")
    print("=" * 80)
    
    # æ¨¡å‹åˆ—è¡¨
    models = ['Transformer', 'LSTM', 'GRU', 'TCN', 'RF', 'GBR', 'XGB', 'LGBM']
    
    # ç‰¹å¾ç»„åˆ
    feature_configs = [
        ('hist_only', 'true', 'false'),
        ('fcst_only', 'false', 'true'),
        ('both', 'true', 'true'),
        ('none', 'false', 'false')
    ]
    
    # å¤æ‚åº¦ç»„åˆ
    complexities = ['low', 'medium', 'high']
    
    # ç»Ÿè®¡ä¿¡æ¯
    total_experiments = len(models) * len(feature_configs) * len(complexities)
    completed = 0
    failed = 0
    
    print(f"ğŸ“Š æ€»å®éªŒæ•°: {total_experiments}")
    print(f"   æ¨¡å‹æ•°: {len(models)}")
    print(f"   ç‰¹å¾ç»„åˆ: {len(feature_configs)}")
    print(f"   å¤æ‚åº¦: {len(complexities)}")
    
    start_time = time.time()
    
    for model in models:
        print(f"\nğŸ¯ å¼€å§‹ {model} æ¨¡å‹å®éªŒ")
        print("-" * 60)
        
        for feat_desc, hist_weather, forecast in feature_configs:
            print(f"\nğŸ“‹ ç‰¹å¾ç»„åˆ: {feat_desc}")
            
            for complexity in complexities:
                description = f"{model} - {feat_desc} - {complexity}"
                
                if run_experiment(model, hist_weather, forecast, complexity, description):
                    completed += 1
                else:
                    failed += 1
                
                # æ˜¾ç¤ºè¿›åº¦
                progress = (completed + failed) / total_experiments * 100
                elapsed = time.time() - start_time
                eta = elapsed / (completed + failed) * (total_experiments - completed - failed) if (completed + failed) > 0 else 0
                
                print(f"ğŸ“ˆ è¿›åº¦: {completed + failed}/{total_experiments} ({progress:.1f}%)")
                print(f"â±ï¸  å·²ç”¨æ—¶é—´: {elapsed/60:.1f}åˆ†é’Ÿ, é¢„è®¡å‰©ä½™: {eta/60:.1f}åˆ†é’Ÿ")
    
    end_time = time.time()
    total_time = end_time - start_time
    
    print(f"\nğŸ‰ å…¨å‚æ•°ç»„åˆå®éªŒå®Œæˆï¼")
    print(f"ğŸ“Š æˆåŠŸ: {completed}/{total_experiments}")
    print(f"âŒ å¤±è´¥: {failed}/{total_experiments}")
    print(f"â±ï¸  æ€»è€—æ—¶: {total_time/60:.1f}åˆ†é’Ÿ")
    
    return completed, failed

def analyze_all_results():
    """åˆ†ææ‰€æœ‰ç»“æœ"""
    print("\nğŸ“Š åˆ†ææ‰€æœ‰ç»“æœ...")
    
    try:
        import glob
        
        # æŸ¥æ‰¾æ‰€æœ‰summary.csvæ–‡ä»¶
        summary_files = glob.glob('result/**/summary.csv', recursive=True)
        
        if not summary_files:
            print("âŒ æœªæ‰¾åˆ°ç»“æœæ–‡ä»¶")
            return
        
        print(f"âœ… æ‰¾åˆ° {len(summary_files)} ä¸ªç»“æœæ–‡ä»¶")
        
        # åˆå¹¶æ‰€æœ‰ç»“æœ
        all_results = []
        for file in summary_files:
            try:
                df = pd.read_csv(file)
                all_results.append(df)
            except Exception as e:
                print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥ {file}: {e}")
        
        if not all_results:
            print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„ç»“æœæ–‡ä»¶")
            return
        
        # åˆå¹¶ç»“æœ
        combined_df = pd.concat(all_results, ignore_index=True)
        
        # ä¿å­˜åˆå¹¶ç»“æœ
        combined_df.to_csv('result/all_experiments_results.csv', index=False)
        print("âœ… åˆå¹¶ç»“æœä¿å­˜åˆ° result/all_experiments_results.csv")
        
        # åˆ›å»ºå¯è§†åŒ–
        create_visualizations(combined_df)
        
        # æ˜¾ç¤ºç»Ÿè®¡ç»“æœ
        show_statistics(combined_df)
        
    except Exception as e:
        print(f"âŒ åˆ†æç»“æœæ—¶å‡ºé”™: {e}")

def create_visualizations(df):
    """åˆ›å»ºå¯è§†åŒ–å›¾è¡¨"""
    print("\nğŸ“Š åˆ›å»ºå¯è§†åŒ–å›¾è¡¨...")
    
    plt.style.use('default')
    fig, axes = plt.subplots(3, 3, figsize=(20, 15))
    
    # 1. æ¨¡å‹æ€§èƒ½å¯¹æ¯”
    ax1 = axes[0, 0]
    model_perf = df.groupby('model')['rmse'].mean().sort_values()
    model_perf.plot(kind='bar', ax=ax1, color='skyblue')
    ax1.set_title('Model Performance (RMSE)', fontsize=12)
    ax1.set_ylabel('RMSE')
    ax1.tick_params(axis='x', rotation=45)
    
    # 2. ç‰¹å¾ç»„åˆå½±å“
    ax2 = axes[0, 1]
    feature_perf = df.groupby(['use_hist_weather', 'use_forecast'])['rmse'].mean()
    feature_perf.plot(kind='bar', ax=ax2, color='lightcoral')
    ax2.set_title('Feature Combination Impact', fontsize=12)
    ax2.set_ylabel('RMSE')
    ax2.tick_params(axis='x', rotation=45)
    
    # 3. å¤æ‚åº¦å½±å“
    ax3 = axes[0, 2]
    complexity_perf = df.groupby('model_complexity')['rmse'].mean()
    complexity_perf.plot(kind='bar', ax=ax3, color='lightgreen')
    ax3.set_title('Complexity Impact', fontsize=12)
    ax3.set_ylabel('RMSE')
    ax3.tick_params(axis='x', rotation=45)
    
    # 4. è®­ç»ƒæ—¶é—´å¯¹æ¯”
    ax4 = axes[1, 0]
    train_time = df.groupby('model')['train_time_sec'].mean().sort_values()
    train_time.plot(kind='bar', ax=ax4, color='orange')
    ax4.set_title('Training Time Comparison', fontsize=12)
    ax4.set_ylabel('Time (seconds)')
    ax4.tick_params(axis='x', rotation=45)
    
    # 5. å‚æ•°æ•°é‡å¯¹æ¯”
    ax5 = axes[1, 1]
    param_count = df.groupby('model')['param_count'].mean().sort_values()
    param_count.plot(kind='bar', ax=ax5, color='purple')
    ax5.set_title('Parameter Count Comparison', fontsize=12)
    ax5.set_ylabel('Parameters')
    ax5.tick_params(axis='x', rotation=45)
    
    # 6. æ€§èƒ½vsæ—¶é—´æ•£ç‚¹å›¾
    ax6 = axes[1, 2]
    scatter = ax6.scatter(df['train_time_sec'], df['rmse'], c=df['param_count'], cmap='viridis', alpha=0.7)
    ax6.set_xlabel('Training Time (s)')
    ax6.set_ylabel('RMSE')
    ax6.set_title('Performance vs Training Time')
    plt.colorbar(scatter, ax=ax6, label='Parameter Count')
    
    # 7. æ¨¡å‹ç±»å‹æ€§èƒ½å¯¹æ¯”
    ax7 = axes[2, 0]
    df['model_type'] = df['model'].apply(lambda x: 'DL' if x in ['Transformer', 'LSTM', 'GRU', 'TCN'] else 'ML')
    type_perf = df.groupby('model_type')['rmse'].mean()
    type_perf.plot(kind='bar', ax=ax7, color=['red', 'blue'])
    ax7.set_title('DL vs ML Performance', fontsize=12)
    ax7.set_ylabel('RMSE')
    ax7.tick_params(axis='x', rotation=0)
    
    # 8. ç‰¹å¾é‡è¦æ€§çƒ­å›¾
    ax8 = axes[2, 1]
    feature_matrix = df.pivot_table(values='rmse', index='use_hist_weather', columns='use_forecast', aggfunc='mean')
    sns.heatmap(feature_matrix, annot=True, fmt='.4f', cmap='YlOrRd', ax=ax8)
    ax8.set_title('Feature Combination Heatmap', fontsize=12)
    ax8.set_xlabel('Use Forecast')
    ax8.set_ylabel('Use Hist Weather')
    
    # 9. å¤æ‚åº¦vsæ€§èƒ½
    ax9 = axes[2, 2]
    complexity_rmse = df.groupby(['model', 'model_complexity'])['rmse'].mean().unstack()
    complexity_rmse.plot(kind='bar', ax=ax9, width=0.8)
    ax9.set_title('Complexity vs Performance by Model', fontsize=12)
    ax9.set_ylabel('RMSE')
    ax9.tick_params(axis='x', rotation=45)
    ax9.legend(title='Complexity')
    
    plt.tight_layout()
    plt.savefig('result/comprehensive_analysis.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    print("âœ… å¯è§†åŒ–å›¾è¡¨ä¿å­˜åˆ° result/comprehensive_analysis.png")

def show_statistics(df):
    """æ˜¾ç¤ºç»Ÿè®¡ç»“æœ"""
    print("\n=== è¯¦ç»†ç»Ÿè®¡ç»“æœ ===")
    
    # æŒ‰æ¨¡å‹ç»Ÿè®¡
    print("\nğŸ“Š æŒ‰æ¨¡å‹ç»Ÿè®¡:")
    model_stats = df.groupby('model').agg({
        'test_loss': ['mean', 'std', 'min'],
        'rmse': ['mean', 'std', 'min'],
        'mae': ['mean', 'std', 'min'],
        'train_time_sec': ['mean', 'std'],
        'param_count': ['mean', 'std']
    }).round(4)
    print(model_stats)
    
    # æŒ‰ç‰¹å¾ç»„åˆç»Ÿè®¡
    print("\nğŸ“Š æŒ‰ç‰¹å¾ç»„åˆç»Ÿè®¡:")
    feature_stats = df.groupby(['use_hist_weather', 'use_forecast']).agg({
        'test_loss': ['mean', 'std'],
        'rmse': ['mean', 'std'],
        'mae': ['mean', 'std']
    }).round(4)
    print(feature_stats)
    
    # æŒ‰å¤æ‚åº¦ç»Ÿè®¡
    print("\nğŸ“Š æŒ‰å¤æ‚åº¦ç»Ÿè®¡:")
    complexity_stats = df.groupby('model_complexity').agg({
        'test_loss': ['mean', 'std'],
        'rmse': ['mean', 'std'],
        'mae': ['mean', 'std'],
        'train_time_sec': ['mean', 'std'],
        'param_count': ['mean', 'std']
    }).round(4)
    print(complexity_stats)
    
    # æ‰¾å‡ºæœ€ä½³é…ç½®
    best_overall = df.loc[df['rmse'].idxmin()]
    print(f"\nğŸ† æœ€ä½³æ•´ä½“é…ç½®:")
    print(f"   æ¨¡å‹: {best_overall['model']}")
    print(f"   å†å²å¤©æ°”: {best_overall['use_hist_weather']}")
    print(f"   é¢„æµ‹å¤©æ°”: {best_overall['use_forecast']}")
    print(f"   å¤æ‚åº¦: {best_overall.get('model_complexity', 'N/A')}")
    print(f"   RMSE: {best_overall['rmse']:.4f}")
    print(f"   MAE: {best_overall['mae']:.4f}")
    print(f"   è®­ç»ƒæ—¶é—´: {best_overall['train_time_sec']:.2f}ç§’")
    
    # æŒ‰æ¨¡å‹æ‰¾å‡ºæœ€ä½³
    print(f"\nğŸ† å„æ¨¡å‹æœ€ä½³é…ç½®:")
    for model in df['model'].unique():
        model_df = df[df['model'] == model]
        best_model = model_df.loc[model_df['rmse'].idxmin()]
        print(f"   {model}: RMSE={best_model['rmse']:.4f}, ç‰¹å¾={best_model['use_hist_weather']}/{best_model['use_forecast']}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ SolarPV-Prediction å…¨å‚æ•°ç»„åˆå®éªŒ (Colabç‰ˆ)")
    print(f"â° å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 80)
    
    # æ£€æŸ¥ç¯å¢ƒ
    if not check_environment():
        return
    
    # è®¾ç½®A100ä¼˜åŒ–
    setup_a100()
    
    # åˆ›å»ºç»“æœç›®å½•
    if not os.path.exists('result'):
        os.makedirs('result')
        print("âœ… åˆ›å»ºresultç›®å½•")
    
    # è¿è¡Œå…¨å‚æ•°ç»„åˆå®éªŒ
    completed, failed = run_full_experiments()
    
    # åˆ†æç»“æœ
    analyze_all_results()
    
    print(f"\nğŸ‰ æ‰€æœ‰å®éªŒå®Œæˆï¼")
    print(f"ğŸ“Š æˆåŠŸ: {completed}")
    print(f"âŒ å¤±è´¥: {failed}")
    print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: result/ ç›®å½•")
    print(f"ğŸ“Š åˆå¹¶ç»“æœ: result/all_experiments_results.csv")
    print(f"ğŸ“Š å¯è§†åŒ–: result/comprehensive_analysis.png")

if __name__ == "__main__":
    main()
