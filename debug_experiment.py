#!/usr/bin/env python3
"""
å®éªŒè°ƒè¯•ä»£ç 
ç”¨äºè¯Šæ–­å®éªŒè¿è¡Œä¸­çš„é—®é¢˜
"""

import os
import sys
import yaml
import pandas as pd
import numpy as np
from pathlib import Path
import traceback
import subprocess
from datetime import datetime

def test_single_experiment_run():
    """æµ‹è¯•å•ä¸ªå®éªŒçš„å®Œæ•´è¿è¡Œæµç¨‹"""
    print("ğŸ” è°ƒè¯•å•ä¸ªå®éªŒè¿è¡Œ")
    print("=" * 60)
    
    # é€‰æ‹©ä¸€ä¸ªç®€å•çš„é…ç½®è¿›è¡Œæµ‹è¯•
    config_name = "LSR_low_PV_24h_noTE"
    config_path = f"config/projects/1140/{config_name}.yaml"
    
    if not os.path.exists(config_path):
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        return False
    
    print(f"âœ… ä½¿ç”¨é…ç½®æ–‡ä»¶: {config_path}")
    
    # åŠ è½½é…ç½®
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    print(f"âœ… é…ç½®åŠ è½½æˆåŠŸ")
    print(f"   æ•°æ®è·¯å¾„: {config.get('data_path')}")
    print(f"   ä¿å­˜è·¯å¾„: {config.get('save_dir')}")
    print(f"   æ¨¡å‹: {config.get('model')}")
    print(f"   å¤æ‚åº¦: {config.get('model_complexity')}")
    
    # æ£€æŸ¥æ•°æ®æ–‡ä»¶
    data_path = config.get('data_path')
    if not os.path.exists(data_path):
        print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_path}")
        return False
    
    print(f"âœ… æ•°æ®æ–‡ä»¶å­˜åœ¨: {data_path}")
    
    # è¿è¡Œå•ä¸ªå®éªŒ
    print(f"\nğŸš€ å¼€å§‹è¿è¡Œå®éªŒ: {config_name}")
    
    try:
        # æ„å»ºmain.pyå‘½ä»¤
        cmd = [
            'python', 'main.py',
            '--config', config_path
        ]
        
        print(f"æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
        
        # è¿è¡Œå®éªŒ
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
        )
        
        print(f"è¿”å›ç : {result.returncode}")
        
        if result.stdout:
            print(f"\nğŸ“¤ æ ‡å‡†è¾“å‡º:")
            print(result.stdout[-2000:])  # åªæ˜¾ç¤ºæœ€å2000å­—ç¬¦
        
        if result.stderr:
            print(f"\nâŒ é”™è¯¯è¾“å‡º:")
            print(result.stderr[-2000:])  # åªæ˜¾ç¤ºæœ€å2000å­—ç¬¦
        
        if result.returncode == 0:
            print(f"âœ… å®éªŒè¿è¡ŒæˆåŠŸ")
            
            # æ£€æŸ¥ç»“æœæ–‡ä»¶
            save_dir = Path(config.get('save_dir'))
            if save_dir.exists():
                print(f"âœ… ç»“æœç›®å½•å­˜åœ¨: {save_dir}")
                
                # æŸ¥æ‰¾ç»“æœæ–‡ä»¶
                result_files = list(save_dir.glob("*"))
                print(f"   ç»“æœæ–‡ä»¶: {[f.name for f in result_files]}")
                
                # æ£€æŸ¥Excelæ–‡ä»¶
                excel_files = list(save_dir.glob("*.xlsx"))
                if excel_files:
                    excel_file = excel_files[0]
                    print(f"âœ… æ‰¾åˆ°Excelæ–‡ä»¶: {excel_file}")
                    
                    try:
                        df = pd.read_excel(excel_file)
                        print(f"   Excelå†…å®¹å½¢çŠ¶: {df.shape}")
                        print(f"   Excelåˆ—å: {list(df.columns)}")
                        
                        # æ£€æŸ¥å…³é”®æŒ‡æ ‡
                        key_metrics = ['mae', 'rmse', 'r2', 'mape', 'train_time_sec', 'inference_time_sec']
                        for metric in key_metrics:
                            if metric in df.columns:
                                value = df[metric].iloc[0] if len(df) > 0 else None
                                print(f"   {metric}: {value}")
                            else:
                                print(f"   âŒ ç¼ºå°‘åˆ—: {metric}")
                        
                    except Exception as e:
                        print(f"âŒ è¯»å–Excelæ–‡ä»¶å¤±è´¥: {e}")
                
                # æ£€æŸ¥CSVæ–‡ä»¶
                csv_files = list(save_dir.glob("*.csv"))
                if csv_files:
                    csv_file = csv_files[0]
                    print(f"âœ… æ‰¾åˆ°CSVæ–‡ä»¶: {csv_file}")
                    
                    try:
                        df = pd.read_csv(csv_file)
                        print(f"   CSVå†…å®¹å½¢çŠ¶: {df.shape}")
                        print(f"   CSVåˆ—å: {list(df.columns)}")
                        
                        # æ£€æŸ¥å…³é”®æŒ‡æ ‡
                        key_metrics = ['mae', 'rmse', 'r2', 'mape', 'train_time_sec', 'inference_time_sec']
                        for metric in key_metrics:
                            if metric in df.columns:
                                value = df[metric].iloc[0] if len(df) > 0 else None
                                print(f"   {metric}: {value}")
                            else:
                                print(f"   âŒ ç¼ºå°‘åˆ—: {metric}")
                        
                    except Exception as e:
                        print(f"âŒ è¯»å–CSVæ–‡ä»¶å¤±è´¥: {e}")
                
            else:
                print(f"âŒ ç»“æœç›®å½•ä¸å­˜åœ¨: {save_dir}")
            
        else:
            print(f"âŒ å®éªŒè¿è¡Œå¤±è´¥ï¼Œè¿”å›ç : {result.returncode}")
            return False
        
        return True
        
    except subprocess.TimeoutExpired:
        print(f"âŒ å®éªŒè¿è¡Œè¶…æ—¶")
        return False
    except Exception as e:
        print(f"âŒ å®éªŒè¿è¡Œå¼‚å¸¸: {e}")
        traceback.print_exc()
        return False

def test_data_preprocessing():
    """æµ‹è¯•æ•°æ®é¢„å¤„ç†æµç¨‹"""
    print("\nğŸ” è°ƒè¯•æ•°æ®é¢„å¤„ç†")
    print("=" * 60)
    
    try:
        # å¯¼å…¥æ•°æ®å·¥å…·
        sys.path.append('.')
        from data.data_utils import load_raw_data, preprocess_features
        
        # åŠ è½½æ•°æ®
        data_path = "data/Project1140.csv"
        print(f"ğŸ“Š åŠ è½½æ•°æ®: {data_path}")
        
        df = load_raw_data(data_path)
        print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸï¼Œå½¢çŠ¶: {df.shape}")
        print(f"   åˆ—å: {list(df.columns)}")
        
        # æµ‹è¯•é…ç½®
        config = {
            'use_pv': True,
            'use_hist_weather': False,
            'use_forecast': False,
            'weather_category': 'none',
            'use_time_encoding': False,
            'past_hours': 24
        }
        
        print(f"ğŸ“ ä½¿ç”¨é…ç½®: {config}")
        
        # é¢„å¤„ç†æ•°æ®
        df_clean, hist_feats, fcst_feats, scaler_hist, scaler_fcst, scaler_target = preprocess_features(df, config)
        
        print(f"âœ… æ•°æ®é¢„å¤„ç†æˆåŠŸ")
        print(f"   æ¸…ç†åæ•°æ®å½¢çŠ¶: {df_clean.shape}")
        print(f"   å†å²ç‰¹å¾: {hist_feats}")
        print(f"   é¢„æµ‹ç‰¹å¾: {fcst_feats}")
        print(f"   ç›®æ ‡åˆ—: Capacity Factor")
        
        # æ£€æŸ¥ç›®æ ‡åˆ—
        if 'Capacity Factor' in df_clean.columns:
            target_values = df_clean['Capacity Factor'].dropna()
            print(f"âœ… ç›®æ ‡åˆ—å­˜åœ¨ï¼Œæœ‰æ•ˆå€¼æ•°é‡: {len(target_values)}")
            print(f"   ç›®æ ‡å€¼èŒƒå›´: {target_values.min():.3f} - {target_values.max():.3f}")
        else:
            print(f"âŒ ç›®æ ‡åˆ—ä¸å­˜åœ¨")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ•°æ®é¢„å¤„ç†å¤±è´¥: {e}")
        traceback.print_exc()
        return False

def test_model_training():
    """æµ‹è¯•æ¨¡å‹è®­ç»ƒæµç¨‹"""
    print("\nğŸ” è°ƒè¯•æ¨¡å‹è®­ç»ƒ")
    print("=" * 60)
    
    try:
        # æ£€æŸ¥ä¾èµ–åŒ…
        missing_packages = []
        
        try:
            import xgboost
            print("âœ… XGBoost å¯ç”¨")
        except ImportError:
            missing_packages.append('xgboost')
            print("âŒ XGBoost ä¸å¯ç”¨")
        
        try:
            import lightgbm
            print("âœ… LightGBM å¯ç”¨")
        except ImportError:
            missing_packages.append('lightgbm')
            print("âŒ LightGBM ä¸å¯ç”¨")
        
        try:
            import sklearn
            print("âœ… Scikit-learn å¯ç”¨")
        except ImportError:
            missing_packages.append('scikit-learn')
            print("âŒ Scikit-learn ä¸å¯ç”¨")
        
        if missing_packages:
            print(f"âš ï¸  ç¼ºå°‘ä¾èµ–åŒ…: {missing_packages}")
            print("   åœ¨Colabç¯å¢ƒä¸­è¿™äº›åŒ…åº”è¯¥æ˜¯å¯ç”¨çš„")
            return False
        
        # å¦‚æœæ‰€æœ‰åŒ…éƒ½å¯ç”¨ï¼Œæµ‹è¯•è®­ç»ƒæµç¨‹
        from train.train_ml import train_ml_model
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        X_train = np.random.rand(100, 5)
        y_train = np.random.rand(100)
        X_val = np.random.rand(20, 5)
        y_val = np.random.rand(20)
        
        # æµ‹è¯•é…ç½®
        config = {
            'model': 'Linear',
            'model_params': {
                'learning_rate': 0.001
            }
        }
        
        print(f"ğŸ“ æµ‹è¯•LSRæ¨¡å‹è®­ç»ƒ")
        print(f"   è®­ç»ƒæ•°æ®å½¢çŠ¶: X={X_train.shape}, y={y_train.shape}")
        print(f"   éªŒè¯æ•°æ®å½¢çŠ¶: X={X_val.shape}, y={y_val.shape}")
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®ï¼ˆæ·»åŠ ç¼ºå¤±çš„å‚æ•°ï¼‰
        Xf_train = np.random.rand(100, 3)
        Xh_test = np.random.rand(20, 5)
        Xf_test = np.random.rand(20, 3)
        y_test = np.random.rand(20)
        dates_test = [f"2024-01-01 {i:02d}:00:00" for i in range(20)]
        
        print(f"   å®Œæ•´è®­ç»ƒæ•°æ®å½¢çŠ¶: Xh={X_train.shape}, Xf={Xf_train.shape}, y={y_train.shape}")
        print(f"   å®Œæ•´æµ‹è¯•æ•°æ®å½¢çŠ¶: Xh={Xh_test.shape}, Xf={Xf_test.shape}, y={y_test.shape}")
        
        # è®­ç»ƒæ¨¡å‹
        model, metrics = train_ml_model(
            config=config,
            Xh_train=X_train,
            Xf_train=Xf_train,
            y_train=y_train,
            Xh_test=Xh_test,
            Xf_test=Xf_test,
            y_test=y_test,
            dates_test=dates_test
        )
        
        print(f"âœ… æ¨¡å‹è®­ç»ƒæˆåŠŸ")
        print(f"   æ¨¡å‹ç±»å‹: {type(model)}")
        print(f"   æ€§èƒ½æŒ‡æ ‡: {metrics}")
        
        # æ£€æŸ¥å…³é”®æŒ‡æ ‡
        key_metrics = ['mae', 'rmse', 'r2', 'mape']
        for metric in key_metrics:
            if metric in metrics:
                print(f"   {metric}: {metrics[metric]}")
            else:
                print(f"   âŒ ç¼ºå°‘æŒ‡æ ‡: {metric}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹è®­ç»ƒå¤±è´¥: {e}")
        traceback.print_exc()
        return False

def test_result_saving():
    """æµ‹è¯•ç»“æœä¿å­˜æµç¨‹"""
    print("\nğŸ” è°ƒè¯•ç»“æœä¿å­˜")
    print("=" * 60)
    
    try:
        # å¯¼å…¥è¯„ä¼°å·¥å…·
        sys.path.append('.')
        from eval.eval_utils import save_results
        
        # åˆ›å»ºæµ‹è¯•ç»“æœï¼ˆä½¿ç”¨æ­£ç¡®çš„æ ¼å¼ï¼‰
        test_metrics = {
            'mae': 0.123,
            'rmse': 0.234,
            'r2': 0.567,
            'mape': 12.34,
            'train_time_sec': 5.67,
            'inference_time_sec': 0.12,
            'param_count': 100,
            'samples_count': 1000,
            'predictions': np.random.rand(20, 1),
            'y_true': np.random.rand(20, 1)
        }
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        test_dates = [f"2024-01-01 {i:02d}:00:00" for i in range(20)]
        test_y_true = np.random.rand(20)
        test_Xh = np.random.rand(20, 5)
        test_Xf = np.random.rand(20, 3)
        
        # æµ‹è¯•ä¿å­˜ç›®å½•
        test_save_dir = Path("debug_test_results")
        test_save_dir.mkdir(exist_ok=True)
        
        test_config = {
            'save_dir': str(test_save_dir),
            'model': 'Linear',
            'plot_days': 7,
            'past_hours': 24,
            'future_hours': 24
        }
        
        print(f"ğŸ“ æµ‹è¯•ç»“æœä¿å­˜åˆ°: {test_save_dir}")
        print(f"   æµ‹è¯•æŒ‡æ ‡: {list(test_metrics.keys())}")
        
        # åˆ›å»ºæ¨¡æ‹Ÿæ¨¡å‹
        class MockModel:
            def predict(self, X):
                return np.random.rand(X.shape[0], 1)
        
        mock_model = MockModel()
        
        # ä¿å­˜ç»“æœï¼ˆä½¿ç”¨æ­£ç¡®çš„å‚æ•°æ ¼å¼ï¼‰
        save_results(
            model=mock_model,
            metrics=test_metrics,
            dates=test_dates,
            y_true=test_y_true,
            Xh_test=test_Xh,
            Xf_test=test_Xf,
            config=test_config
        )
        
        print(f"âœ… ç»“æœä¿å­˜æˆåŠŸ")
        
        # æ£€æŸ¥ä¿å­˜çš„æ–‡ä»¶
        result_files = list(test_save_dir.glob("*"))
        print(f"   ä¿å­˜çš„æ–‡ä»¶: {[f.name for f in result_files]}")
        
        # æ£€æŸ¥Excelæ–‡ä»¶
        excel_files = list(test_save_dir.glob("*.xlsx"))
        if excel_files:
            excel_file = excel_files[0]
            df = pd.read_excel(excel_file)
            print(f"   Excelæ–‡ä»¶å†…å®¹å½¢çŠ¶: {df.shape}")
            print(f"   Excelåˆ—å: {list(df.columns)}")
            
            # éªŒè¯å…³é”®æŒ‡æ ‡
            key_metrics = ['mae', 'rmse', 'r2', 'mape', 'train_time_sec']
            for metric in key_metrics:
                if metric in df.columns:
                    saved_value = df[metric].iloc[0]
                    original_value = test_metrics[metric]
                    print(f"   âœ… {metric}: æœŸæœ›{original_value}, å®é™…{saved_value}")
                else:
                    print(f"   âŒ ç¼ºå°‘åˆ—: {metric}")
        
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        import shutil
        shutil.rmtree(test_save_dir)
        print(f"âœ… æµ‹è¯•æ–‡ä»¶å·²æ¸…ç†")
        
        return True
        
    except Exception as e:
        print(f"âŒ ç»“æœä¿å­˜å¤±è´¥: {e}")
        traceback.print_exc()
        return False

def main():
    """ä¸»è°ƒè¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹å®éªŒè°ƒè¯•")
    print("=" * 80)
    
    debug_results = {}
    
    # æµ‹è¯•1: æ•°æ®é¢„å¤„ç†
    debug_results['data_preprocessing'] = test_data_preprocessing()
    
    # æµ‹è¯•2: æ¨¡å‹è®­ç»ƒ
    debug_results['model_training'] = test_model_training()
    
    # æµ‹è¯•3: ç»“æœä¿å­˜
    debug_results['result_saving'] = test_result_saving()
    
    # æµ‹è¯•4: å®Œæ•´å®éªŒè¿è¡Œ
    debug_results['full_experiment'] = test_single_experiment_run()
    
    # æ€»ç»“
    print("\n" + "=" * 80)
    print("ğŸ¯ è°ƒè¯•æ€»ç»“")
    print("=" * 80)
    
    for test_name, result in debug_results.items():
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"   {test_name}: {status}")
    
    total_passed = sum(debug_results.values())
    total_tests = len(debug_results)
    
    print(f"\nğŸ“Š æ€»ä½“ç»“æœ: {total_passed}/{total_tests} æµ‹è¯•é€šè¿‡")
    
    if total_passed == total_tests:
        print("ğŸ‰ æ‰€æœ‰è°ƒè¯•æµ‹è¯•é€šè¿‡ï¼")
    else:
        print("âš ï¸  éƒ¨åˆ†è°ƒè¯•æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥æ£€æŸ¥")
    
    return debug_results

if __name__ == "__main__":
    main()
