#!/usr/bin/env python3
"""
SolarPVé¡¹ç›® - æ‰¹é‡å®éªŒè„šæœ¬ (ä¿®å¤ç‰ˆæœ¬)
åœ¨Colabä¸Šè¿è¡Œ100ä¸ªé¡¹ç›®çš„å®Œæ•´å®éªŒï¼Œä¿å­˜ç»“æœåˆ°Google Drive
ä¿®å¤äº†ä¸´æ—¶æ–‡ä»¶å†²çªã€è¶…æ—¶è®¾ç½®ç­‰é—®é¢˜
"""

import os
import sys
import time
import subprocess
import yaml
import pandas as pd
from pathlib import Path
import re
import uuid

def check_drive_mount():
    """æ£€æŸ¥Google Driveæ˜¯å¦å·²æŒ‚è½½"""
    drive_path = "/content/drive/MyDrive"
    if os.path.exists(drive_path):
        print("âœ… Google Driveå·²æŒ‚è½½")
        return True
    else:
        print("âŒ Google DriveæœªæŒ‚è½½ï¼Œè¯·å…ˆæŒ‚è½½Drive")
        return False

def get_data_files():
    """æ‰«ædataç›®å½•ï¼Œè·å–æ‰€æœ‰é¡¹ç›®CSVæ–‡ä»¶"""
    data_dir = "data"
    if not os.path.exists(data_dir):
        print(f"âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
        return []
    
    csv_files = []
    for file in os.listdir(data_dir):
        if file.startswith("Project") and file.endswith(".csv"):
            project_id = file.replace("Project", "").replace(".csv", "")
            csv_files.append((project_id, os.path.join(data_dir, file)))
    
    csv_files.sort(key=lambda x: int(x[0]))  # æ­£åºæ’åº
    return csv_files

def get_config_files():
    """è·å–æ‰€æœ‰é…ç½®æ–‡ä»¶"""
    config_dir = "config/projects"
    all_config_files = []
    
    if os.path.exists(config_dir):
        for project_dir in sorted(os.listdir(config_dir)):
            project_path = os.path.join(config_dir, project_dir)
            if os.path.isdir(project_path):
                for config_file in sorted(os.listdir(project_path)):
                    if config_file.endswith('.yaml'):
                        all_config_files.append(os.path.join(project_path, config_file))
    
    return all_config_files

def get_completed_experiments(drive_path):
    """è·å–å·²å®Œæˆçš„å®éªŒåˆ—è¡¨"""
    completed_configs = set()
    
    try:
        results_file = os.path.join(drive_path, "SolarPV_Results", "all_results.csv")
        if os.path.exists(results_file):
            df = pd.read_csv(results_file)
            if 'config_file' in df.columns:
                completed_configs = set(df['config_file'].tolist())
                print(f"ğŸ“Š å‘ç° {len(completed_configs)} ä¸ªå·²å®Œæˆçš„å®éªŒ")
    except Exception as e:
        print(f"âš ï¸ æ— æ³•è¯»å–ç°æœ‰ç»“æœæ–‡ä»¶: {e}")
    
    return completed_configs

def run_experiment(config_file, data_file, project_id):
    """è¿è¡Œå•ä¸ªå®éªŒ"""
    try:
        # åŠ è½½é…ç½®æ–‡ä»¶
        with open(config_file, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        # ä¿®æ”¹é…ç½®æ–‡ä»¶ä¸­çš„data_path
        config['data_path'] = data_file
        config['plant_id'] = project_id
        
        # åˆ›å»ºä¸´æ—¶é…ç½®æ–‡ä»¶ï¼ˆä½¿ç”¨UUIDé¿å…å†²çªï¼‰
        temp_config = f"temp_config_{project_id}_{uuid.uuid4().hex[:8]}.yaml"
        with open(temp_config, 'w', encoding='utf-8') as f:
            yaml.dump(config, f, default_flow_style=False, allow_unicode=True)
        
        # è¿è¡Œå®éªŒå¹¶è®°å½•æ—¶é—´
        cmd = ['python', 'main.py', '--config', temp_config]
        start_time = time.time()
        
        # å¢åŠ è¶…æ—¶æ—¶é—´åˆ°60åˆ†é’Ÿ
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=3600)
        duration = time.time() - start_time
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if os.path.exists(temp_config):
            os.remove(temp_config)
        
        if result.returncode == 0:
            return True, result.stdout, result.stderr, duration, config
        else:
            return False, result.stdout, result.stderr, duration, config
            
    except subprocess.TimeoutExpired:
        # å¤„ç†è¶…æ—¶
        if os.path.exists(temp_config):
            os.remove(temp_config)
        return False, "", "å®éªŒè¶…æ—¶ï¼ˆ60åˆ†é’Ÿï¼‰", 3600.0, {}
    except Exception as e:
        return False, "", str(e), 0.0, {}

def parse_experiment_output(output, config_file, duration, config):
    """è§£æå®éªŒè¾“å‡ºï¼Œæå–ç»“æœ"""
    try:
        # æå–æ¨¡å‹ä¿¡æ¯
        model_name = config.get('model', 'Unknown')
        complexity = config.get('model_complexity', 'unknown')
        
        # æå–è®­ç»ƒå‚æ•°
        use_pv = config.get('use_pv', False)
        use_hist_weather = config.get('use_hist_weather', False)
        use_forecast = config.get('use_forecast', False)
        weather_category = config.get('weather_category', 'none')
        time_encoding = config.get('use_time_encoding', False)
        past_days = config.get('past_days', 1)
        use_ideal_nwp = config.get('use_ideal_nwp', False)
        
        # ç¡®å®šè¾“å…¥ç±»åˆ«
        if use_pv and use_hist_weather:
            input_category = 'PV_plus_HW'
        elif use_pv and use_forecast and use_ideal_nwp:
            input_category = 'PV_plus_NWP_plus'
        elif use_pv and use_forecast:
            input_category = 'PV_plus_NWP'
        elif use_pv:
            input_category = 'PV'
        elif use_forecast and use_ideal_nwp:
            input_category = 'NWP_plus'
        elif use_forecast:
            input_category = 'NWP'
        else:
            input_category = 'Unknown'
        
        # åˆ¤æ–­æ˜¯å¦ä¸ºæ·±åº¦å­¦ä¹ æ¨¡å‹
        is_dl_model = model_name in ['LSTM', 'GRU', 'Transformer', 'TCN']
        has_learning_rate = is_dl_model or model_name in ['XGB', 'LGBM']
        
        # æå–æŒ‡æ ‡ï¼ˆä½¿ç”¨æ­£ç¡®çš„æ ¼å¼ï¼šmse=0.1234ï¼‰
        mse_match = re.search(r'mse=([+-]?[0-9]*\.?[0-9]+(?:[eE][+-]?[0-9]+)?)', output)
        rmse_match = re.search(r'rmse=([+-]?[0-9]*\.?[0-9]+(?:[eE][+-]?[0-9]+)?)', output)
        mae_match = re.search(r'mae=([+-]?[0-9]*\.?[0-9]+(?:[eE][+-]?[0-9]+)?)', output)
        r_square_match = re.search(r'r_square=([+-]?[0-9]*\.?[0-9]+(?:[eE][+-]?[0-9]+)?)', output)
        
        # è°ƒè¯•ï¼šæ˜¾ç¤ºåŒ¹é…ç»“æœ
        print(f"ğŸ” è°ƒè¯•: MSEåŒ¹é…: {mse_match.group(1) if mse_match else 'None'}")
        print(f"ğŸ” è°ƒè¯•: RMSEåŒ¹é…: {rmse_match.group(1) if rmse_match else 'None'}")
        print(f"ğŸ” è°ƒè¯•: MAEåŒ¹é…: {mae_match.group(1) if mae_match else 'None'}")
        print(f"ğŸ” è°ƒè¯•: RÂ²åŒ¹é…: {r_square_match.group(1) if r_square_match else 'None'}")
        
        # è®¡ç®—å…¶ä»–æŒ‡æ ‡
        mse = float(mse_match.group(1)) if mse_match else 0.0
        rmse = float(rmse_match.group(1)) if rmse_match else 0.0
        mae = float(mae_match.group(1)) if mae_match else 0.0
        r_square = float(r_square_match.group(1)) if r_square_match else 0.0
        
        # è®¡ç®—NRMSEå’ŒSMAPE
        nrmse = (rmse / (mae + 1e-8)) * 100 if mae > 0 else 0.0
        smape = (2 * mae / (mae + 1e-8)) * 100 if mae > 0 else 0.0
        
        # æå–è®­ç»ƒä¿¡æ¯
        best_epoch = 0
        final_lr = 0.0
        if is_dl_model:
            epoch_match = re.search(r'Best epoch: (\d+)', output)
            lr_match = re.search(r'Final LR: ([\d.]+)', output)
            best_epoch = int(epoch_match.group(1)) if epoch_match else 0
            final_lr = float(lr_match.group(1)) if lr_match else 0.0
        
        # æå–å‚æ•°æ•°é‡
        param_match = re.search(r'Total parameters: ([\d,]+)', output)
        param_count = int(param_match.group(1).replace(',', '')) if param_match else 0
        
        # æå–æ ·æœ¬æ•°é‡
        samples_match = re.search(r'Training samples: (\d+)', output)
        samples_count = int(samples_match.group(1)) if samples_match else 0
        
        # æå–æ¨ç†æ—¶é—´
        inference_match = re.search(r'Inference time: ([\d.]+)s', output)
        inference_time = float(inference_match.group(1)) if inference_match else 0.0
        
        # æå–GPUå†…å­˜ä½¿ç”¨
        gpu_memory_match = re.search(r'GPU memory used: ([\d.]+)MB', output)
        gpu_memory_used = float(gpu_memory_match.group(1)) if gpu_memory_match else 0.0
        
        # åˆ›å»ºç»“æœè¡Œ
        result_row = {
            'model': model_name,
            'use_pv': use_pv,
            'use_hist_weather': use_hist_weather,
            'use_forecast': use_forecast,
            'weather_category': weather_category,
            'use_time_encoding': time_encoding,
            'past_days': past_days,
            'model_complexity': complexity,
            'epochs': config.get('epochs', 80 if complexity == 'high' else 50) if is_dl_model else 0,
            'batch_size': config.get('train_params', {}).get('batch_size', 64) if is_dl_model else 0,
            'learning_rate': config.get('train_params', {}).get('learning_rate', 0.001) if has_learning_rate else 0.0,
            'use_ideal_nwp': use_ideal_nwp,
            'input_category': input_category,
            'train_time_sec': round(duration, 4),
            'inference_time_sec': inference_time,
            'param_count': param_count,
            'samples_count': samples_count,
            'best_epoch': best_epoch if is_dl_model else 0,
            'final_lr': final_lr if is_dl_model else 0.0,
            'mse': mse,
            'rmse': rmse,
            'mae': mae,
            'nrmse': nrmse,
            'r_square': r_square,
            'smape': smape,
            'gpu_memory_used': gpu_memory_used,
            'config_file': os.path.basename(config_file)
        }
        
        return result_row
        
    except Exception as e:
        print(f"âš ï¸ è§£æå®éªŒç»“æœå¤±è´¥: {e}")
        return None

def save_results_to_drive(results, drive_path):
    """ä¿å­˜ç»“æœåˆ°Google Drive"""
    try:
        print(f"ğŸ” è°ƒè¯•: å‡†å¤‡ä¿å­˜ {len(results)} ä¸ªç»“æœåˆ° {drive_path}")
        
        results_dir = os.path.join(drive_path, "SolarPV_Results")
        print(f"ğŸ” è°ƒè¯•: ç»“æœç›®å½•: {results_dir}")
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(results_dir, exist_ok=True)
        print(f"ğŸ” è°ƒè¯•: ç›®å½•åˆ›å»ºæˆåŠŸ: {os.path.exists(results_dir)}")
        
        # ä¿å­˜åˆ°CSV
        results_file = os.path.join(results_dir, "all_results.csv")
        print(f"ğŸ” è°ƒè¯•: CSVæ–‡ä»¶è·¯å¾„: {results_file}")
        
        if os.path.exists(results_file):
            print(f"ğŸ” è°ƒè¯•: è¯»å–ç°æœ‰CSVæ–‡ä»¶")
            # è¯»å–ç°æœ‰ç»“æœ
            existing_df = pd.read_csv(results_file)
            print(f"ğŸ” è°ƒè¯•: ç°æœ‰ç»“æœæ•°é‡: {len(existing_df)}")
            new_df = pd.DataFrame(results)
            print(f"ğŸ” è°ƒè¯•: æ–°ç»“æœæ•°é‡: {len(new_df)}")
            combined_df = pd.concat([existing_df, new_df], ignore_index=True)
            print(f"ğŸ” è°ƒè¯•: åˆå¹¶åç»“æœæ•°é‡: {len(combined_df)}")
        else:
            print(f"ğŸ” è°ƒè¯•: åˆ›å»ºæ–°çš„CSVæ–‡ä»¶")
            combined_df = pd.DataFrame(results)
            print(f"ğŸ” è°ƒè¯•: æ–°ç»“æœæ•°é‡: {len(combined_df)}")
        
        # ä¿å­˜CSV
        combined_df.to_csv(results_file, index=False)
        print(f"âœ… ç»“æœå·²ä¿å­˜åˆ°: {results_file}")
        print(f"ğŸ” è°ƒè¯•: æ–‡ä»¶å¤§å°: {os.path.getsize(results_file)} å­—èŠ‚")
        
        # ä¿å­˜åˆ°Excel
        excel_file = os.path.join(results_dir, "all_results.xlsx")
        combined_df.to_excel(excel_file, index=False)
        print(f"âœ… Excelç»“æœå·²ä¿å­˜åˆ°: {excel_file}")
        print(f"ğŸ” è°ƒè¯•: Excelæ–‡ä»¶å¤§å°: {os.path.getsize(excel_file)} å­—èŠ‚")
        
    except Exception as e:
        print(f"âŒ ä¿å­˜ç»“æœå¤±è´¥: {e}")
        import traceback
        print(f"ğŸ” è°ƒè¯•: è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸŒŸ SolarPVé¡¹ç›® - æ‰¹é‡å®éªŒè„šæœ¬ (ä¿®å¤ç‰ˆæœ¬)")
    print("=" * 60)
    
    # æ£€æŸ¥Google Drive
    if not check_drive_mount():
        return
    
    drive_path = "/content/drive/MyDrive"
    
    # è·å–æ•°æ®æ–‡ä»¶
    print("ğŸ“ æ‰«ææ•°æ®æ–‡ä»¶...")
    data_files = get_data_files()
    if not data_files:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°æ•°æ®æ–‡ä»¶")
        return
    
    print(f"ğŸ“Š æ‰¾åˆ° {len(data_files)} ä¸ªæ•°æ®æ–‡ä»¶")
    
    # è·å–é…ç½®æ–‡ä»¶
    print("ğŸ“ æ‰«æé…ç½®æ–‡ä»¶...")
    config_files = get_config_files()
    print(f"ğŸ“Š æ‰¾åˆ° {len(config_files)} ä¸ªé…ç½®æ–‡ä»¶")
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦ç”Ÿæˆé…ç½®æ–‡ä»¶
    if len(config_files) < len(data_files) * 100:
        print("ğŸ”§ é…ç½®æ–‡ä»¶ä¸è¶³ï¼Œæ­£åœ¨ç”Ÿæˆ...")
        try:
            result = subprocess.run([
                'python', 'scripts/generate_dynamic_project_configs.py'
            ], capture_output=True, text=True, timeout=300)
            if result.returncode == 0:
                print("âœ… é…ç½®æ–‡ä»¶ç”Ÿæˆå®Œæˆ")
                config_files = get_config_files()
                print(f"ğŸ“Š ç°åœ¨æœ‰ {len(config_files)} ä¸ªé…ç½®æ–‡ä»¶")
            else:
                print(f"âŒ é…ç½®æ–‡ä»¶ç”Ÿæˆå¤±è´¥: {result.stderr}")
                return
        except Exception as e:
            print(f"âŒ é…ç½®æ–‡ä»¶ç”Ÿæˆå¼‚å¸¸: {e}")
            return
    
    # è·å–å·²å®Œæˆçš„å®éªŒ
    completed_configs = get_completed_experiments(drive_path)
    
    # å¼€å§‹å®éªŒ
    all_results = []
    total_experiments = 0
    completed_experiments = 0
    failed_experiments = 0
    
    for project_idx, (project_id, data_file) in enumerate(data_files, 1):
        print(f"\nğŸš€ å¼€å§‹é¡¹ç›® {project_id} çš„å®éªŒ ({project_idx}/{len(data_files)})")
        print(f"ğŸ“ æ•°æ®æ–‡ä»¶: {data_file}")
        
        # è·å–è¯¥é¡¹ç›®çš„é…ç½®æ–‡ä»¶
        project_configs = sorted([cf for cf in config_files if f"/{project_id}/" in cf])
        print(f"ğŸ“Š æ‰¾åˆ° {len(project_configs)} ä¸ªé…ç½®æ–‡ä»¶")
        
        if not project_configs:
            print(f"âš ï¸ é¡¹ç›® {project_id} æ²¡æœ‰é…ç½®æ–‡ä»¶ï¼Œè·³è¿‡")
            continue
        
        # æ˜¾ç¤ºä¸€äº›å·²å®Œæˆçš„å®éªŒç¤ºä¾‹
        if completed_configs:
            sample_completed = list(completed_configs)[:5]
            print(f"ğŸ” å·²å®Œæˆå®éªŒç¤ºä¾‹: {sample_completed}")
        
        project_results = []
        skipped_count = 0
        
        for config_file in project_configs:
            config_name = os.path.basename(config_file)
            total_experiments += 1
            
            # æ£€æŸ¥æ˜¯å¦å·²å®Œæˆ
            if config_name in completed_configs:
                skipped_count += 1
                if skipped_count <= 5:
                    print(f"â­ï¸ è·³è¿‡å·²å®Œæˆå®éªŒ: {config_name}")
                continue
            
            print(f"\nğŸ”„ è¿è¡Œå®éªŒ: {config_name}")
            
            # è¿è¡Œå®éªŒ
            success, stdout, stderr, duration, config = run_experiment(config_file, data_file, project_id)
            
            if success:
                # è§£æç»“æœ
                print(f"ğŸ” è°ƒè¯•: å¼€å§‹è§£æå®éªŒç»“æœ: {config_name}")
                result_row = parse_experiment_output(stdout, config_file, duration, config)
                if result_row:
                    project_results.append(result_row)
                    completed_experiments += 1
                    print(f"âœ… å®éªŒå®Œæˆ: {config_name} ({duration:.1f}s) - MSE: {result_row['mse']:.4f}")
                    print(f"ğŸ” è°ƒè¯•: è§£ææˆåŠŸï¼Œç»“æœå­—æ®µ: {list(result_row.keys())}")
                else:
                    failed_experiments += 1
                    print(f"âš ï¸ æ— æ³•è§£æå®éªŒç»“æœ: {config_name}")
                    print(f"ğŸ” è°ƒè¯•: å®éªŒè¾“å‡ºå‰500å­—ç¬¦: {stdout[:500]}")
            else:
                failed_experiments += 1
                print(f"âŒ å®éªŒå¤±è´¥: {config_name}")
                print(f"   é”™è¯¯: {stderr}")
                print(f"ğŸ” è°ƒè¯•: æ ‡å‡†è¾“å‡º: {stdout[:200]}")
        
        if skipped_count > 5:
            print(f"â­ï¸ ... è¿˜æœ‰ {skipped_count - 5} ä¸ªå·²å®Œæˆçš„å®éªŒè¢«è·³è¿‡")
        
        # ä¿å­˜é¡¹ç›®ç»“æœ
        if project_results:
            save_results_to_drive(project_results, drive_path)
            all_results.extend(project_results)
            print(f"ğŸ’¾ é¡¹ç›® {project_id} å®Œæˆï¼Œä¿å­˜äº† {len(project_results)} ä¸ªç»“æœ")
        
        print(f"ğŸ“Š é¡¹ç›® {project_id} ç»Ÿè®¡:")
        print(f"   æ€»å®éªŒ: {len(project_configs)}")
        print(f"   è·³è¿‡: {skipped_count}")
        print(f"   å®Œæˆ: {len(project_results)}")
        print(f"   å¤±è´¥: {len(project_configs) - skipped_count - len(project_results)}")
    
    # æœ€ç»ˆç»Ÿè®¡
    print("\n" + "=" * 60)
    print("ğŸ‰ æ‰€æœ‰å®éªŒå®Œæˆï¼")
    print(f"ğŸ“Š æ€»å®éªŒæ•°: {total_experiments}")
    print(f"âœ… å®Œæˆ: {completed_experiments}")
    print(f"âŒ å¤±è´¥: {failed_experiments}")
    print(f"â­ï¸ è·³è¿‡: {total_experiments - completed_experiments - failed_experiments}")
    
    if all_results:
        print(f"ğŸ’¾ æ€»å…±ä¿å­˜äº† {len(all_results)} ä¸ªç»“æœ")
        print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {os.path.join(drive_path, 'SolarPV_Results')}")

if __name__ == "__main__":
    main()