#!/usr/bin/env python3
"""
SolarPVé¡¹ç›® - æ‰¹é‡å®éªŒè„šæœ¬ (é€†åºç‰ˆæœ¬)
åœ¨Colabä¸Šè¿è¡Œ100ä¸ªé¡¹ç›®çš„å®Œæ•´å®éªŒï¼Œä¿å­˜ç»“æœåˆ°Google Drive
ä»æœ€å¤§é¡¹ç›®IDå¼€å§‹ï¼Œé€†åºè®­ç»ƒ
"""

import os
import sys
import time
import subprocess
import yaml
import pandas as pd
from pathlib import Path
import re

def check_drive_mount():
    """æ£€æŸ¥Google Driveæ˜¯å¦å·²æŒ‚è½½"""
    drive_path = "/content/drive/MyDrive"
    if os.path.exists(drive_path):
        print("âœ… Google Driveå·²æŒ‚è½½")
        return True
    else:
        print("âŒ Google DriveæœªæŒ‚è½½ï¼Œè¯·å…ˆæŒ‚è½½Drive")
        return False

def get_data_files():
    """æ‰«ædataç›®å½•ï¼Œè·å–æ‰€æœ‰é¡¹ç›®CSVæ–‡ä»¶"""
    data_dir = "data"
    if not os.path.exists(data_dir):
        print(f"âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
        return []
    
    csv_files = []
    for file in os.listdir(data_dir):
        if file.startswith("Project") and file.endswith(".csv"):
            project_id = file.replace("Project", "").replace(".csv", "")
            csv_files.append((project_id, os.path.join(data_dir, file)))
    
    csv_files.sort(key=lambda x: int(x[0]), reverse=True)  # é€†åºæ’åº
    return csv_files

def get_config_files():
    """è·å–æ‰€æœ‰é…ç½®æ–‡ä»¶"""
    config_dir = "config/projects"
    all_config_files = []
    
    if os.path.exists(config_dir):
        for project_dir in os.listdir(config_dir):
            project_path = os.path.join(config_dir, project_dir)
            if os.path.isdir(project_path):
                for config_file in os.listdir(project_path):
                    if config_file.endswith('.yaml') and config_file != 'config_index.yaml':
                        all_config_files.append(os.path.join(project_path, config_file))
    
    return all_config_files

def create_project_csv(project_id, drive_path):
    """ä¸ºé¡¹ç›®åˆ›å»ºCSVæ–‡ä»¶"""
    csv_file = os.path.join(drive_path, f"{project_id}_results.csv")
    
    if not os.path.exists(csv_file):
        # åˆ›å»ºCSVæ–‡ä»¶å¤´
        columns = [
            'model', 'use_pv', 'use_hist_weather', 'use_forecast', 'weather_category',
            'use_time_encoding', 'past_days', 'model_complexity', 'epochs', 'batch_size',
            'learning_rate', 'use_ideal_nwp', 'train_time_sec', 'inference_time_sec', 'param_count',
            'samples_count', 'best_epoch', 'final_lr', 'mse', 'rmse', 'mae', 'nrmse',
            'r_square', 'smape', 'gpu_memory_used'
        ]
        
        df = pd.DataFrame(columns=columns)
        df.to_csv(csv_file, index=False)
        print(f"ğŸ“„ åˆ›å»ºé¡¹ç›®CSVæ–‡ä»¶: {csv_file}")
        return True
    else:
        print(f"ğŸ“„ é¡¹ç›®CSVæ–‡ä»¶å·²å­˜åœ¨: {csv_file}")
        return True

def get_completed_experiments_count(project_id, drive_path):
    """è·å–å·²å®Œæˆçš„å®éªŒæ•°é‡"""
    csv_file = os.path.join(drive_path, f"{project_id}_results.csv")
    completed_count = 0
    
    if os.path.exists(csv_file):
        try:
            df = pd.read_csv(csv_file)
            completed_count = len(df)
            print(f"ğŸ“Š å‘ç° {completed_count} ä¸ªå·²å®Œæˆå®éªŒ")
        except Exception as e:
            print(f"âš ï¸ æ— æ³•è¯»å–ç°æœ‰ç»“æœæ–‡ä»¶: {e}")
            completed_count = 0
    
    return completed_count

def get_completed_experiment_configs(project_id, drive_path):
    """è·å–å·²å®Œæˆçš„å®éªŒé…ç½®åç§°åˆ—è¡¨"""
    csv_file = os.path.join(drive_path, f"{project_id}_results.csv")
    completed_configs = set()
    
    if os.path.exists(csv_file):
        try:
            df = pd.read_csv(csv_file)
            # ä»CSVä¸­æå–é…ç½®ä¿¡æ¯ï¼Œé‡å»ºé…ç½®åç§°
            for _, row in df.iterrows():
                # æ ¹æ®CSVä¸­çš„å‚æ•°é‡å»ºé…ç½®åç§°
                model = row['model']
                complexity = row['model_complexity']
                use_pv = row['use_pv']
                use_hist_weather = row['use_hist_weather']
                use_forecast = row['use_forecast']
                use_ideal_nwp = row.get('use_ideal_nwp', False)
                past_days = row['past_days']
                use_time_encoding = row['use_time_encoding']
                
                # ç¡®å®šè¾“å…¥ç±»åˆ«
                if use_pv and not use_hist_weather and not use_forecast:
                    input_cat = 'PV'
                elif use_pv and not use_hist_weather and use_forecast and not use_ideal_nwp:
                    input_cat = 'PV_plus_NWP'
                elif use_pv and not use_hist_weather and use_forecast and use_ideal_nwp:
                    input_cat = 'PV_plus_NWP_plus'
                elif use_pv and use_hist_weather and not use_forecast:
                    input_cat = 'PV_plus_HW'
                elif not use_pv and not use_hist_weather and use_forecast and not use_ideal_nwp:
                    input_cat = 'NWP'
                elif not use_pv and not use_hist_weather and use_forecast and use_ideal_nwp:
                    input_cat = 'NWP_plus'
                else:
                    continue  # è·³è¿‡æ— æ³•è¯†åˆ«çš„ç»„åˆ
                
                # ç¡®å®šå›çœ‹å°æ—¶æ•°
                lookback_hours = past_days * 24
                
                # ç¡®å®šæ—¶é—´ç¼–ç åç¼€
                te_suffix = 'TE' if use_time_encoding else 'noTE'
                
                # é‡å»ºé…ç½®åç§°
                config_name = f"{model}_{complexity}_{input_cat}_{lookback_hours}h_{te_suffix}"
                completed_configs.add(config_name)
                
        except Exception as e:
            print(f"âš ï¸ æ— æ³•è¯»å–ç°æœ‰ç»“æœæ–‡ä»¶: {e}")
    
    return completed_configs

def run_experiment(config_file, data_file, project_id):
    """è¿è¡Œå•ä¸ªå®éªŒ"""
    try:
        # åŠ è½½é…ç½®æ–‡ä»¶
        with open(config_file, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        # ä¿®æ”¹é…ç½®æ–‡ä»¶ä¸­çš„data_path
        config['data_path'] = data_file
        config['plant_id'] = project_id
        
        # åˆ›å»ºä¸´æ—¶é…ç½®æ–‡ä»¶
        temp_config = f"temp_config_{project_id}_{int(time.time())}.yaml"
        with open(temp_config, 'w', encoding='utf-8') as f:
            yaml.dump(config, f, default_flow_style=False, allow_unicode=True)
        
        # è¿è¡Œå®éªŒå¹¶è®°å½•æ—¶é—´
        cmd = ['python', 'main.py', '--config', temp_config]
        start_time = time.time()
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=1800)
        duration = time.time() - start_time
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if os.path.exists(temp_config):
            os.remove(temp_config)
        
        if result.returncode == 0:
            return True, result.stdout, result.stderr, duration, config
        else:
            return False, result.stdout, result.stderr, duration, config
            
    except Exception as e:
        return False, "", str(e), 0.0, {}

def parse_experiment_output(output, config_file, duration, config):
    """è§£æå®éªŒè¾“å‡ºï¼Œæå–ç»“æœ"""
    try:
        # æå–åŸºæœ¬æŒ‡æ ‡
        mse_match = re.search(r'mse=([0-9.]+)', output)
        rmse_match = re.search(r'rmse=([0-9.]+)', output)
        mae_match = re.search(r'mae=([0-9.]+)', output)
        r_square_match = re.search(r'r_square=([0-9.]+)', output)
        
        # åˆå§‹åŒ–é¢å¤–å­—æ®µ
        inference_time = 0.0
        param_count = 0
        samples_count = 0
        best_epoch = 0
        final_lr = 0.0
        nrmse = 0.0
        smape = 0.0
        gpu_memory_used = 0
        
        # è°ƒè¯•ï¼šæ˜¾ç¤ºæ‰€æœ‰è¾“å‡ºè¡Œ
        print("ğŸ” è°ƒè¯•ï¼šæ£€æŸ¥å®éªŒè¾“å‡ºä¸­çš„METRICSè¡Œ")
        for line in output.split('\n'):
            if "[METRICS]" in line:
                print(f"   æ‰¾åˆ°METRICSè¡Œ: {line}")
        
        # ä½¿ç”¨METRICSæ ‡ç­¾æå–é¢å¤–ä¿¡æ¯ï¼ˆä¸colab_batch_experiments.pyä¿æŒä¸€è‡´ï¼‰
        for line in output.split('\n'):
            if "[METRICS]" in line:
                # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–æ‰€æœ‰é”®å€¼å¯¹
                metrics_in_line = re.findall(r'(\w+)=([0-9.-]+)', line)
                for key, value_str in metrics_in_line:
                    try:
                        if key == 'inference_time':
                            inference_time = float(value_str)
                            print(f"ğŸ” è°ƒè¯•ï¼šæå–inference_time={inference_time}")
                        elif key == 'param_count':
                            param_count = int(float(value_str))
                            print(f"ğŸ” è°ƒè¯•ï¼šæå–param_count={param_count}")
                        elif key == 'samples_count':
                            samples_count = int(float(value_str))
                            print(f"ğŸ” è°ƒè¯•ï¼šæå–samples_count={samples_count}")
                        elif key == 'best_epoch':
                            if value_str.lower() == 'nan':
                                best_epoch = 0
                            else:
                                best_epoch = int(float(value_str))
                            print(f"ğŸ” è°ƒè¯•ï¼šæå–best_epoch={best_epoch}")
                        elif key == 'final_lr':
                            if value_str.lower() == 'nan':
                                final_lr = 0.0
                            else:
                                final_lr = float(value_str)
                            print(f"ğŸ” è°ƒè¯•ï¼šæå–final_lr={final_lr}")
                        elif key == 'nrmse':
                            nrmse = float(value_str)
                            print(f"ğŸ” è°ƒè¯•ï¼šæå–nrmse={nrmse}")
                        elif key == 'smape':
                            smape = float(value_str)
                            print(f"ğŸ” è°ƒè¯•ï¼šæå–smape={smape}")
                        elif key == 'gpu_memory_used':
                            gpu_memory_used = int(float(value_str))
                            print(f"ğŸ” è°ƒè¯•ï¼šæå–gpu_memory_used={gpu_memory_used}")
                    except Exception as e:
                        print(f"ğŸ” è°ƒè¯•ï¼š{key}æå–å¤±è´¥: {e}")
        
        # ä»é…ç½®æ–‡ä»¶åè§£æå‚æ•°
        config_filename = os.path.basename(config_file)
        parts = config_filename.replace('.yaml', '').split('_')
        
        model_name = parts[0]
        complexity = parts[1]
        
        # è§£æè¾“å…¥ç±»åˆ«å’Œæ—¶é—´ç¼–ç 
        if len(parts) > 2:
            # å¤„ç†åŒ…å«ä¸‹åˆ’çº¿çš„è¾“å…¥ç±»åˆ«åç§°
            if parts[2] == 'PV' and len(parts) > 3:
                if parts[3] == 'plus' and len(parts) > 4:
                    if parts[4] == 'NWP' and len(parts) > 5 and parts[5] == 'plus':
                        input_category = 'PV_plus_NWP_plus'
                        lookback_hours = parts[6].replace('h', '') if len(parts) > 6 else '24'
                        time_encoding = parts[7] == 'TE' if len(parts) > 7 else False
                    elif parts[4] == 'NWP':
                        input_category = 'PV_plus_NWP'
                        lookback_hours = parts[5].replace('h', '') if len(parts) > 5 else '24'
                        time_encoding = parts[6] == 'TE' if len(parts) > 6 else False
                    elif parts[4] == 'HW':
                        input_category = 'PV_plus_HW'
                        lookback_hours = parts[5].replace('h', '') if len(parts) > 5 else '24'
                        time_encoding = parts[6] == 'TE' if len(parts) > 6 else False
                    else:
                        input_category = 'PV'
                        lookback_hours = parts[3].replace('h', '') if len(parts) > 3 else '24'
                        time_encoding = parts[4] == 'TE' if len(parts) > 4 else False
                else:
                    input_category = 'PV'
                    lookback_hours = parts[3].replace('h', '') if len(parts) > 3 else '24'
                    time_encoding = parts[4] == 'TE' if len(parts) > 4 else False
            elif parts[2] == 'NWP' and len(parts) > 3 and parts[3] == 'plus':
                input_category = 'NWP_plus'
                lookback_hours = parts[4].replace('h', '') if len(parts) > 4 else '24'
                time_encoding = parts[5] == 'TE' if len(parts) > 5 else False
            elif parts[2] == 'NWP':
                input_category = 'NWP'
                lookback_hours = parts[3].replace('h', '') if len(parts) > 3 else '24'
                time_encoding = parts[4] == 'TE' if len(parts) > 4 else False
            else:
                input_category = parts[2]
                lookback_hours = parts[3].replace('h', '') if len(parts) > 3 else '24'
                time_encoding = parts[4] == 'TE' if len(parts) > 4 else False
        else:
            input_category = 'unknown'
            lookback_hours = '24'
            time_encoding = False
        
        # æ ¹æ®input_categoryç¡®å®šå…¶ä»–å‚æ•°
        use_pv = input_category in ['PV', 'PV_plus_NWP', 'PV_plus_NWP_plus', 'PV_plus_HW']
        use_hist_weather = input_category in ['PV_plus_HW']
        use_forecast = input_category in ['PV_plus_NWP', 'PV_plus_NWP_plus', 'PV_plus_HW', 'NWP', 'NWP_plus']
        
        # è®¡ç®—past_days
        past_days = int(int(lookback_hours) / 24) if lookback_hours.isdigit() else 1
        
        # åˆ¤æ–­æ¨¡å‹ç±»å‹
        is_dl_model = model_name in ['Transformer', 'LSTM', 'GRU', 'TCN']
        has_learning_rate = model_name in ['XGB', 'LGBM']
        
        # åˆ›å»ºç»“æœè¡Œ
        result_row = {
            'model': model_name,
            'use_pv': use_pv,
            'use_hist_weather': use_hist_weather,
            'use_forecast': use_forecast,
            'weather_category': 'all_weather',
            'use_time_encoding': time_encoding,
            'past_days': past_days,
            'model_complexity': complexity,
            'epochs': 50 if complexity == 'high' else 15 if is_dl_model else 0,
            'batch_size': 32 if is_dl_model else 0,
            'learning_rate': 0.001 if has_learning_rate else 0.0,
            'use_ideal_nwp': config.get('use_ideal_nwp', False),
            'train_time_sec': round(duration, 4),  # ä½¿ç”¨ä¼ å…¥çš„durationå‚æ•°
            'inference_time_sec': inference_time,
            'param_count': param_count,
            'samples_count': samples_count,
            'best_epoch': best_epoch if is_dl_model else 0,
            'final_lr': final_lr if is_dl_model else 0.0,
            'mse': float(mse_match.group(1)) if mse_match else 0.0,
            'rmse': float(rmse_match.group(1)) if rmse_match else 0.0,
            'mae': float(mae_match.group(1)) if mae_match else 0.0,
            'nrmse': nrmse,
            'r_square': float(r_square_match.group(1)) if r_square_match else 0.0,
            'smape': smape,
            'gpu_memory_used': gpu_memory_used
        }
        
        return result_row
        
    except Exception as e:
        print(f"âŒ è§£æå®éªŒè¾“å‡ºå¤±è´¥: {e}")
        return None

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸŒŸ SolarPVé¡¹ç›® - æ‰¹é‡å®éªŒè„šæœ¬ (é€†åºç‰ˆæœ¬)")
    print("=" * 50)
    
    # æ£€æŸ¥Google Drive
    if not check_drive_mount():
        return
    
    # è®¾ç½®è·¯å¾„
    drive_path = "/content/drive/MyDrive/Solar PV electricity/ablation results"
    os.makedirs(drive_path, exist_ok=True)
    
    # è·å–æ•°æ®æ–‡ä»¶
    print("ğŸ“ æ‰«ææ•°æ®æ–‡ä»¶...")
    data_files = get_data_files()
    print(f"ğŸ“Š æ‰¾åˆ° {len(data_files)} ä¸ªé¡¹ç›®: {[pid for pid, _ in data_files[:10]]}...")
    
    # è·å–é…ç½®æ–‡ä»¶
    print("ğŸ“ æ£€æŸ¥é…ç½®æ–‡ä»¶...")
    config_files = get_config_files()
    print(f"ğŸ“Š æ‰¾åˆ° {len(config_files)} ä¸ªé…ç½®æ–‡ä»¶")
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦ç”Ÿæˆé…ç½®æ–‡ä»¶
    if len(config_files) < len(data_files) * 100:
        print("ğŸ”§ é…ç½®æ–‡ä»¶ä¸è¶³ï¼Œæ­£åœ¨ç”Ÿæˆ...")
        try:
            result = subprocess.run([
                'python', 'scripts/generate_dynamic_project_configs.py'
            ], capture_output=True, text=True, timeout=300)
            if result.returncode == 0:
                print("âœ… é…ç½®æ–‡ä»¶ç”Ÿæˆå®Œæˆ")
                config_files = get_config_files()
                print(f"ğŸ“Š ç°åœ¨æœ‰ {len(config_files)} ä¸ªé…ç½®æ–‡ä»¶")
            else:
                print(f"âŒ é…ç½®æ–‡ä»¶ç”Ÿæˆå¤±è´¥: {result.stderr}")
                return
        except Exception as e:
            print(f"âŒ é…ç½®æ–‡ä»¶ç”Ÿæˆå¼‚å¸¸: {e}")
            return
    
    if not data_files or not config_files:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°æ•°æ®æ–‡ä»¶æˆ–é…ç½®æ–‡ä»¶")
        return
    
    print("ğŸš€ å¼€å§‹æ‰¹é‡å®éªŒ!")
    print(f"ğŸ“Š æ€»é¡¹ç›®æ•°: {len(data_files)}")
    print(f"ğŸ“Š æ¯é¡¹ç›®å®éªŒæ•°: {len(config_files) // len(data_files)}")
    print(f"ğŸ“Š æ€»å®éªŒæ•°: {len(data_files) * (len(config_files) // len(data_files))}")
    
    total_experiments = 0
    successful_experiments = 0
    failed_experiments = 0
    
    # éå†æ¯ä¸ªé¡¹ç›®
    for project_idx, (project_id, data_file) in enumerate(data_files, 1):
        print(f"\n{'='*80}")
        print(f"ğŸš€ å¼€å§‹é¡¹ç›® {project_id} çš„å®éªŒ (é€†åº: {project_idx}/{len(data_files)})")
        print(f"{'='*80}")
        
        # åˆ›å»ºé¡¹ç›®CSVæ–‡ä»¶
        if not create_project_csv(project_id, drive_path):
            print(f"âŒ æ— æ³•ä¸ºé¡¹ç›® {project_id} åˆ›å»ºCSVæ–‡ä»¶")
            continue
        
        # è·å–è¯¥é¡¹ç›®çš„é…ç½®æ–‡ä»¶
        project_configs = [cf for cf in config_files if f"/{project_id}/" in cf]
        
        # æ£€æŸ¥å·²å®Œæˆçš„å®éªŒ
        completed_count = get_completed_experiments_count(project_id, drive_path)
        completed_configs = get_completed_experiment_configs(project_id, drive_path)
        
        print(f"ğŸ“Š é¡¹ç›® {project_id}: å°†è¿è¡Œ {len(project_configs)} ä¸ªå®éªŒ")
        print(f"ğŸ“ ç»“æœä¿å­˜åˆ°: {drive_path}")
        print(f"ğŸ“Š å·²å®Œæˆå®éªŒ: {len(completed_configs)} ä¸ª")
        
        # è¿è¡Œå®éªŒ
        for exp_idx, config_file in enumerate(project_configs, 1):
            config_name = os.path.basename(config_file)
            # ç§»é™¤.yamlåç¼€è·å–é…ç½®åç§°
            config_name_without_ext = config_name.replace('.yaml', '')
            
            # è·³è¿‡å·²å®Œæˆçš„å®éªŒï¼ˆåŸºäºé…ç½®åç§°åˆ¤æ–­ï¼‰
            if config_name_without_ext in completed_configs:
                print(f"â­ï¸ è·³è¿‡å·²å®Œæˆå®éªŒ: {config_name}")
                continue
                
            print(f"\nğŸ”„ è¿›åº¦: {exp_idx}/{len(project_configs)} - {config_name}")
            
            # è¿è¡Œå®éªŒ
            success, stdout, stderr, duration, config = run_experiment(config_file, data_file, project_id)
            total_experiments += 1
            
            if success:
                print(f"âœ… å®éªŒæˆåŠŸ! ç”¨æ—¶: {duration:.1f}ç§’")
                successful_experiments += 1
                
                # è§£æç»“æœ
                result_row = parse_experiment_output(stdout, config_file, duration, config)
                if result_row:
                    # ä¿å­˜ç»“æœåˆ°CSV
                    csv_file = os.path.join(drive_path, f"{project_id}_results.csv")
                    
                    # è¯»å–ç°æœ‰CSV
                    if os.path.exists(csv_file):
                        df = pd.read_csv(csv_file)
                    else:
                        df = pd.DataFrame()
                    
                    # æ·»åŠ æ–°è¡Œ
                    new_row_df = pd.DataFrame([result_row])
                    df = pd.concat([df, new_row_df], ignore_index=True)
                    
                    # ä¿å­˜CSV
                    df.to_csv(csv_file, index=False)
                    print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {csv_file}")
                    print(f"ğŸ“Š CSVæ–‡ä»¶å½“å‰è¡Œæ•°: {len(df)}")
                    print(f"ğŸ“Š æœ€æ–°å®éªŒ: {result_row['model']} - {result_row['mse']:.4f}")
                    print(f"ğŸ” è§£æçš„é…ç½®ä¿¡æ¯:")
                    print(f"   æ¨¡å‹: {result_row['model']}, å¤æ‚åº¦: {result_row['model_complexity']}")
                    print(f"   æ—¶é—´ç¼–ç : {result_row['use_time_encoding']}")
                    print(f"   PV: {result_row['use_pv']}, å†å²å¤©æ°”: {result_row['use_hist_weather']}, é¢„æµ‹å¤©æ°”: {result_row['use_forecast']}")
                    print(f"ğŸ” æå–çš„é¢å¤–å­—æ®µ:")
                    print(f"   æ¨ç†æ—¶é—´: {result_row['inference_time_sec']}s, å‚æ•°æ•°é‡: {result_row['param_count']}, æ ·æœ¬æ•°é‡: {result_row['samples_count']}")
                    print(f"   æœ€ä½³è½®æ¬¡: {result_row['best_epoch']}, æœ€ç»ˆå­¦ä¹ ç‡: {result_row['final_lr']}")
                    print(f"   NRMSE: {result_row['nrmse']}, SMAPE: {result_row['smape']}, GPUå†…å­˜: {result_row['gpu_memory_used']}MB")
                else:
                    print("âš ï¸ æ— æ³•è§£æå®éªŒç»“æœ")
            else:
                print(f"âŒ å®éªŒå¤±è´¥!")
                print(f"   é”™è¯¯: {stderr}")
                failed_experiments += 1
        
        print(f"âœ… é¡¹ç›® {project_id} å®Œæˆ!")
    
    # æ€»ç»“
    print(f"\n{'='*80}")
    print("ğŸ‰ æ‰¹é‡å®éªŒå®Œæˆ!")
    print(f"ğŸ“Š æ€»å®éªŒæ•°: {total_experiments}")
    print(f"âœ… æˆåŠŸ: {successful_experiments}")
    print(f"âŒ å¤±è´¥: {failed_experiments}")
    print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {drive_path}")
    print(f"{'='*80}")

if __name__ == "__main__":
    main()
