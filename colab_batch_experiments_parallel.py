#!/usr/bin/env python3
"""
SolarPVé¡¹ç›® - å•GPUå¹¶è¡Œæ‰¹é‡å®éªŒè„šæœ¬
åœ¨å•å—GPUä¸Šå¹¶è¡Œè¿è¡Œ340ä¸ªå®éªŒï¼Œä¿å­˜ç»“æœåˆ°Google Drive
ä¿æŒä¸colab_batch_experiments.pyç›¸åŒçš„æ•ˆæœå’Œç»“æœæ ¼å¼ï¼Œä½†é€Ÿåº¦æ›´å¿«
"""

import os
import sys
import time
import subprocess
import yaml
import pandas as pd
import threading
import queue
from pathlib import Path
import re
from concurrent.futures import ThreadPoolExecutor
import torch
from utils.experiment_gpu_utils import get_single_experiment_gpu_memory

def check_drive_mount():
    """æ£€æŸ¥Google Driveæ˜¯å¦å·²æŒ‚è½½"""
    drive_path = "/content/drive/MyDrive"
    if os.path.exists(drive_path):
        print("âœ… Google Driveå·²æŒ‚è½½")
        return True
    else:
        print("âŒ Google DriveæœªæŒ‚è½½ï¼Œè¯·å…ˆæŒ‚è½½Drive")
        return False

def get_data_files():
    """æ‰«ædataç›®å½•ï¼Œè·å–æ‰€æœ‰é¡¹ç›®CSVæ–‡ä»¶"""
    data_dir = "data"
    if not os.path.exists(data_dir):
        print(f"âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
        return []
    
    csv_files = []
    for file in os.listdir(data_dir):
        if file.startswith("Project") and file.endswith(".csv"):
            project_id = file.replace("Project", "").replace(".csv", "")
            csv_files.append((project_id, os.path.join(data_dir, file)))
    
    csv_files.sort(key=lambda x: int(x[0]))  # æ­£åºæ’åº
    return csv_files

def get_config_files():
    """è·å–æ‰€æœ‰é…ç½®æ–‡ä»¶"""
    config_dir = "config/projects"
    all_config_files = []
    
    if os.path.exists(config_dir):
        for project_dir in sorted(os.listdir(config_dir)):
            project_path = os.path.join(config_dir, project_dir)
            if os.path.isdir(project_path):
                for config_file in sorted(os.listdir(project_path)):
                    if config_file.endswith('.yaml') and config_file != 'config_index.yaml':
                        all_config_files.append(os.path.join(project_path, config_file))
    
    return all_config_files

def create_project_csv(project_id, drive_path):
    """ä¸ºé¡¹ç›®åˆ›å»ºCSVæ–‡ä»¶"""
    csv_file = os.path.join(drive_path, f"{project_id}_results.csv")
    
    if not os.path.exists(csv_file):
        # åˆ›å»ºCSVæ–‡ä»¶å¤´
        columns = [
            'model', 'use_pv', 'use_hist_weather', 'use_forecast', 'weather_category',
            'use_time_encoding', 'past_days', 'model_complexity', 'epochs', 'batch_size',
            'learning_rate', 'use_ideal_nwp', 'input_category', 'train_time_sec', 'inference_time_sec', 'param_count',
            'samples_count', 'best_epoch', 'final_lr', 'mse', 'rmse', 'mae', 'nrmse',
            'r_square', 'smape', 'gpu_memory_used'
        ]
        
        df = pd.DataFrame(columns=columns)
        df.to_csv(csv_file, index=False)
        print(f"ğŸ“„ åˆ›å»ºé¡¹ç›®CSVæ–‡ä»¶: {csv_file}")
        return True
    else:
        print(f"ğŸ“„ é¡¹ç›®CSVæ–‡ä»¶å·²å­˜åœ¨: {csv_file}")
        return True

def get_completed_experiments_count(project_id, drive_path):
    """è·å–å·²å®Œæˆçš„å®éªŒæ•°é‡"""
    csv_file = os.path.join(drive_path, f"{project_id}_results.csv")
    completed_count = 0
    
    if os.path.exists(csv_file):
        try:
            df = pd.read_csv(csv_file)
            completed_count = len(df)
            print(f"ğŸ“Š å‘ç° {completed_count} ä¸ªå·²å®Œæˆå®éªŒ")
        except Exception as e:
            print(f"âš ï¸ æ— æ³•è¯»å–ç°æœ‰ç»“æœæ–‡ä»¶: {e}")
            completed_count = 0
    
    return completed_count

def get_completed_experiment_configs(project_id, drive_path):
    """è·å–å·²å®Œæˆçš„å®éªŒé…ç½®åç§°åˆ—è¡¨"""
    csv_file = os.path.join(drive_path, f"{project_id}_results.csv")
    completed_configs = set()
    
    if os.path.exists(csv_file):
        try:
            df = pd.read_csv(csv_file)
            # ä»CSVä¸­æå–é…ç½®ä¿¡æ¯ï¼Œé‡å»ºé…ç½®åç§°
            for _, row in df.iterrows():
                # è·å–æ‰€æœ‰å¿…è¦çš„å‚æ•°æ¥é‡å»ºå®Œæ•´çš„é…ç½®åç§°
                model = row['model']
                complexity = row['model_complexity']
                past_days = row['past_days']
                use_time_encoding = row['use_time_encoding']
                
                # ä¼˜å…ˆä½¿ç”¨input_categoryå­—æ®µï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                if 'input_category' in df.columns and pd.notna(row.get('input_category')):
                    input_cat = row['input_category']
                else:
                    # å…¼å®¹æ—§æ ¼å¼ï¼šæ ¹æ®CSVä¸­çš„å‚æ•°é‡å»ºé…ç½®åç§°
                    use_pv = row['use_pv']
                    use_hist_weather = row['use_hist_weather']
                    use_forecast = row['use_forecast']
                    use_ideal_nwp = row.get('use_ideal_nwp', False)
                    
                    # ç¡®å®šè¾“å…¥ç±»åˆ«
                    if use_pv and not use_hist_weather and not use_forecast:
                        input_cat = 'PV'
                    elif use_pv and not use_hist_weather and use_forecast and not use_ideal_nwp:
                        input_cat = 'PV_plus_NWP'
                    elif use_pv and not use_hist_weather and use_forecast and use_ideal_nwp:
                        input_cat = 'PV_plus_NWP_plus'
                    elif use_pv and use_hist_weather and not use_forecast:
                        input_cat = 'PV_plus_HW'
                    elif not use_pv and not use_hist_weather and use_forecast and not use_ideal_nwp:
                        input_cat = 'NWP'
                    elif not use_pv and not use_hist_weather and use_forecast and use_ideal_nwp:
                        input_cat = 'NWP_plus'
                    else:
                        continue  # è·³è¿‡æ— æ³•è¯†åˆ«çš„ç»„åˆ
                
                # ç¡®å®šå›çœ‹å°æ—¶æ•°
                lookback_hours = past_days * 24
                
                # ç¡®å®šæ—¶é—´ç¼–ç åç¼€
                te_suffix = 'TE' if use_time_encoding else 'noTE'
                
                # é‡å»ºå®Œæ•´çš„é…ç½®åç§°ï¼ˆåŒ…å«æ‰€æœ‰å…³é”®å­—æ®µï¼‰
                config_name = f"{model}_{complexity}_{input_cat}_{lookback_hours}h_{te_suffix}"
                completed_configs.add(config_name)
                
        except Exception as e:
            print(f"âš ï¸ æ— æ³•è¯»å–ç°æœ‰ç»“æœæ–‡ä»¶: {e}")
    
    return completed_configs

def run_experiment(config_file, data_file, project_id):
    """è¿è¡Œå•ä¸ªå®éªŒ"""
    try:
        # åŠ è½½é…ç½®æ–‡ä»¶
        with open(config_file, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        # ä¿®æ”¹é…ç½®æ–‡ä»¶ä¸­çš„data_path
        config['data_path'] = data_file
        config['plant_id'] = project_id
        
        # åˆ›å»ºä¸´æ—¶é…ç½®æ–‡ä»¶
        temp_config = f"temp_config_{project_id}_{int(time.time())}_{threading.current_thread().ident}.yaml"
        with open(temp_config, 'w', encoding='utf-8') as f:
            yaml.dump(config, f, default_flow_style=False, allow_unicode=True)
        
        # è¿è¡Œå®éªŒå¹¶è®°å½•æ—¶é—´
        cmd = ['python', 'main.py', '--config', temp_config]
        start_time = time.time()
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=1800)
        duration = time.time() - start_time
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if os.path.exists(temp_config):
            os.remove(temp_config)
        
        if result.returncode == 0:
            return True, result.stdout, result.stderr, duration, config
        else:
            return False, result.stdout, result.stderr, duration, config
            
    except Exception as e:
        return False, "", str(e), 0.0, {}

def parse_experiment_output(output, config_file, duration, config):
    """è§£æå®éªŒè¾“å‡ºï¼Œæå–ç»“æœï¼ˆä¸colab_batch_experiments.pyå®Œå…¨ä¸€è‡´ï¼‰"""
    try:
        # æå–åŸºæœ¬æŒ‡æ ‡ï¼ˆæ”¯æŒè´Ÿæ•°å’Œå°æ•°ï¼‰
        mse_match = re.search(r'mse=([+-]?[0-9]*\.?[0-9]+(?:[eE][+-]?[0-9]+)?)', output)
        rmse_match = re.search(r'rmse=([+-]?[0-9]*\.?[0-9]+(?:[eE][+-]?[0-9]+)?)', output)
        mae_match = re.search(r'mae=([+-]?[0-9]*\.?[0-9]+(?:[eE][+-]?[0-9]+)?)', output)
        r_square_match = re.search(r'r_square=([+-]?[0-9]*\.?[0-9]+(?:[eE][+-]?[0-9]+)?)', output)
        
        # åˆå§‹åŒ–é¢å¤–å­—æ®µ
        inference_time = 0.0
        param_count = 0
        samples_count = 0
        best_epoch = 0
        final_lr = 0.0
        nrmse = 0.0
        smape = 0.0
        gpu_memory_used = 0
        
        # ä½¿ç”¨METRICSæ ‡ç­¾æå–é¢å¤–ä¿¡æ¯ï¼ˆä¸colab_batch_experiments.pyä¿æŒä¸€è‡´ï¼‰
        for line in output.split('\n'):
            if "[METRICS]" in line:
                # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–æ‰€æœ‰é”®å€¼å¯¹
                metrics_in_line = re.findall(r'(\w+)=([0-9.-]+)', line)
                for key, value_str in metrics_in_line:
                    try:
                        if key == 'inference_time':
                            inference_time = float(value_str)
                        elif key == 'param_count':
                            param_count = int(float(value_str))
                        elif key == 'samples_count':
                            samples_count = int(float(value_str))
                        elif key == 'best_epoch':
                            if value_str.lower() == 'nan':
                                best_epoch = 0
                            else:
                                best_epoch = int(float(value_str))
                        elif key == 'final_lr':
                            if value_str.lower() == 'nan':
                                final_lr = 0.0
                            else:
                                final_lr = float(value_str)
                        elif key == 'nrmse':
                            nrmse = float(value_str)
                        elif key == 'smape':
                            smape = float(value_str)
                        elif key == 'gpu_memory_used':
                            gpu_memory_used = int(float(value_str))
                    except Exception as e:
                        pass
        
        # ä»é…ç½®æ–‡ä»¶åè§£æå‚æ•°
        config_filename = os.path.basename(config_file)
        parts = config_filename.replace('.yaml', '').split('_')
        
        model_name = parts[0]
        complexity = parts[1]
        
        # è§£æè¾“å…¥ç±»åˆ«å’Œæ—¶é—´ç¼–ç 
        if len(parts) > 2:
            # å¤„ç†åŒ…å«ä¸‹åˆ’çº¿çš„è¾“å…¥ç±»åˆ«åç§°
            if parts[2] == 'PV' and len(parts) > 3:
                if parts[3] == 'plus' and len(parts) > 4:
                    if parts[4] == 'NWP' and len(parts) > 5 and parts[5] == 'plus':
                        input_category = 'PV_plus_NWP_plus'
                        lookback_hours = parts[6].replace('h', '') if len(parts) > 6 else '24'
                        time_encoding = parts[7] == 'TE' if len(parts) > 7 else False
                    elif parts[4] == 'NWP':
                        input_category = 'PV_plus_NWP'
                        lookback_hours = parts[5].replace('h', '') if len(parts) > 5 else '24'
                        time_encoding = parts[6] == 'TE' if len(parts) > 6 else False
                    elif parts[4] == 'HW':
                        input_category = 'PV_plus_HW'
                        lookback_hours = parts[5].replace('h', '') if len(parts) > 5 else '24'
                        time_encoding = parts[6] == 'TE' if len(parts) > 6 else False
                    else:
                        input_category = 'PV'
                        lookback_hours = parts[3].replace('h', '') if len(parts) > 3 else '24'
                        time_encoding = parts[4] == 'TE' if len(parts) > 4 else False
                else:
                    input_category = 'PV'
                    lookback_hours = parts[3].replace('h', '') if len(parts) > 3 else '24'
                    time_encoding = parts[4] == 'TE' if len(parts) > 4 else False
            elif parts[2] == 'NWP' and len(parts) > 3 and parts[3] == 'plus':
                input_category = 'NWP_plus'
                lookback_hours = parts[4].replace('h', '') if len(parts) > 4 else '24'
                time_encoding = parts[5] == 'TE' if len(parts) > 5 else False
            elif parts[2] == 'NWP':
                input_category = 'NWP'
                lookback_hours = parts[3].replace('h', '') if len(parts) > 3 else '24'
                time_encoding = parts[4] == 'TE' if len(parts) > 4 else False
            else:
                input_category = parts[2]
                lookback_hours = parts[3].replace('h', '') if len(parts) > 3 else '24'
                time_encoding = parts[4] == 'TE' if len(parts) > 4 else False
        else:
            input_category = 'unknown'
            lookback_hours = '24'
            time_encoding = False
        
        # æ ¹æ®input_categoryç¡®å®šå…¶ä»–å‚æ•°
        use_pv = input_category in ['PV', 'PV_plus_NWP', 'PV_plus_NWP_plus', 'PV_plus_HW']
        use_hist_weather = input_category in ['PV_plus_HW']
        use_forecast = input_category in ['PV_plus_NWP', 'PV_plus_NWP_plus', 'NWP', 'NWP_plus']
        use_ideal_nwp = input_category in ['PV_plus_NWP_plus', 'NWP_plus']
        
        # æ ¹æ®input_categoryç¡®å®šweather_category
        if input_category == 'PV':
            weather_category = 'none'
        else:
            weather_category = 'all_weather'
        
        # è®¡ç®—past_days
        past_days = int(int(lookback_hours) / 24) if lookback_hours.isdigit() else 1
        
        # åˆ¤æ–­æ¨¡å‹ç±»å‹
        is_dl_model = model_name in ['Transformer', 'LSTM', 'GRU', 'TCN']
        has_learning_rate = model_name in ['XGB', 'LGBM']
        
        # åˆ›å»ºç»“æœè¡Œ
        result_row = {
            'model': model_name,
            'use_pv': use_pv,
            'use_hist_weather': use_hist_weather,
            'use_forecast': use_forecast,
            'weather_category': weather_category,
            'use_time_encoding': time_encoding,
            'past_days': past_days,
            'model_complexity': complexity,
            'epochs': config.get('epochs', 80 if complexity == 'high' else 50) if is_dl_model else 0,
            'batch_size': config.get('train_params', {}).get('batch_size', 64) if is_dl_model else 0,
            'learning_rate': config.get('train_params', {}).get('learning_rate', 0.001) if has_learning_rate else 0.0,
            'use_ideal_nwp': use_ideal_nwp,
            'input_category': input_category,  # æ·»åŠ input_categoryå­—æ®µ
            'train_time_sec': round(duration, 4),  # ä½¿ç”¨ä¼ å…¥çš„durationå‚æ•°
            'inference_time_sec': inference_time,
            'param_count': param_count,
            'samples_count': samples_count,
            'best_epoch': best_epoch if is_dl_model else 0,
            'final_lr': final_lr if is_dl_model else 0.0,
            'mse': float(mse_match.group(1)) if mse_match else 0.0,
            'rmse': float(rmse_match.group(1)) if rmse_match else 0.0,
            'mae': float(mae_match.group(1)) if mae_match else 0.0,
            'nrmse': nrmse,
            'r_square': float(r_square_match.group(1)) if r_square_match else 0.0,
            'smape': smape,
            'gpu_memory_used': gpu_memory_used  # è®°å½•è¯¥å®éªŒè‡ªå·±çš„GPUæ¶ˆè€—
        }
        
        return result_row
        
    except Exception as e:
        print(f"âŒ è§£æå®éªŒè¾“å‡ºå¤±è´¥: {e}")
        return None

class SingleGPUParallelExecutor:
    """å•GPUå¹¶è¡Œæ‰§è¡Œå™¨"""
    
    def __init__(self, max_workers=2):
        self.max_workers = max_workers
        self.executor = ThreadPoolExecutor(max_workers=max_workers)
        self.results_lock = threading.Lock()
        self.completed_count = 0
        self.failed_count = 0
    
    def execute_experiment(self, config_file, data_file, project_id, drive_path):
        """æ‰§è¡Œå•ä¸ªå®éªŒ"""
        config_name = os.path.basename(config_file)
        experiment_id = f"{project_id}_{config_name}_{int(time.time())}"
        
        try:
            print(f"ğŸ”„ å¼€å§‹å®éªŒ: {config_name}")
            
            # è¿è¡Œå®éªŒ
            success, stdout, stderr, duration, config = run_experiment(config_file, data_file, project_id)
            
            if success:
                # ä»å®éªŒè¾“å‡ºä¸­è§£æGPUå†…å­˜ä½¿ç”¨é‡
                actual_gpu_memory = 0
                if torch.cuda.is_available():
                    # å°è¯•ä»å®éªŒè¾“å‡ºä¸­æå–GPUå†…å­˜ä¿¡æ¯
                    gpu_memory_match = re.search(r'gpu_memory_used=([0-9.]+)', stdout)
                    if gpu_memory_match:
                        actual_gpu_memory = int(float(gpu_memory_match.group(1)))
                        print(f"ğŸ” ä»è¾“å‡ºä¸­æå–GPUå†…å­˜: {actual_gpu_memory}MB")
                    else:
                        # å¦‚æœæ— æ³•ä»è¾“å‡ºä¸­æå–ï¼Œä½¿ç”¨ä¸€ä¸ªåŸºäºæ¨¡å‹ç±»å‹çš„ä¼°ç®—å€¼
                        model_name = os.path.basename(config_file).split('_')[0]
                        complexity = os.path.basename(config_file).split('_')[1]
                        
                        # åŸºäºæ¨¡å‹ç±»å‹å’Œå¤æ‚åº¦ä¼°ç®—GPUå†…å­˜ä½¿ç”¨
                        if model_name in ['Transformer']:
                            if complexity == 'high':
                                actual_gpu_memory = 2000  # 2GB
                            elif complexity == 'medium':
                                actual_gpu_memory = 1500  # 1.5GB
                            else:
                                actual_gpu_memory = 1000  # 1GB
                        elif model_name in ['LSTM', 'GRU']:
                            if complexity == 'high':
                                actual_gpu_memory = 800   # 800MB
                            elif complexity == 'medium':
                                actual_gpu_memory = 600   # 600MB
                            else:
                                actual_gpu_memory = 400   # 400MB
                        elif model_name in ['TCN']:
                            if complexity == 'high':
                                actual_gpu_memory = 1200  # 1.2GB
                            elif complexity == 'medium':
                                actual_gpu_memory = 900   # 900MB
                            else:
                                actual_gpu_memory = 600   # 600MB
                        else:  # XGB, LGBMç­‰
                            actual_gpu_memory = 200  # 200MB
                        
                        print(f"ğŸ” ä½¿ç”¨ä¼°ç®—GPUå†…å­˜: {actual_gpu_memory}MB (æ¨¡å‹: {model_name}, å¤æ‚åº¦: {complexity})")
                
                # è§£æç»“æœ
                result_row = parse_experiment_output(stdout, config_file, duration, config)
                if result_row:
                    # ä½¿ç”¨å‡†ç¡®çš„GPUå†…å­˜æµ‹é‡å€¼æ›¿æ¢è§£æå‡ºçš„å€¼
                    result_row['gpu_memory_used'] = int(actual_gpu_memory)
                    
                    # ä¿å­˜ç»“æœåˆ°CSV
                    csv_file = os.path.join(drive_path, f"{project_id}_results.csv")
                    
                    with self.results_lock:
                        # è¯»å–ç°æœ‰CSV
                        if os.path.exists(csv_file):
                            df = pd.read_csv(csv_file)
                        else:
                            df = pd.DataFrame()
                        
                        # æ·»åŠ æ–°è¡Œ
                        new_row_df = pd.DataFrame([result_row])
                        df = pd.concat([df, new_row_df], ignore_index=True)
                        
                    # ä¿å­˜CSV
                    df.to_csv(csv_file, index=False)
                    self.completed_count += 1
                    
                    print(f"âœ… å®Œæˆ: {config_name} ({duration:.1f}s) - MSE: {result_row['mse']:.4f}")
                    print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {csv_file}")
                    print(f"ğŸ“Š GPUå†…å­˜ä½¿ç”¨: {result_row['gpu_memory_used']}MB")
                    if torch.cuda.is_available():
                        current_memory = torch.cuda.memory_allocated() / 1024 / 1024
                        print(f"ğŸ” è°ƒè¯•ä¿¡æ¯: å½“å‰GPUå†…å­˜={current_memory:.1f}MB")
                else:
                    with self.results_lock:
                        self.failed_count += 1
                    print(f"âš ï¸ æ— æ³•è§£æå®éªŒç»“æœ: {config_name}")
            else:
                with self.results_lock:
                    self.failed_count += 1
                print(f"âŒ å®éªŒå¤±è´¥: {config_name}")
                print(f"   é”™è¯¯: {stderr}")
                
        except Exception as e:
            with self.results_lock:
                self.failed_count += 1
            print(f"ğŸ’¥ å®éªŒå¼‚å¸¸: {config_name} - {e}")
    
    def run_parallel_experiments(self, experiments, drive_path):
        """å¹¶è¡Œè¿è¡Œå®éªŒ"""
        print(f"ğŸš€ å¯åŠ¨å¹¶è¡Œæ‰§è¡Œå™¨ (æœ€å¤§å¹¶è¡Œæ•°: {self.max_workers})")
        
        # æäº¤æ‰€æœ‰å®éªŒåˆ°çº¿ç¨‹æ± 
        futures = []
        for config_file, data_file, project_id in experiments:
            future = self.executor.submit(
                self.execute_experiment, 
                config_file, data_file, project_id, drive_path
            )
            futures.append(future)
        
        # ç­‰å¾…æ‰€æœ‰å®éªŒå®Œæˆ
        for future in futures:
            try:
                future.result()
            except Exception as e:
                print(f"ğŸ’¥ çº¿ç¨‹æ‰§è¡Œå¼‚å¸¸: {e}")
        
        self.executor.shutdown(wait=True)
        
        print(f"âœ… å¹¶è¡Œæ‰§è¡Œå®Œæˆ! æˆåŠŸ: {self.completed_count}, å¤±è´¥: {self.failed_count}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸŒŸ SolarPVé¡¹ç›® - å•GPUå¹¶è¡Œæ‰¹é‡å®éªŒè„šæœ¬")
    print("=" * 60)
    
    # æ£€æŸ¥Google Drive
    if not check_drive_mount():
        return
    
    # è®¾ç½®è·¯å¾„
    drive_path = "/content/drive/MyDrive/Solar PV electricity/ablation results"
    os.makedirs(drive_path, exist_ok=True)
    
    # è·å–æ•°æ®æ–‡ä»¶
    print("ğŸ“ æ‰«ææ•°æ®æ–‡ä»¶...")
    data_files = get_data_files()
    print(f"ğŸ“Š æ‰¾åˆ° {len(data_files)} ä¸ªé¡¹ç›®: {[pid for pid, _ in data_files[:10]]}...")
    
    # è·å–é…ç½®æ–‡ä»¶
    print("ğŸ“ æ£€æŸ¥é…ç½®æ–‡ä»¶...")
    config_files = get_config_files()
    print(f"ğŸ“Š æ‰¾åˆ° {len(config_files)} ä¸ªé…ç½®æ–‡ä»¶")
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦ç”Ÿæˆé…ç½®æ–‡ä»¶
    if len(config_files) < len(data_files) * 100:
        print("ğŸ”§ é…ç½®æ–‡ä»¶ä¸è¶³ï¼Œæ­£åœ¨ç”Ÿæˆ...")
        try:
            result = subprocess.run([
                'python', 'scripts/generate_dynamic_project_configs.py'
            ], capture_output=True, text=True, timeout=300)
            if result.returncode == 0:
                print("âœ… é…ç½®æ–‡ä»¶ç”Ÿæˆå®Œæˆ")
                config_files = get_config_files()
                print(f"ğŸ“Š ç°åœ¨æœ‰ {len(config_files)} ä¸ªé…ç½®æ–‡ä»¶")
            else:
                print(f"âŒ é…ç½®æ–‡ä»¶ç”Ÿæˆå¤±è´¥: {result.stderr}")
                return
        except Exception as e:
            print(f"âŒ é…ç½®æ–‡ä»¶ç”Ÿæˆå¼‚å¸¸: {e}")
            return
    
    if not data_files or not config_files:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°æ•°æ®æ–‡ä»¶æˆ–é…ç½®æ–‡ä»¶")
        return
    
    # æ£€æŸ¥GPU
    if not torch.cuda.is_available():
        print("âŒ æœªæ£€æµ‹åˆ°CUDA GPU")
        return
    
    gpu_name = torch.cuda.get_device_name(0)
    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024 / 1024 / 1024
    print(f"ğŸ¯ GPU: {gpu_name} ({gpu_memory:.1f}GB)")
    
    # æ ¹æ®GPUå†…å­˜è®¾ç½®å¹¶è¡Œæ•°é‡
    if gpu_memory >= 40:  # 40GB+ (A100ç­‰)
        max_parallel = 6
    elif gpu_memory >= 24:  # 24GB+ (RTX 4090, RTX 3090ç­‰)
        max_parallel = 5
    elif gpu_memory >= 14:  # 16GB+ (RTX 4080, T4ç­‰)
        max_parallel = 4
    elif gpu_memory >= 12:  # 12GB+ (RTX 4070ç­‰)
        max_parallel = 3
    else:  # 8GB+ (RTX 3070ç­‰)
        max_parallel = 2
    
    print(f"ğŸ“Š è®¾ç½®å¹¶è¡Œæ•°: {max_parallel}")
    
    print("ğŸš€ å¼€å§‹æ‰¹é‡å®éªŒ!")
    print(f"ğŸ“Š æ€»é¡¹ç›®æ•°: {len(data_files)}")
    print(f"ğŸ“Š æ¯é¡¹ç›®å®éªŒæ•°: {len(config_files) // len(data_files)}")
    print(f"ğŸ“Š æ€»å®éªŒæ•°: {len(data_files) * (len(config_files) // len(data_files))}")
    
    total_experiments = 0
    successful_experiments = 0
    failed_experiments = 0
    
    # éå†æ¯ä¸ªé¡¹ç›®
    for project_idx, (project_id, data_file) in enumerate(data_files, 1):
        print(f"\n{'='*80}")
        print(f"ğŸš€ å¼€å§‹é¡¹ç›® {project_id} çš„å®éªŒ (æ­£åº: {project_idx}/{len(data_files)})")
        print(f"{'='*80}")
        
        # åˆ›å»ºé¡¹ç›®CSVæ–‡ä»¶
        if not create_project_csv(project_id, drive_path):
            print(f"âŒ æ— æ³•ä¸ºé¡¹ç›® {project_id} åˆ›å»ºCSVæ–‡ä»¶")
            continue
        
        # è·å–è¯¥é¡¹ç›®çš„é…ç½®æ–‡ä»¶
        project_configs = sorted([cf for cf in config_files if f"/{project_id}/" in cf])
        
        # æ£€æŸ¥å·²å®Œæˆçš„å®éªŒ
        completed_count = get_completed_experiments_count(project_id, drive_path)
        completed_configs = get_completed_experiment_configs(project_id, drive_path)
        
        print(f"ğŸ“Š é¡¹ç›® {project_id}: å°†è¿è¡Œ {len(project_configs)} ä¸ªå®éªŒ")
        print(f"ğŸ“ ç»“æœä¿å­˜åˆ°: {drive_path}")
        print(f"ğŸ“Š å·²å®Œæˆå®éªŒ: {len(completed_configs)} ä¸ª")
        
        # æ˜¾ç¤ºä¸€äº›å·²å®Œæˆçš„å®éªŒç¤ºä¾‹ï¼ˆç”¨äºè°ƒè¯•ï¼‰
        if completed_configs:
            sample_completed = list(completed_configs)[:5]  # æ˜¾ç¤ºå‰5ä¸ª
            print(f"ğŸ” å·²å®Œæˆå®éªŒç¤ºä¾‹: {sample_completed}")
        
        # å‡†å¤‡å®éªŒåˆ—è¡¨ï¼ˆè·³è¿‡å·²å®Œæˆçš„ï¼‰
        experiments_to_run = []
        skipped_count = 0
        for config_file in project_configs:
            config_name = os.path.basename(config_file)
            config_name_without_ext = config_name.replace('.yaml', '')
            
            # è·³è¿‡å·²å®Œæˆçš„å®éªŒ
            if config_name_without_ext in completed_configs:
                skipped_count += 1
                if skipped_count <= 5:  # åªæ˜¾ç¤ºå‰5ä¸ªè·³è¿‡çš„å®éªŒ
                    print(f"â­ï¸ è·³è¿‡å·²å®Œæˆå®éªŒ: {config_name}")
                continue
            
            experiments_to_run.append((config_file, data_file, project_id))
        
        if skipped_count > 5:
            print(f"â­ï¸ ... è¿˜æœ‰ {skipped_count - 5} ä¸ªå·²å®Œæˆçš„å®éªŒè¢«è·³è¿‡")
        
        if not experiments_to_run:
            print(f"âœ… é¡¹ç›® {project_id} æ‰€æœ‰å®éªŒå·²å®Œæˆ!")
            continue
        
        print(f"ğŸš€ å¼€å§‹å¹¶è¡Œè¿è¡Œ {len(experiments_to_run)} ä¸ªå®éªŒ...")
        
        # åˆ›å»ºå¹¶è¡Œæ‰§è¡Œå™¨
        executor = SingleGPUParallelExecutor(max_workers=max_parallel)
        
        # è¿è¡Œå¹¶è¡Œå®éªŒ
        start_time = time.time()
        executor.run_parallel_experiments(experiments_to_run, drive_path)
        duration = time.time() - start_time
        
        total_experiments += len(experiments_to_run)
        successful_experiments += executor.completed_count
        failed_experiments += executor.failed_count
        
        print(f"âœ… é¡¹ç›® {project_id} å®Œæˆ! ç”¨æ—¶: {duration/60:.1f}åˆ†é’Ÿ")
        print(f"ğŸ“Š æˆåŠŸ: {executor.completed_count}, å¤±è´¥: {executor.failed_count}")
    
    # æ€»ç»“
    print(f"\n{'='*80}")
    print("ğŸ‰ å•GPUå¹¶è¡Œæ‰¹é‡å®éªŒå®Œæˆ!")
    print(f"ğŸ“Š æ€»å®éªŒæ•°: {total_experiments}")
    print(f"âœ… æˆåŠŸ: {successful_experiments}")
    print(f"âŒ å¤±è´¥: {failed_experiments}")
    print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {drive_path}")
    print(f"ğŸš€ å¹¶è¡ŒåŠ é€Ÿæ¯”: {max_parallel}x")
    print(f"{'='*80}")

if __name__ == "__main__":
    main()
