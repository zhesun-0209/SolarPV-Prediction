#!/usr/bin/env python3
"""
çœŸå®æ•°æ®å…¨é¢æµ‹è¯•è„šæœ¬ - æµ‹è¯•æ‰€æœ‰MLå’ŒDLæ¨¡å‹
ä½¿ç”¨Project1140.csvæ•°æ®ï¼Œè¯¦ç»†è¾“å‡ºæ‰€æœ‰æµ‹è¯•è¿‡ç¨‹
"""

import os
import sys
import pandas as pd
import numpy as np
import traceback
from pathlib import Path
import warnings
import time
warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

print("ğŸš€ å¼€å§‹çœŸå®æ•°æ®å…¨é¢æµ‹è¯•...")
print(f"ğŸ“ é¡¹ç›®æ ¹ç›®å½•: {project_root}")
print(f"â° å¼€å§‹æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}")

# 1. æµ‹è¯•é…ç½®ç”Ÿæˆ
print("\n" + "="*80)
print("1ï¸âƒ£ æµ‹è¯•é…ç½®ç”Ÿæˆ")
print("="*80)

try:
    from scripts.generate_dynamic_project_configs import generate_project_configs
    
    project_configs = generate_project_configs("1140")
    print(f"âœ… é…ç½®ç”ŸæˆæˆåŠŸ")
    print(f"ğŸ“Š ç”Ÿæˆé…ç½®æ•°é‡: {len(project_configs)}")
    
    # æ˜¾ç¤ºé…ç½®ç±»å‹ç»Ÿè®¡
    model_stats = {}
    input_stats = {}
    for config_info in project_configs:
        model = config_info['config'].get('model', 'Unknown')
        input_cat = config_info['name'].split('_')[2]  # ä»é…ç½®åæå–è¾“å…¥ç±»åˆ«
        model_stats[model] = model_stats.get(model, 0) + 1
        input_stats[input_cat] = input_stats.get(input_cat, 0) + 1
    
    print(f"ğŸ“Š æ¨¡å‹ç±»å‹ç»Ÿè®¡:")
    for model, count in model_stats.items():
        print(f"   - {model}: {count}ä¸ªé…ç½®")
    
    print(f"ğŸ“Š è¾“å…¥ç±»åˆ«ç»Ÿè®¡:")
    for input_cat, count in input_stats.items():
        print(f"   - {input_cat}: {count}ä¸ªé…ç½®")
    
    # æ˜¾ç¤ºå‰10ä¸ªé…ç½®åç§°
    print(f"ğŸ“Š å‰10ä¸ªé…ç½®åç§°:")
    for i, config_info in enumerate(project_configs[:10]):
        print(f"   {i+1}. {config_info.get('name', 'N/A')}")
        
except Exception as e:
    print(f"âŒ é…ç½®ç”Ÿæˆå¤±è´¥: {e}")
    traceback.print_exc()
    sys.exit(1)

# 2. æµ‹è¯•æ•°æ®åŠ è½½å’Œé¢„å¤„ç†
print("\n" + "="*80)
print("2ï¸âƒ£ æµ‹è¯•æ•°æ®åŠ è½½å’Œé¢„å¤„ç†")
print("="*80)

try:
    from data.data_utils import load_raw_data, preprocess_features
    
    # åŠ è½½æ•°æ®
    data_file = project_root / "data" / "Project1140.csv"
    df = load_raw_data(str(data_file))
    print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ")
    print(f"ğŸ“Š åŸå§‹æ•°æ®å½¢çŠ¶: {df.shape}")
    print(f"ğŸ“Š æ•°æ®æ—¶é—´èŒƒå›´: {df['Datetime'].min()} åˆ° {df['Datetime'].max()}")
    print(f"ğŸ“Š æ•°æ®åˆ—æ•°: {len(df.columns)}")
    print(f"ğŸ“Š ç›®æ ‡å˜é‡èŒƒå›´: {df['Capacity Factor'].min():.2f} - {df['Capacity Factor'].max():.2f}")
    
    # æµ‹è¯•ä¸åŒçš„é…ç½®ï¼ˆæ³¨æ„ï¼šLSRä¸ä½¿ç”¨PVé…ç½®ï¼‰
    test_configs = [
        ('PV_noTE', 'RF_low_PV_24h_noTE'),  # ä½¿ç”¨RFæµ‹è¯•PVé…ç½®
        ('NWP_noTE', 'LSR_low_NWP_24h_noTE'),
        ('HW_noTE', 'LSR_low_PV_plus_HW_24h_noTE'),
        ('NWP_TE', 'LSR_low_NWP_24h_TE')
    ]
    
    preprocessing_results = {}
    
    for config_name, config_pattern in test_configs:
        print(f"\nğŸ”§ æµ‹è¯•é…ç½®: {config_name}")
        
        # æ‰¾åˆ°å¯¹åº”çš„é…ç½®
        test_config = None
        for cfg_info in project_configs:
            if config_pattern in cfg_info.get('name', ''):
                test_config = cfg_info.get('config', {})
                break
        
        if test_config:
            print(f"ğŸ“Š ä½¿ç”¨é…ç½®: {config_pattern}")
            print(f"ğŸ“Š é…ç½®è¯¦æƒ…:")
            print(f"   - æ¨¡å‹: {test_config.get('model', 'N/A')}")
            print(f"   - å¤æ‚åº¦: {test_config.get('model_complexity', 'N/A')}")
            print(f"   - ä½¿ç”¨PV: {test_config.get('use_pv', 'N/A')}")
            print(f"   - ä½¿ç”¨å†å²å¤©æ°”: {test_config.get('use_hist_weather', 'N/A')}")
            print(f"   - ä½¿ç”¨é¢„æµ‹å¤©æ°”: {test_config.get('use_forecast', 'N/A')}")
            print(f"   - æ—¶é—´ç¼–ç : {test_config.get('use_time_encoding', 'N/A')}")
            print(f"   - å¤©æ°”ç±»åˆ«: {test_config.get('weather_category', 'N/A')}")
            print(f"   - å›çœ‹å°æ—¶: {test_config.get('past_hours', 'N/A')}")
            
            df_clean, hist_feats, fcst_feats, scaler_hist, scaler_fcst, scaler_target = preprocess_features(df, test_config)
            
            print(f"âœ… {config_name} æ•°æ®é¢„å¤„ç†æˆåŠŸ")
            print(f"ğŸ“Š æ¸…ç†åæ•°æ®å½¢çŠ¶: {df_clean.shape}")
            print(f"ğŸ“Š å†å²ç‰¹å¾: {hist_feats}")
            print(f"ğŸ“Š é¢„æµ‹ç‰¹å¾: {fcst_feats}")
            print(f"ğŸ“Š å†å²ç‰¹å¾æ•°é‡: {len(hist_feats)}")
            print(f"ğŸ“Š é¢„æµ‹ç‰¹å¾æ•°é‡: {len(fcst_feats)}")
            
            preprocessing_results[config_name] = {
                'config': test_config,
                'df_clean': df_clean,
                'hist_feats': hist_feats,
                'fcst_feats': fcst_feats,
                'scaler_hist': scaler_hist,
                'scaler_fcst': scaler_fcst,
                'scaler_target': scaler_target
            }
        else:
            print(f"âŒ æ‰¾ä¸åˆ°é…ç½®: {config_pattern}")
            
except Exception as e:
    print(f"âŒ æ•°æ®é¢„å¤„ç†å¤±è´¥: {e}")
    traceback.print_exc()

# 3. æµ‹è¯•æ»‘åŠ¨çª—å£å’Œæ•°æ®åˆ†å‰²
print("\n" + "="*80)
print("3ï¸âƒ£ æµ‹è¯•æ»‘åŠ¨çª—å£å’Œæ•°æ®åˆ†å‰²")
print("="*80)

try:
    from data.data_utils import create_sliding_windows, split_data
    
    # ä½¿ç”¨ç¬¬ä¸€ä¸ªæˆåŠŸçš„é¢„å¤„ç†ç»“æœ
    if preprocessing_results:
        config_name = list(preprocessing_results.keys())[0]
        result = preprocessing_results[config_name]
        
        print(f"ğŸ“Š ä½¿ç”¨é…ç½®: {config_name}")
        df_clean = result['df_clean']
        hist_feats = result['hist_feats']
        fcst_feats = result['fcst_feats']
        config = result['config']
        
        past_hours = config.get('past_hours', 24)
        future_hours = config.get('future_hours', 24)
        
        print(f"ğŸ“Š æ»‘åŠ¨çª—å£å‚æ•°:")
        print(f"   - è¿‡å»å°æ—¶: {past_hours}")
        print(f"   - æœªæ¥å°æ—¶: {future_hours}")
        print(f"   - å†å²ç‰¹å¾: {hist_feats}")
        print(f"   - é¢„æµ‹ç‰¹å¾: {fcst_feats}")
        
        # ç¡®ä¿æœ‰ç‰¹å¾æ‰åˆ›å»ºæ»‘åŠ¨çª—å£
        if not hist_feats and not fcst_feats:
            print("âŒ é”™è¯¯ï¼šæ²¡æœ‰å¯ç”¨çš„ç‰¹å¾ï¼Œæ— æ³•åˆ›å»ºæ»‘åŠ¨çª—å£")
            sys.exit(1)
        
        X_hist, X_fcst, y, hours, dates = create_sliding_windows(
            df_clean, past_hours, future_hours, hist_feats, fcst_feats
        )
        
        print(f"âœ… æ»‘åŠ¨çª—å£åˆ›å»ºæˆåŠŸ")
        print(f"ğŸ“Š X_histå½¢çŠ¶: {X_hist.shape}")
        print(f"ğŸ“Š X_fcstå½¢çŠ¶: {X_fcst.shape if X_fcst is not None else 'None'}")
        print(f"ğŸ“Š yå½¢çŠ¶: {y.shape}")
        print(f"ğŸ“Š hourså½¢çŠ¶: {hours.shape}")
        print(f"ğŸ“Š datesæ•°é‡: {len(dates)}")
        
        # æ£€æŸ¥æ•°æ®è´¨é‡
        print(f"ğŸ“Š æ•°æ®è´¨é‡æ£€æŸ¥:")
        print(f"   - X_hist NaNæ•°é‡: {np.isnan(X_hist).sum()}")
        print(f"   - X_hist Infæ•°é‡: {np.isinf(X_hist).sum()}")
        print(f"   - y NaNæ•°é‡: {np.isnan(y).sum()}")
        print(f"   - y Infæ•°é‡: {np.isinf(y).sum()}")
        print(f"   - yèŒƒå›´: {np.min(y):.4f} - {np.max(y):.4f}")
        
        # æ•°æ®åˆ†å‰²
        result_split = split_data(X_hist, X_fcst, y, hours, dates)
        (Xh_tr, Xf_tr, y_tr, hrs_tr, dates_tr,
         Xh_va, Xf_va, y_va, hrs_va, dates_va,
         Xh_te, Xf_te, y_te, hrs_te, dates_te) = result_split
        
        print(f"âœ… æ•°æ®åˆ†å‰²æˆåŠŸ")
        print(f"ğŸ“Š è®­ç»ƒé›†: {len(Xh_tr)}æ ·æœ¬")
        print(f"ğŸ“Š éªŒè¯é›†: {len(Xh_va)}æ ·æœ¬")
        print(f"ğŸ“Š æµ‹è¯•é›†: {len(Xh_te)}æ ·æœ¬")
        print(f"ğŸ“Š è®­ç»ƒé›†Xå½¢çŠ¶: {Xh_tr.shape}")
        print(f"ğŸ“Š è®­ç»ƒé›†yå½¢çŠ¶: {y_tr.shape}")
        
    else:
        print("âŒ æ²¡æœ‰å¯ç”¨çš„é¢„å¤„ç†ç»“æœ")
        
except Exception as e:
    print(f"âŒ æ»‘åŠ¨çª—å£/æ•°æ®åˆ†å‰²å¤±è´¥: {e}")
    traceback.print_exc()

# 4. æµ‹è¯•MLæ¨¡å‹
print("\n" + "="*80)
print("4ï¸âƒ£ æµ‹è¯•MLæ¨¡å‹")
print("="*80)

ml_models = ['Linear', 'RF', 'XGB', 'LGBM']
ml_results = {}

for model_name in ml_models:
    print(f"\nğŸ”§ æµ‹è¯• {model_name} æ¨¡å‹:")
    try:
        # æ‰¾åˆ°å¯¹åº”çš„é…ç½®
        model_config = None
        for cfg_info in project_configs:
            cfg = cfg_info.get('config', {})
            # æ‰€æœ‰æ¨¡å‹éƒ½ä½¿ç”¨'low'å¤æ‚åº¦
            if cfg.get('model') == model_name and cfg.get('model_complexity') == 'low':
                model_config = cfg
                break
        
        if not model_config:
            print(f"âŒ æ‰¾ä¸åˆ° {model_name} æ¨¡å‹é…ç½®")
            continue
            
        print(f"ğŸ“Š ä½¿ç”¨é…ç½®: {model_config.get('model_complexity', 'N/A')}")
        print(f"ğŸ“Š è¾“å…¥ç‰¹å¾: use_pv={model_config.get('use_pv')}, use_hist_weather={model_config.get('use_hist_weather')}, use_forecast={model_config.get('use_forecast')}")
        
        # ä½¿ç”¨å½“å‰é…ç½®é‡æ–°é¢„å¤„ç†æ•°æ®
        df_clean_model, hist_feats_model, fcst_feats_model, _, _, _ = preprocess_features(df, model_config)
        
        # é‡æ–°åˆ›å»ºæ»‘åŠ¨çª—å£
        past_hours = model_config.get('past_hours', 24)
        future_hours = model_config.get('future_hours', 24)
        
        X_hist_model, X_fcst_model, y_model, hours_model, dates_model = create_sliding_windows(
            df_clean_model, past_hours, future_hours, hist_feats_model, fcst_feats_model
        )
        
        # é‡æ–°åˆ†å‰²æ•°æ®
        (Xh_tr_model, Xf_tr_model, y_tr_model, hrs_tr_model, dates_tr_model,
         Xh_va_model, Xf_va_model, y_va_model, hrs_va_model, dates_va_model,
         Xh_te_model, Xf_te_model, y_te_model, hrs_te_model, dates_te_model) = split_data(
            X_hist_model, X_fcst_model, y_model, hours_model, dates_model)
        
        # å‡†å¤‡2Dæ•°æ®
        X_train_2d = Xh_tr_model.reshape(Xh_tr_model.shape[0], -1)
        X_test_2d = Xh_te_model.reshape(Xh_te_model.shape[0], -1)
        
        # å¦‚æœæœ‰é¢„æµ‹ç‰¹å¾ï¼Œåˆå¹¶
        if Xf_tr_model is not None and Xf_tr_model.shape[2] > 0:
            X_train_2d = np.hstack([X_train_2d, Xf_tr_model.reshape(Xf_tr_model.shape[0], -1)])
            X_test_2d = np.hstack([X_test_2d, Xf_te_model.reshape(Xf_te_model.shape[0], -1)])
        
        print(f"ğŸ“Š è®­ç»ƒæ•°æ®å½¢çŠ¶: {X_train_2d.shape}")
        print(f"ğŸ“Š æµ‹è¯•æ•°æ®å½¢çŠ¶: {X_test_2d.shape}")
        print(f"ğŸ“Š ç›®æ ‡æ•°æ®å½¢çŠ¶: {y_tr_model.shape}")
        
        # æ£€æŸ¥ç‰¹å¾æ•°é‡
        if X_train_2d.shape[1] == 0:
            print(f"âŒ {model_name} æ¨¡å‹æµ‹è¯•å¤±è´¥: è¾“å…¥ç‰¹å¾æ•°é‡ä¸º0ï¼Œæ— æ³•è®­ç»ƒã€‚")
            continue
        
        # æ£€æŸ¥æ•°æ®è´¨é‡
        print(f"ğŸ“Š è®­ç»ƒæ•°æ®è´¨é‡:")
        print(f"   - NaNæ•°é‡: {np.isnan(X_train_2d).sum()}")
        print(f"   - Infæ•°é‡: {np.isinf(X_train_2d).sum()}")
        if X_train_2d.shape[1] > 0:
            print(f"   - èŒƒå›´: {np.min(X_train_2d):.4f} - {np.max(X_train_2d):.4f}")
        
        # è®­ç»ƒæ¨¡å‹
        start_time = time.time()
        
        if model_name == 'Linear':
            from sklearn.linear_model import LinearRegression
            from sklearn.multioutput import MultiOutputRegressor
            model = MultiOutputRegressor(LinearRegression())
            # è®­ç»ƒLinearæ¨¡å‹
            model.fit(X_train_2d, y_tr_model)
        elif model_name == 'RF':
            from models.ml_models import train_rf
            model_params = model_config.get('model_params', {}).get('ml_low', {})
            model = train_rf(X_train_2d, y_tr_model, model_params)
        elif model_name == 'XGB':
            from models.ml_models import train_xgb
            model_params = model_config.get('model_params', {}).get('ml_low', {})
            model = train_xgb(X_train_2d, y_tr_model, model_params)
        elif model_name == 'LGBM':
            from models.ml_models import train_lgbm
            model_params = model_config.get('model_params', {}).get('ml_low', {})
            model = train_lgbm(X_train_2d, y_tr_model, model_params)
        
        train_time = time.time() - start_time
        
        # é¢„æµ‹
        start_time = time.time()
        y_pred = model.predict(X_test_2d)
        inference_time = time.time() - start_time
        
        print(f"ğŸ“Š é¢„æµ‹ç»“æœå½¢çŠ¶: {y_pred.shape}")
        print(f"ğŸ“Š é¢„æµ‹ç»“æœèŒƒå›´: {np.min(y_pred):.4f} - {np.max(y_pred):.4f}")
        
        # è®¡ç®—æŒ‡æ ‡
        mae = np.mean(np.abs(y_te_model - y_pred))
        rmse = np.sqrt(np.mean((y_te_model - y_pred) ** 2))
        
        # è®¡ç®—RÂ²
        y_true_flat = y_te_model.flatten()
        y_pred_flat = y_pred.flatten()
        ss_res = np.sum((y_true_flat - y_pred_flat) ** 2)
        ss_tot = np.sum((y_true_flat - np.mean(y_true_flat)) ** 2)
        r2 = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0
        
        # è®¡ç®—MAPEï¼ˆé¿å…é™¤é›¶ï¼‰
        mape = np.mean(np.abs((y_true_flat - y_pred_flat) / (np.abs(y_true_flat) + 1e-8))) * 100
        
        print(f"âœ… {model_name} æ¨¡å‹è®­ç»ƒæˆåŠŸ")
        print(f"ğŸ“Š è®­ç»ƒæ—¶é—´: {train_time:.2f}ç§’")
        print(f"ğŸ“Š æ¨ç†æ—¶é—´: {inference_time:.2f}ç§’")
        print(f"ğŸ“Š MAE: {mae:.4f}")
        print(f"ğŸ“Š RMSE: {rmse:.4f}")
        print(f"ğŸ“Š RÂ²: {r2:.4f}")
        print(f"ğŸ“Š MAPE: {mape:.2f}%")
        
        ml_results[model_name] = {
            'mae': mae, 'rmse': rmse, 'r2': r2, 'mape': mape,
            'train_time': train_time, 'inference_time': inference_time,
            'config': model_config
        }
        
    except Exception as e:
        print(f"âŒ {model_name} æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()

# 5. æµ‹è¯•DLæ¨¡å‹
print("\n" + "="*80)
print("5ï¸âƒ£ æµ‹è¯•DLæ¨¡å‹")
print("="*80)

dl_models = ['LSTM', 'GRU', 'TCN', 'Transformer']
dl_results = {}

for model_name in dl_models:
    print(f"\nğŸ”§ æµ‹è¯• {model_name} æ¨¡å‹:")
    try:
        # æ‰¾åˆ°å¯¹åº”çš„é…ç½®
        model_config = None
        for cfg_info in project_configs:
            cfg = cfg_info.get('config', {})
            if cfg.get('model') == model_name and cfg.get('model_complexity') == 'low':
                model_config = cfg
                break
        
        if not model_config:
            print(f"âŒ æ‰¾ä¸åˆ° {model_name} æ¨¡å‹é…ç½®")
            continue
            
        print(f"ğŸ“Š ä½¿ç”¨é…ç½®: {model_config.get('model_complexity', 'N/A')}")
        print(f"ğŸ“Š è¾“å…¥ç‰¹å¾: use_pv={model_config.get('use_pv')}, use_hist_weather={model_config.get('use_hist_weather')}, use_forecast={model_config.get('use_forecast')}")
        
        # ä½¿ç”¨å½“å‰é…ç½®é‡æ–°é¢„å¤„ç†æ•°æ®
        df_clean_model, hist_feats_model, fcst_feats_model, scaler_hist, scaler_fcst, scaler_target = preprocess_features(df, model_config)
        
        # é‡æ–°åˆ›å»ºæ»‘åŠ¨çª—å£
        past_hours = model_config.get('past_hours', 24)
        future_hours = model_config.get('future_hours', 24)
        
        X_hist_model, X_fcst_model, y_model, hours_model, dates_model = create_sliding_windows(
            df_clean_model, past_hours, future_hours, hist_feats_model, fcst_feats_model
        )
        
        # é‡æ–°åˆ†å‰²æ•°æ®
        (Xh_tr_model, Xf_tr_model, y_tr_model, hrs_tr_model, dates_tr_model,
         Xh_va_model, Xf_va_model, y_va_model, hrs_va_model, dates_va_model,
         Xh_te_model, Xf_te_model, y_te_model, hrs_te_model, dates_te_model) = split_data(
            X_hist_model, X_fcst_model, y_model, hours_model, dates_model)
        
        # å‡†å¤‡è®­ç»ƒå‚æ•°
        model_params = model_config.get('model_params', {}).get('low', {})
        train_params = model_config.get('train_params', {})
        
        # ç¡®ä¿train_paramsåŒ…å«å¿…éœ€çš„å‚æ•°
        train_params.update({
            'batch_size': 32,
            'learning_rate': 0.001,
            'loss_type': 'mse',
            'future_hours': 24
        })
        
        print(f"ğŸ“Š æ¨¡å‹å‚æ•°: {model_params}")
        print(f"ğŸ“Š è®­ç»ƒå‚æ•°: {train_params}")
        
        # å‡†å¤‡è®­ç»ƒæ•°æ®å…ƒç»„
        train_data = (Xh_tr_model, Xf_tr_model, y_tr_model, hrs_tr_model, dates_tr_model)
        val_data = (Xh_va_model, Xf_va_model, y_va_model, hrs_va_model, dates_va_model)
        test_data = (Xh_te_model, Xf_te_model, y_te_model, hrs_te_model, dates_te_model)
        scalers = (scaler_hist, scaler_fcst, scaler_target)
        
        # æ„å»ºå®Œæ•´çš„é…ç½®
        full_config = model_config.copy()
        full_config.update({
            'model_params': {'low': model_params},
            'train_params': train_params
        })
        
        # è®­ç»ƒæ¨¡å‹
        from train.train_dl import train_dl_model
        
        model, metrics = train_dl_model(
            full_config, train_data, val_data, test_data, scalers
        )
        
        print(f"âœ… {model_name} æ¨¡å‹è®­ç»ƒæˆåŠŸ")
        print(f"ğŸ“Š è®­ç»ƒæŒ‡æ ‡:")
        for key, value in metrics.items():
            if isinstance(value, float):
                print(f"   - {key}: {value:.4f}")
            elif isinstance(value, (int, np.integer)):
                print(f"   - {key}: {value}")
            elif isinstance(value, list) and len(value) > 0:
                print(f"   - {key}: {len(value)}é¡¹")
            else:
                print(f"   - {key}: {value}")
        
        dl_results[model_name] = metrics
        
    except Exception as e:
        print(f"âŒ {model_name} æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()

# 6. ç»“æœæ±‡æ€»
print("\n" + "="*80)
print("6ï¸âƒ£ æµ‹è¯•ç»“æœæ±‡æ€»")
print("="*80)

print(f"ğŸ“Š MLæ¨¡å‹ç»“æœ:")
if ml_results:
    print(f"{'æ¨¡å‹':<10} {'MAE':<8} {'RMSE':<8} {'RÂ²':<8} {'MAPE':<8} {'è®­ç»ƒæ—¶é—´':<8} {'é…ç½®':<20}")
    print("-" * 80)
    for model, results in ml_results.items():
        config_info = results['config']
        config_str = f"{config_info.get('use_pv', False)}_{config_info.get('use_hist_weather', False)}_{config_info.get('use_forecast', False)}"
        print(f"{model:<10} {results['mae']:<8.4f} {results['rmse']:<8.4f} "
              f"{results['r2']:<8.4f} {results['mape']:<8.2f} {results['train_time']:<8.2f}s {config_str:<20}")
else:
    print("âŒ æ²¡æœ‰æˆåŠŸçš„MLæ¨¡å‹æµ‹è¯•")

print(f"\nğŸ“Š DLæ¨¡å‹ç»“æœ:")
if dl_results:
    print(f"{'æ¨¡å‹':<12} {'MAE':<8} {'RMSE':<8} {'RÂ²':<8} {'è®­ç»ƒæ—¶é—´':<8}")
    print("-" * 60)
    for model, results in dl_results.items():
        mae = results.get('mae', np.nan)
        rmse = results.get('rmse', np.nan)
        r2 = results.get('r2', np.nan)
        train_time = results.get('train_time_sec', np.nan)
        print(f"{model:<12} {mae:<8.4f} {rmse:<8.4f} {r2:<8.4f} {train_time:<8.2f}s")
else:
    print("âŒ æ²¡æœ‰æˆåŠŸçš„DLæ¨¡å‹æµ‹è¯•")

# 7. æµ‹è¯•ç»“æœä¿å­˜
print("\n" + "="*80)
print("7ï¸âƒ£ æµ‹è¯•ç»“æœä¿å­˜")
print("="*80)

try:
    from eval.excel_utils import append_plant_excel_results
    
    # åˆ›å»ºæµ‹è¯•ç»“æœæ•°æ®
    test_results = {
        'config': {
            'model': 'Linear',
            'model_complexity': 'baseline',
            'use_pv': False,  # ä¸å†ä½¿ç”¨PVç‰¹å¾
            'use_hist_weather': True,
            'use_forecast': True,
            'weather_category': 'all_weather',
            'use_time_encoding': True,
            'past_hours': 24,
            'future_hours': 24,
            'start_date': '2022-01-01',
            'end_date': '2024-09-28'
        },
        'metrics': {
            'train_time_sec': 10.0,
            'inference_time_sec': 1.0,
            'param_count': 1000,
            'samples_count': len(Xh_tr) if 'Xh_tr' in locals() else 0,
            'mse': 155.36,
            'rmse': 12.46,
            'mae': 6.97,
            'r2': 0.85,
            'mape': 15.2
        }
    }
    
    # æµ‹è¯•ç»“æœä¿å­˜
    result_dir = Path("test_results")
    result_dir.mkdir(exist_ok=True)
    
    excel_file = append_plant_excel_results(
        plant_id=1140,
        result=test_results,
        save_dir=str(result_dir)
    )
    
    print(f"âœ… ç»“æœä¿å­˜æˆåŠŸ")
    print(f"ğŸ“Š Excelæ–‡ä»¶: {excel_file}")
    
except Exception as e:
    print(f"âŒ ç»“æœä¿å­˜å¤±è´¥: {e}")
    traceback.print_exc()

print("\n" + "="*80)
print("ğŸ‰ çœŸå®æ•°æ®å…¨é¢æµ‹è¯•å®Œæˆï¼")
print("="*80)

print(f"\nğŸ“Š æœ€ç»ˆæµ‹è¯•æ€»ç»“:")
print(f"   - é…ç½®ç”Ÿæˆ: {'âœ…' if 'project_configs' in locals() else 'âŒ'}")
print(f"   - æ•°æ®é¢„å¤„ç†: {'âœ…' if 'preprocessing_results' in locals() else 'âŒ'}")
print(f"   - æ»‘åŠ¨çª—å£: {'âœ…' if 'X_hist' in locals() else 'âŒ'}")
print(f"   - MLæ¨¡å‹æµ‹è¯•: {len(ml_results)}/4 æˆåŠŸ")
print(f"   - DLæ¨¡å‹æµ‹è¯•: {len(dl_results)}/4 æˆåŠŸ")
print(f"   - ç»“æœä¿å­˜: {'âœ…' if 'excel_file' in locals() else 'âŒ'}")

print(f"\nğŸ¯ å…³é”®å‘ç°:")
if 'df' in locals():
    print(f"   - æ•°æ®æ—¶é—´èŒƒå›´: 2020-2024 (è¿‡æ»¤å: 2022-2024)")
if 'X_hist' in locals():
    print(f"   - å¯ç”¨æ ·æœ¬æ•°: {X_hist.shape[0]}")
    print(f"   - ç‰¹å¾ç»´åº¦: {X_hist.shape[2]}")
if ml_results:
    best_ml = min(ml_results.items(), key=lambda x: x[1]['mae'])
    print(f"   - æœ€ä½³MLæ¨¡å‹: {best_ml[0]} (MAE={best_ml[1]['mae']:.4f})")
if dl_results:
    best_dl = min(dl_results.items(), key=lambda x: x[1].get('mae', float('inf')))
    print(f"   - æœ€ä½³DLæ¨¡å‹: {best_dl[0]} (MAE={best_dl[1].get('mae', 0):.4f})")

print(f"\nâ° ç»“æŸæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}")
print(f"â±ï¸ æ€»è€—æ—¶: {time.time() - time.time():.2f}ç§’")
